From 38b4703a83b37bef6c4d0cf65a5afef6c1d64bd3 Mon Sep 17 00:00:00 2001
From: Razvan A Lupusoru <razvan.a.lupusoru@intel.com>
Date: Fri, 5 Apr 2013 19:46:22 -0700
Subject: Dalvik: Scratch virtual registers

BZ: 96319

This patch adds 4 scratch virtual registers per java frame.
These can be used by middle end optimizations for intermediate
values that do not need to be live out of trace.

Category: device-enablement
Domain: AOSP-Dalvik-Compiler-CG; AOSP-Dalvik-Compiler-ME; AOSP-Dalvik-GC; AOSP-Dalvik-Interpreter; AOSP-Dalvik-Runtime
Origin: internal
Upstream-Candidate: no, needs rework

Change-Id: I2bf201523e2422709652712bd709c9b50cca3030
Orig-MCG-Change-Id: Ieb6c3aab77bed57a2c711227400896ac5d6fe728
Signed-off-by: Razvan A Lupusoru <razvan.a.lupusoru@intel.com>
Signed-off-by: Qiming Shi <qiming.shi@intel.com>
Signed-off-by: Serguei Katkov <serguei.i.katkov@intel.com>
---
 vm/Dvm.mk                                         |    4 +-
 vm/Thread.h                                       |    2 +-
 vm/alloc/Copying.cpp                              |   37 ++-
 vm/alloc/Visit.cpp                                |   28 +-
 vm/compiler/Dataflow.cpp                          |    6 +-
 vm/compiler/Frontend.cpp                          |    9 +-
 vm/compiler/LoopInformation.cpp                   |    2 +-
 vm/compiler/RegisterizationME.cpp                 |    3 +-
 vm/compiler/StackExtension.h                      |   55 ++
 vm/compiler/codegen/x86/AnalysisO1.cpp            |    5 +-
 vm/compiler/codegen/x86/AnalysisO1.h              |    2 +-
 vm/compiler/codegen/x86/BytecodeVisitor.cpp       |   43 +-
 vm/compiler/codegen/x86/InstructionGeneration.cpp |    6 +-
 vm/compiler/codegen/x86/Lower.h                   |   96 +----
 vm/compiler/codegen/x86/LowerAlu.cpp              |  542 ++++++++++----------
 vm/compiler/codegen/x86/LowerConst.cpp            |   26 +-
 vm/compiler/codegen/x86/LowerGetPut.cpp           |  218 ++++----
 vm/compiler/codegen/x86/LowerHelper.cpp           |  112 +----
 vm/compiler/codegen/x86/LowerInvoke.cpp           |  124 +++---
 vm/compiler/codegen/x86/LowerJump.cpp             |   44 +-
 vm/compiler/codegen/x86/LowerMove.cpp             |   34 +-
 vm/compiler/codegen/x86/LowerObject.cpp           |   60 ++--
 vm/compiler/codegen/x86/LowerReturn.cpp           |   10 +-
 vm/compiler/codegen/x86/NcgAot.cpp                |    4 +-
 vm/compiler/codegen/x86/StackExtensionX86.cpp     |   59 +++
 vm/compiler/codegen/x86/StackExtensionX86.h       |   69 +++
 vm/interp/Stack.h                                 |   16 +-
 vm/mterp/common/asm-constants.h                   |   27 +-
 28 files changed, 886 insertions(+), 757 deletions(-)
 create mode 100644 vm/compiler/StackExtension.h
 create mode 100644 vm/compiler/codegen/x86/StackExtensionX86.cpp
 create mode 100644 vm/compiler/codegen/x86/StackExtensionX86.h

diff --git a/vm/Dvm.mk b/vm/Dvm.mk
index a55c84d..fc99d9b 100644
--- a/vm/Dvm.mk
+++ b/vm/Dvm.mk
@@ -325,7 +325,8 @@ ifeq ($(dvm_arch),x86)
   ifeq ($(dvm_os),linux)
     MTERP_ARCH_KNOWN := true
     LOCAL_CFLAGS += -DDVM_JMP_TABLE_MTERP=1 \
-                    -DMTERP_STUB
+                    -DMTERP_STUB \
+                    -DEXTRA_SCRATCH_VR
     LOCAL_SRC_FILES += \
 		arch/$(dvm_arch)/Call386ABI.S \
 		arch/$(dvm_arch)/Hints386ABI.cpp \
@@ -354,6 +355,7 @@ ifeq ($(dvm_arch),x86)
               compiler/codegen/$(dvm_arch_variant)/ExceptionHandling.cpp \
               compiler/codegen/$(dvm_arch_variant)/CodegenErrors.cpp \
               compiler/codegen/$(dvm_arch_variant)/RegisterizationBE.cpp \
+              compiler/codegen/$(dvm_arch_variant)/StackExtensionX86.cpp \
               compiler/LoopOpt.cpp \
               compiler/Checks.cpp \
               compiler/Pass.cpp \
diff --git a/vm/Thread.h b/vm/Thread.h
index 19bd49c..d7a6143 100644
--- a/vm/Thread.h
+++ b/vm/Thread.h
@@ -76,7 +76,7 @@ void dvmSlayDaemons(void);
 #define kInternalRefMax         4096    /* mainly a sanity check */
 
 #define kMinStackSize       (512 + STACK_OVERFLOW_RESERVE)
-#define kDefaultStackSize   (16*1024)   /* four 4K pages */
+#define kDefaultStackSize   (20*1024)   /* five 4K pages */
 #define kMaxStackSize       (256*1024 + STACK_OVERFLOW_RESERVE)
 
 /*
diff --git a/vm/alloc/Copying.cpp b/vm/alloc/Copying.cpp
index 77cdac3..74cb6b8 100644
--- a/vm/alloc/Copying.cpp
+++ b/vm/alloc/Copying.cpp
@@ -1635,6 +1635,8 @@ static void scavengeThreadStack(Thread *thread)
             if (regVector == NULL) {
                 /*
                  * There are no roots to scavenge.  Skip over the entire frame.
+                 * We do not need to take into account the temporaries because
+                 * they are part of the StackSaveArea.
                  */
                 framePtr += method->registersSize;
             } else {
@@ -1647,7 +1649,18 @@ static void scavengeThreadStack(Thread *thread)
                  * A '1' bit indicates a live reference.
                  */
                 u2 bits = 1 << 1;
-                for (int i = method->registersSize - 1; i >= 0; i--) {
+
+                int totalRegisters = method->registersSize;
+#ifdef WITH_JIT
+                /*
+                 * We want to scan through temporary registers as well but
+                 * for now since they are just live within a trace, we do
+                 * not have to scan them.
+                 */
+                totalRegisters += 0; //dvmArchSpecGetNumberOfScratch ();
+#endif
+
+                for (int i = totalRegisters - 1; i >= 0; i--) {
                     u4 rval = *framePtr;
 
                     bits >>= 1;
@@ -1665,7 +1678,7 @@ static void scavengeThreadStack(Thread *thread)
                         if ((rval & 0x3) != 0 || !dvmIsValidObject((Object*) rval)) {
                             /* this is very bad */
                             ALOGE("PGC: invalid ref in reg %d: 0x%08x",
-                                method->registersSize-1 - i, rval);
+                                    totalRegisters - 1 - i, rval);
                         } else
 #endif
                         {
@@ -1682,7 +1695,7 @@ static void scavengeThreadStack(Thread *thread)
                         if (dvmIsValidObject((Object*) rval)) {
                             /* this is normal, but we feel chatty */
                             ALOGD("PGC: ignoring valid ref in reg %d: 0x%08x",
-                                 method->registersSize-1 - i, rval);
+                                    totalRegisters - 1 - i, rval);
                         }
 #endif
                     }
@@ -1782,6 +1795,11 @@ static void pinThreadStack(const Thread *thread)
                 }
             }
             shorty = method->shorty+1;      // skip return value
+
+            /*
+             * We don't need to pin the temporaries on frame since the native
+             * code won't touch that area.
+             */
             for (int i = method->registersSize - 1; i >= 0; i--, framePtr++) {
                 switch (*shorty++) {
                 case 'L':
@@ -1819,7 +1837,18 @@ static void pinThreadStack(const Thread *thread)
                 /*
                  * No register info for this frame, conservatively pin.
                  */
-                for (int i = 0; i < method->registersSize; ++i) {
+
+                unsigned int totalRegisters = method->registersSize;
+#ifdef WITH_JIT
+                /*
+                 * Since we do not have native method, we should conservatively
+                 * pin the temporaries as well. However, for now temporaries are
+                 * not live out of compiled traces so we can skip them.
+                 */
+                totalRegisters += 0; //dvmArchSpecGetNumberOfScratch ();
+#endif
+
+                for (unsigned int i = 0; i < totalRegisters; ++i) {
                     u4 regValue = framePtr[i];
                     if (regValue != 0 && (regValue & 0x3) == 0 && dvmIsValidObject((Object *)regValue)) {
                         pinObject((Object *)regValue);
diff --git a/vm/alloc/Visit.cpp b/vm/alloc/Visit.cpp
index 410b66e..a04a835 100644
--- a/vm/alloc/Visit.cpp
+++ b/vm/alloc/Visit.cpp
@@ -106,7 +106,18 @@ static void visitThreadStack(RootVisitor *visitor, Thread *thread, void *arg)
                  * info for the current PC.  Perform a conservative
                  * scan.
                  */
-                for (size_t i = 0; i < method->registersSize; ++i) {
+
+                unsigned int totalRegisters = method->registersSize;
+#ifdef WITH_JIT
+                /*
+                 * We want to scan through temporary registers as well but
+                 * for now since they are just live within a trace, we do
+                 * not have to scan them.
+                 */
+                totalRegisters += 0; //dvmArchSpecGetNumberOfScratch ();
+#endif
+
+                for (unsigned int i = 0; i < totalRegisters; ++i) {
                     if (dvmIsValidObject((Object *)fp[i])) {
                         (*visitor)(&fp[i], threadId, ROOT_JAVA_FRAME, arg);
                     }
@@ -121,7 +132,18 @@ static void visitThreadStack(RootVisitor *visitor, Thread *thread, void *arg)
                  * A '1' bit indicates a live reference.
                  */
                 u2 bits = 1 << 1;
-                for (size_t i = 0; i < method->registersSize; ++i) {
+
+                unsigned int totalRegisters = method->registersSize;
+#ifdef WITH_JIT
+                /*
+                 * We want to scan through temporary registers as well but
+                 * for now since they are just live within a trace, we do
+                 * not have to scan them.
+                 */
+                totalRegisters += 0; //dvmArchSpecGetNumberOfScratch ();
+#endif
+
+                for (unsigned int i = 0; i < totalRegisters; ++i) {
                     bits >>= 1;
                     if (bits == 1) {
                         /* set bit 9 so we can tell when we're empty */
@@ -135,7 +157,7 @@ static void visitThreadStack(RootVisitor *visitor, Thread *thread, void *arg)
                         if (fp[i] != 0 && !dvmIsValidObject((Object *)fp[i])) {
                             /* this is very bad */
                             ALOGE("PGC: invalid ref in reg %d: %#x",
-                                 method->registersSize - 1 - i, fp[i]);
+                                    totalRegisters - 1 - i, fp[i]);
                             ALOGE("PGC: %s.%s addr %#x",
                                  method->clazz->descriptor, method->name,
                                  saveArea->xtra.currentPc - method->insns);
diff --git a/vm/compiler/Dataflow.cpp b/vm/compiler/Dataflow.cpp
index 6e7acb7..80031bd 100644
--- a/vm/compiler/Dataflow.cpp
+++ b/vm/compiler/Dataflow.cpp
@@ -1542,12 +1542,12 @@ bool dvmCompilerDoSSAConversion(CompilationUnit *cUnit, BasicBlock *bb)
     //Next remember SSA state at entrance
     if (bb->dataFlowInfo->dalvikToSSAMap == 0)
     {
-        bb->dataFlowInfo->dalvikToSSAMap = static_cast<int *> (dvmCompilerNew (sizeof (* (bb->dataFlowInfo->dalvikToSSAMap)) * cUnit->method->registersSize, false));
+        bb->dataFlowInfo->dalvikToSSAMap = static_cast<int *> (dvmCompilerNew (sizeof (* (bb->dataFlowInfo->dalvikToSSAMap)) * cUnit->numDalvikRegisters, false));
     }
 
     //Remember the state we were at when starting the BasicBlock
     memcpy(bb->dataFlowInfo->dalvikToSSAMap, cUnit->dalvikToSSAMap,
-           sizeof (* (bb->dataFlowInfo->dalvikToSSAMap)) * cUnit->method->registersSize);
+           sizeof (* (bb->dataFlowInfo->dalvikToSSAMap)) * cUnit->numDalvikRegisters);
 
     for (mir = bb->firstMIRInsn; mir; mir = mir->next) {
         //If not yet generated
@@ -2139,7 +2139,7 @@ void dvmCompilerFindInductionVariables(CompilationUnit *cUnit,
 void dvmInitializeSSAConversion(CompilationUnit *cUnit)
 {
     int i;
-    int numDalvikReg = cUnit->method->registersSize;
+    int numDalvikReg = cUnit->numDalvikRegisters;
 
     //If ever the new number is not the same as before, invalidate all dataflow and ssa structures
     if (numDalvikReg > cUnit->numSSARegs)
diff --git a/vm/compiler/Frontend.cpp b/vm/compiler/Frontend.cpp
index 27b8fdd..fc9bb4b 100644
--- a/vm/compiler/Frontend.cpp
+++ b/vm/compiler/Frontend.cpp
@@ -1514,7 +1514,8 @@ bool dvmCompileMethod(const Method *method, JitTranslationInfo *info)
     }
 
     /* Adjust this value accordingly once inlining is performed */
-    cUnit.numDalvikRegisters = cUnit.method->registersSize;
+    cUnit.numDalvikRegisters = cUnit.method->registersSize
+            + dvmArchSpecGetNumberOfScratch();
 
     /* Verify if all blocks are connected as claimed */
     /* FIXME - to be disabled in the future */
@@ -1792,7 +1793,8 @@ static bool compileLoop(CompilationUnit *cUnit, unsigned int startOffset,
     dvmInsertGrowableList(&cUnit->blockList, (intptr_t) bb);
     cUnit->puntBlock = bb;
 
-    cUnit->numDalvikRegisters = cUnit->method->registersSize;
+    cUnit->numDalvikRegisters = cUnit->method->registersSize
+            + dvmArchSpecGetNumberOfScratch();
 
     /* Verify if all blocks are connected as claimed */
     /* FIXME - to be disabled in the future */
@@ -2564,7 +2566,8 @@ bool dvmCompileTrace(JitTraceDescription *desc, int numMaxInsts,
         dvmCompilerInlineMIR(&cUnit, info);
     }
 
-    cUnit.numDalvikRegisters = cUnit.method->registersSize;
+    cUnit.numDalvikRegisters = cUnit.method->registersSize
+            + dvmArchSpecGetNumberOfScratch();
 
 #ifndef ARCH_IA32
     /* Preparation for SSA conversion */
diff --git a/vm/compiler/LoopInformation.cpp b/vm/compiler/LoopInformation.cpp
index 656f59d..4f0d056 100644
--- a/vm/compiler/LoopInformation.cpp
+++ b/vm/compiler/LoopInformation.cpp
@@ -44,7 +44,7 @@ void LoopInformation::init (const Method *method)
 
     if (method != 0)
     {
-        scratchRegisters = method->registersSize + 1;
+        scratchRegisters = dvmArchSpecGetNumberOfScratch();
     }
     else
     {
diff --git a/vm/compiler/RegisterizationME.cpp b/vm/compiler/RegisterizationME.cpp
index dc2b739..645cf40 100644
--- a/vm/compiler/RegisterizationME.cpp
+++ b/vm/compiler/RegisterizationME.cpp
@@ -211,7 +211,8 @@ static void handleWriteBackRequestsPostLoop (const CompilationUnit *cUnit, const
         }
 
         //For the moment, we are being simple, exiting the loop, we request write backs of
-        //every register in the method
+        //every register in the method. Note that we do not request writebacks of
+        //temporaries and thus we do not want to use cUnit->numDalvikRegisters
         unsigned int size = cUnit->method->registersSize;
         dvmSetInitialBits (bb->requestWriteBack, size);
     }
diff --git a/vm/compiler/StackExtension.h b/vm/compiler/StackExtension.h
new file mode 100644
index 0000000..519b267
--- /dev/null
+++ b/vm/compiler/StackExtension.h
@@ -0,0 +1,55 @@
+/*
+ * Copyright (C) 2013 Intel Corporation
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef STACKEXTENSION_H_
+#define STACKEXTENSION_H_
+
+/* Architecture specific stack extension */
+struct ArchSpecificStackExtension;
+
+/* Returns whether the architecture created space for scratch registers */
+unsigned int dvmArchSpecGetNumberOfScratch (void);
+
+/* Given a scratch register index, it returns >= 0 if it can find one with
+ * available with that index. The return value will be the Virtual Register
+ * number to be used to refer to the scratch register. Scratch register indices
+ * accepted are [0 .. N-1] where N is maximum number of scratch registers
+ * available. The parameter method must be the method containing the MIR
+ * for which we want to use scratch register. Whenever a scratch register
+ * with that index is not available, the return value will be -1.
+ */
+int dvmArchSpecGetScratchRegister (const Method * method, unsigned int idx);
+
+#ifdef ARCH_IA32
+
+#include "vm/compiler/codegen/x86/StackExtensionX86.h"
+
+#else
+
+unsigned int dvmArchSpecGetNumberOfScratch (void)
+{
+    //Non-x86 don't have scratch registers in their frames
+    return 0;
+}
+
+int dvmArchSpecGetScratchRegister (const Method * method, unsigned int idx)
+{
+    //Non-x86 don't have scratch registers in their frames
+    return -1;
+}
+#endif
+
+#endif /* STACKEXTENSION_H_ */
diff --git a/vm/compiler/codegen/x86/AnalysisO1.cpp b/vm/compiler/codegen/x86/AnalysisO1.cpp
index d32d55c..82f4437 100644
--- a/vm/compiler/codegen/x86/AnalysisO1.cpp
+++ b/vm/compiler/codegen/x86/AnalysisO1.cpp
@@ -29,7 +29,6 @@
 #include "Singleton.h"
 #include <set>
 
-
 /* compilation flags to turn on debug printout */
 //#define DEBUG_COMPILE_TABLE
 //#define DEBUG_ALLOC_CONSTRAINT
@@ -3636,7 +3635,7 @@ int sortAllocConstraint(RegAllocConstraint* allocConstraints,
 //! \param vA The VR to search for
 //! \param type Register type
 //! \return the virtual reg if found, else -1 as error.
-int findVirtualRegInTable(u2 vA, LowOpndRegType type) {
+int findVirtualRegInTable(int vA, LowOpndRegType type) {
     int k = searchCompileTable(type | LowOpndRegType_virtual, vA);
     if(k < 0) {
         ALOGI("JIT_INFO: Couldn't find virtual register %d type %d in compiler table\n", vA, type);
@@ -5378,7 +5377,7 @@ int checkVirtualReg(int reg, LowOpndRegType type, int updateRefCount) {
 
 //!This is called in get_virtual_reg
 //!If this function returns false, new register will be allocated for this temporary
-bool checkTempReg2(int reg, int type, bool isPhysical, int physicalRegForVR, u2 vB) {
+bool checkTempReg2(int reg, int type, bool isPhysical, int physicalRegForVR, int vB) {
     if (isPhysical) {
         // If temporary is already physical, we cannot share with VR
         return false;
diff --git a/vm/compiler/codegen/x86/AnalysisO1.h b/vm/compiler/codegen/x86/AnalysisO1.h
index 4776fb2..d76ab50 100644
--- a/vm/compiler/codegen/x86/AnalysisO1.h
+++ b/vm/compiler/codegen/x86/AnalysisO1.h
@@ -390,7 +390,7 @@ int createCFGHandler(Method* method);
 //Set a VR to a constant value
 void setVRToConst(int regNum, OpndSize size, int* tmpValue);
 
-int findVirtualRegInTable(u2 vA, LowOpndRegType type);
+int findVirtualRegInTable(int vA, LowOpndRegType type);
 int searchCompileTable(int type, int regNum);
 void handleJump(BasicBlock_O1* bb_prev, int relOff);
 void connectBasicBlock(BasicBlock_O1* src, BasicBlock_O1* dst);
diff --git a/vm/compiler/codegen/x86/BytecodeVisitor.cpp b/vm/compiler/codegen/x86/BytecodeVisitor.cpp
index cbce454..d0e4f5e 100644
--- a/vm/compiler/codegen/x86/BytecodeVisitor.cpp
+++ b/vm/compiler/codegen/x86/BytecodeVisitor.cpp
@@ -428,7 +428,7 @@ int getByteCodeSize() { //uses inst, unit in u2
 //! \param type
 //!
 //! \return -1 on error, 0 otherwise
-static int touchOneVR(u2 vA, LowOpndRegType type) {
+static int touchOneVR(int vA, LowOpndRegType type) {
     int index = searchCompileTable(LowOpndRegType_virtual | type, vA);
     if(index < 0) {
         ALOGI("JIT_INFO: virtual reg %d type %d not found in touchOneVR\n", vA, type);
@@ -543,7 +543,7 @@ int getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
     int retCode = 0;
     compileTableEntry* infoArray = compileTable;
     Opcode inst_op = currentMIR->dalvikInsn.opcode;
-    u2 vA = 0, vB = 0, v1, v2;
+    int vA = 0, vB = 0, v1, v2;
     u2 BBBB;
     u2 tmp_u2;
     s4 tmp_s4;
@@ -1273,9 +1273,9 @@ int getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
 //! uses of virtual registers are added to infoArray first
 int getVirtualRegInfo(VirtualRegInfo* infoArray, const MIR * currentMIR) {
     u2 inst_op = currentMIR->dalvikInsn.opcode;
-    u2 vA = 0, vB = 0, vref, vindex;
-    u2 v1, v2, length, vD, vG, vE, vF, count;
-    u4 v1_u4, v2_u4;
+    int vA = 0, vB = 0, vref, vindex;
+    int v1, v2, vD, vG, vE, vF;
+    u2 length, count;
     int kk, num, num_entry;
     s2 tmp_s2;
     int codeSize = 0;
@@ -1651,9 +1651,9 @@ int getVirtualRegInfo(VirtualRegInfo* infoArray, const MIR * currentMIR) {
         length = currentMIR->dalvikInsn.vA;
         v1 = currentMIR->dalvikInsn.arg[0];
         v2 = currentMIR->dalvikInsn.arg[1];
-        u2 v3 = currentMIR->dalvikInsn.arg[2];
-        u2 v4 = currentMIR->dalvikInsn.arg[3];
-        u2 v5 = currentMIR->dalvikInsn.arg[4];
+        int v3 = currentMIR->dalvikInsn.arg[2];
+        int v4 = currentMIR->dalvikInsn.arg[3];
+        int v5 = currentMIR->dalvikInsn.arg[4];
         if(length >= 1) {
             infoArray[0].regNum = v1; //src
             infoArray[0].refCount = 1;
@@ -1759,14 +1759,14 @@ int getVirtualRegInfo(VirtualRegInfo* infoArray, const MIR * currentMIR) {
     case OP_CMPG_FLOAT:
         codeSize = 2;
         vA = currentMIR->dalvikInsn.vA;
-        v1_u4 = currentMIR->dalvikInsn.vB;
-        v2_u4 = currentMIR->dalvikInsn.vC;
+        v1 = currentMIR->dalvikInsn.vB;
+        v2 = currentMIR->dalvikInsn.vC;
         num_regs_per_bytecode = 1;
-        infoArray[0].regNum = v1_u4; //use ss or sd CHECK
+        infoArray[0].regNum = v1; //use ss or sd CHECK
         infoArray[0].refCount = 1;
         infoArray[0].accessType = REGACCESS_U;
         infoArray[0].physicalType = LowOpndRegType_ss;
-        infoArray[1].regNum = v2_u4; //use
+        infoArray[1].regNum = v2; //use
         infoArray[1].refCount = 1;
         infoArray[1].accessType = REGACCESS_U;
         infoArray[1].physicalType = LowOpndRegType_ss;
@@ -1782,23 +1782,23 @@ int getVirtualRegInfo(VirtualRegInfo* infoArray, const MIR * currentMIR) {
     case OP_CMP_LONG: //load v1, v1+1, v2, v2+1 to gpr
         codeSize = 2;
         vA = currentMIR->dalvikInsn.vA;
-        v1_u4 = currentMIR->dalvikInsn.vB;
-        v2_u4 = currentMIR->dalvikInsn.vC;
+        v1 = currentMIR->dalvikInsn.vB;
+        v2 = currentMIR->dalvikInsn.vC;
         num_regs_per_bytecode = 1;
         if(inst_op == OP_CMP_LONG) {
-            infoArray[0].regNum = v1_u4; //use
+            infoArray[0].regNum = v1; //use
             infoArray[0].refCount = 1;
             infoArray[0].accessType = REGACCESS_U;
             infoArray[0].physicalType = LowOpndRegType_gp;
-            infoArray[1].regNum = v1_u4 + 1; //use
+            infoArray[1].regNum = v1 + 1; //use
             infoArray[1].refCount = 1;
             infoArray[1].accessType = REGACCESS_U;
             infoArray[1].physicalType = LowOpndRegType_gp;
-            infoArray[2].regNum = v2_u4; //use
+            infoArray[2].regNum = v2; //use
             infoArray[2].refCount = 1;
             infoArray[2].accessType = REGACCESS_U;
             infoArray[2].physicalType = LowOpndRegType_gp;
-            infoArray[3].regNum = v2_u4 + 1; //use
+            infoArray[3].regNum = v2 + 1; //use
             infoArray[3].refCount = 1;
             infoArray[3].accessType = REGACCESS_U;
             infoArray[3].physicalType = LowOpndRegType_gp;
@@ -1810,11 +1810,11 @@ int getVirtualRegInfo(VirtualRegInfo* infoArray, const MIR * currentMIR) {
             infoArray[num_entry].physicalType = LowOpndRegType_gp;
         }
         else {
-            infoArray[0].regNum = v1_u4; //use ss or sd CHECK
+            infoArray[0].regNum = v1; //use ss or sd CHECK
             infoArray[0].refCount = 1;
             infoArray[0].accessType = REGACCESS_U;
             infoArray[0].physicalType = LowOpndRegType_xmm;
-            infoArray[1].regNum = v2_u4; //use
+            infoArray[1].regNum = v2; //use
             infoArray[1].refCount = 1;
             infoArray[1].accessType = REGACCESS_U;
             infoArray[1].physicalType = LowOpndRegType_xmm;
@@ -3392,7 +3392,8 @@ int getTempRegInfo(TempRegInfo* infoArray, const MIR * currentMIR) { //returns a
         infoArray[k].shareWithVR = true;
         infoArray[k].is8Bit = false;
     }
-    u2 vA, vB, v1, v2, length, num, tmp;
+    u2 length, num, tmp;
+    int vA, vB, v1, v2;
     Opcode inst_op = currentMIR->dalvikInsn.opcode;
     s2 tmp_s2;
     int tmpvalue, isConst;
diff --git a/vm/compiler/codegen/x86/InstructionGeneration.cpp b/vm/compiler/codegen/x86/InstructionGeneration.cpp
index 6649b07..9638faf 100644
--- a/vm/compiler/codegen/x86/InstructionGeneration.cpp
+++ b/vm/compiler/codegen/x86/InstructionGeneration.cpp
@@ -75,7 +75,7 @@ void genHoistedBoundCheck (CompilationUnit *cUnit, MIR *mir)
     export_pc();
 
     //Compare array length with index value
-    compare_mem_reg(OpndSize_32, offArrayObject_length, P_GPR_1, true, P_GPR_2, true);
+    compare_mem_reg(OpndSize_32, OFFSETOF_MEMBER(ArrayObject, length), P_GPR_1, true, P_GPR_2, true);
     //Jump to exception block if array.length <= index
     condJumpToBasicBlock(stream, Condition_LE, cUnit->exceptionBlockId);
 
@@ -126,7 +126,7 @@ void genHoistedChecksForCountUpLoop(CompilationUnit *cUnit, MIR *mir)
     } else if(delta > 0) {
         alu_binary_imm_reg(OpndSize_32, add_opc, delta, P_GPR_2, true);
     }
-    compare_mem_reg(OpndSize_32, offArrayObject_length, P_GPR_1, true, P_GPR_2, true);
+    compare_mem_reg(OpndSize_32, OFFSETOF_MEMBER(ArrayObject, length), P_GPR_1, true, P_GPR_2, true);
     condJumpToBasicBlock(stream, Condition_NC, cUnit->exceptionBlockId);
 }
 
@@ -155,7 +155,7 @@ void genHoistedChecksForCountDownLoop(CompilationUnit *cUnit, MIR *mir)
     } else if(maxC > 0) {
         alu_binary_imm_reg(OpndSize_32, add_opc, maxC, P_GPR_2, true);
     }
-    compare_mem_reg(OpndSize_32, offArrayObject_length, P_GPR_1, true, P_GPR_2, true);
+    compare_mem_reg(OpndSize_32, OFFSETOF_MEMBER(ArrayObject, length), P_GPR_1, true, P_GPR_2, true);
     condJumpToBasicBlock(stream, Condition_NC, cUnit->exceptionBlockId);
 
 }
diff --git a/vm/compiler/codegen/x86/Lower.h b/vm/compiler/codegen/x86/Lower.h
index 80a6d22..7075def 100644
--- a/vm/compiler/codegen/x86/Lower.h
+++ b/vm/compiler/codegen/x86/Lower.h
@@ -84,87 +84,9 @@
 #define INST_B(_inst)       ((_inst) >> 12)
 #define INST_AA(_inst)      ((_inst) >> 8)
 
-//#include "vm/mterp/common/asm-constants.h"
 #define offEBP_self 8
 #define offEBP_spill -56
-#define offThread_exception 68
-#define offClassObject_descriptor 24
-#define offArrayObject_length 8
-#ifdef PROFILE_FIELD_ACCESS
-#define offStaticField_value 24
-#define offInstField_byteOffset 24
-#else
-#define offStaticField_value 16
-#define offInstField_byteOffset 16
-#endif
-
-#ifdef EASY_GDB
-#define offStackSaveArea_prevFrame 4
-#define offStackSaveArea_savedPc 8
-#define offStackSaveArea_method 12
-#define offStackSaveArea_localRefTop 16 // -> StackSaveArea.xtra.locakRefCookie
-#define offStackSaveArea_returnAddr 20
-#define offStackSaveArea_isDebugInterpreted 24
-#define sizeofStackSaveArea 24
-#else
-#define offStackSaveArea_prevFrame 0
-#define offStackSaveArea_savedPc 4
-#define offStackSaveArea_method 8
-#define offStackSaveArea_localRefTop 12 // -> StackSaveArea.xtra.locakRefCookie
-#define offStackSaveArea_returnAddr 16
-#define offStackSaveArea_isDebugInterpreted 20
-#define sizeofStackSaveArea 20
-#endif
-
-#define offClassObject_status 44
-#define offClassObject_accessFlags 32
-#ifdef MTERP_NO_UNALIGN_64
-#define offArrayObject_contents 16
-#else
-#define offArrayObject_contents 12
-#endif
-
-#define offField_clazz 0
-#define offObject_clazz 0
-#define offClassObject_vtable 116
-#define offClassObject_pDvmDex 40
-#define offClassObject_super 72
-#define offClassObject_vtableCount 112
-#define offMethod_name 16
-#define offMethod_accessFlags 4
-#define offMethod_methodIndex 8
-#define offMethod_registersSize 10
-#define offMethod_outsSize 12
-#define offGlue_interpStackEnd 32
-#define offThread_inJitCodeCache 124
 #define offThread_jniLocal_nextEntry 168
-#define offMethod_insns 32
-#ifdef ENABLE_TRACING
-#define offMethod_insns_bytecode 44
-#define offMethod_insns_ncg 48
-#endif
-
-#define offGlue_pc     0
-#define offGlue_fp     4
-#define offGlue_retval 8
-
-#define offThread_curFrame 4
-#define offGlue_method 16
-#define offGlue_methodClassDex 20
-#define offGlue_self 24
-#define offGlue_pSelfSuspendCount 36
-#define offGlue_cardTable 40
-#define offGlue_pDebuggerActive 44
-#define offGlue_pActiveProfilers 48
-#define offGlue_entryPoint 52
-#define offGlue_icRechainCount 84
-#define offGlue_espEntry 88
-#define offGlue_spillRegion 92
-#define offDvmDex_pResStrings 8
-#define offDvmDex_pResClasses 12
-#define offDvmDex_pResMethods 16
-#define offDvmDex_pResFields  20
-#define offMethod_clazz       0
 
 // Definitions must be consistent with vm/mterp/x86/header.S
 #define FRAME_SIZE     124
@@ -711,7 +633,7 @@ int updateRefCount2(int reg, int type, bool isPhysical);
 int spillVirtualReg(int vrNum, LowOpndRegType type, bool updateTable);
 int isVirtualRegConstant(int regNum, LowOpndRegType type, int* valuePtr, bool updateRef);
 int checkTempReg(int reg, int type, bool isPhysical, int vA);
-bool checkTempReg2(int reg, int type, bool isPhysical, int physicalRegForVR, u2 vB);
+bool checkTempReg2(int reg, int type, bool isPhysical, int physicalRegForVR, int vB);
 int freeReg(bool writeBackAllVRs);
 int nextVersionOfHardReg(PhysicalReg pReg, int refCount);
 int updateVirtualReg(int reg, LowOpndRegType type);
@@ -856,7 +778,7 @@ void alu_binary_imm_mem(OpndSize size, ALU_Opcode opc,
 void alu_binary_imm_reg(OpndSize size, ALU_Opcode opc, int imm, int reg, bool isPhysical);
 //Operate on a VR with another VR and an immediate
 bool alu_imm_to_VR(OpndSize size, ALU_Opcode opc,
-                         u2 srcVR, u2 destVR, int imm, int tempReg, bool isTempPhysical);
+                         int srcVR, int destVR, int imm, int tempReg, bool isTempPhysical);
 void alu_binary_mem_reg(OpndSize size, ALU_Opcode opc,
                          int disp, int base_reg, bool isBasePhysical,
                          int reg, bool isPhysical);
@@ -942,22 +864,22 @@ void move_reg_to_mem_disp_scale(OpndSize size,
                             int base_reg, bool isBasePhysical, int disp, int index_reg, bool isIndexPhysical, int scale);
 void move_imm_to_mem(OpndSize size, int imm,
                       int disp, int base_reg, bool isBasePhysical);
-void set_VR_to_imm(u2 vA, OpndSize size, int imm);
-void set_VR_to_imm_noalloc(u2 vA, OpndSize size, int imm);
-void set_VR_to_imm_noupdateref(LowOp* op, u2 vA, OpndSize size, int imm);
+void set_VR_to_imm(int vA, OpndSize size, int imm);
+void set_VR_to_imm_noalloc(int vA, OpndSize size, int imm);
+void set_VR_to_imm_noupdateref(LowOp* op, int vA, OpndSize size, int imm);
 void move_imm_to_reg(OpndSize size, int imm, int reg, bool isPhysical);
 void move_imm_to_reg_noalloc(OpndSize size, int imm, int reg, bool isPhysical);
 
 //LR[reg] = VR[vB]
 //or
 //PR[reg] = VR[vB]
-void get_virtual_reg(u2 vB, OpndSize size, int reg, bool isPhysical);
-void get_virtual_reg_noalloc(u2 vB, OpndSize size, int reg, bool isPhysical);
+void get_virtual_reg(int vB, OpndSize size, int reg, bool isPhysical);
+void get_virtual_reg_noalloc(int vB, OpndSize size, int reg, bool isPhysical);
 //VR[v] = LR[reg]
 //or
 //VR[v] = PR[reg]
-void set_virtual_reg(u2 vA, OpndSize size, int reg, bool isPhysical);
-void set_virtual_reg_noalloc(u2 vA, OpndSize size, int reg, bool isPhysical);
+void set_virtual_reg(int vA, OpndSize size, int reg, bool isPhysical);
+void set_virtual_reg_noalloc(int vA, OpndSize size, int reg, bool isPhysical);
 void get_VR_ss(int vB, int reg, bool isPhysical);
 void set_VR_ss(int vA, int reg, bool isPhysical);
 void get_VR_sd(int vB, int reg, bool isPhysical);
diff --git a/vm/compiler/codegen/x86/LowerAlu.cpp b/vm/compiler/codegen/x86/LowerAlu.cpp
index 678b521..326023c 100644
--- a/vm/compiler/codegen/x86/LowerAlu.cpp
+++ b/vm/compiler/codegen/x86/LowerAlu.cpp
@@ -34,8 +34,8 @@
  */
 int op_neg_int(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_NEG_INT);
-    u2 vA = mir->dalvikInsn.vA; //destination
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA; //destination
+    int vB = mir->dalvikInsn.vB;
     get_virtual_reg(vB, OpndSize_32, 1, false);
     alu_unary_reg(OpndSize_32, neg_opc, 1, false);
     set_virtual_reg(vA, OpndSize_32, 1, false);
@@ -49,8 +49,8 @@ int op_neg_int(const MIR * mir) {
  */
 int op_not_int(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_NOT_INT);
-    u2 vA = mir->dalvikInsn.vA; //destination
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA; //destination
+    int vB = mir->dalvikInsn.vB;
     get_virtual_reg(vB, OpndSize_32, 1, false);
     alu_unary_reg(OpndSize_32, not_opc, 1, false);
     set_virtual_reg(vA, OpndSize_32, 1, false);
@@ -66,8 +66,8 @@ int op_not_int(const MIR * mir) {
  */
 int op_neg_long(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_NEG_LONG);
-    u2 vA = mir->dalvikInsn.vA; //destination
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA; //destination
+    int vB = mir->dalvikInsn.vB;
     get_virtual_reg(vB, OpndSize_64, 1, false);
     alu_binary_reg_reg(OpndSize_64, xor_opc, 2, false, 2, false);
     alu_binary_reg_reg(OpndSize_64, sub_opc, 1, false, 2, false);
@@ -83,8 +83,8 @@ int op_neg_long(const MIR * mir) {
  */
 int op_not_long(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_NOT_LONG);
-    u2 vA = mir->dalvikInsn.vA; //destination
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA; //destination
+    int vB = mir->dalvikInsn.vB;
     get_virtual_reg(vB, OpndSize_64, 1, false);
     load_global_data_API("64bits", OpndSize_64, 2, false);
     alu_binary_reg_reg(OpndSize_64, andn_opc, 2, false, 1, false);
@@ -101,8 +101,8 @@ int op_not_long(const MIR * mir) {
  */
 int op_neg_float(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_NEG_FLOAT);
-    u2 vA = mir->dalvikInsn.vA; //destination
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA; //destination
+    int vB = mir->dalvikInsn.vB;
     get_virtual_reg(vB, OpndSize_32, 1, false);
     alu_binary_imm_reg(OpndSize_32, add_opc, 0x80000000, 1, false);
     set_virtual_reg(vA, OpndSize_32, 1, false);
@@ -118,8 +118,8 @@ int op_neg_float(const MIR * mir) {
  */
 int op_neg_double(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_NEG_DOUBLE);
-    u2 vA = mir->dalvikInsn.vA; //destination
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA; //destination
+    int vB = mir->dalvikInsn.vB;
     get_virtual_reg(vB, OpndSize_64, 1, false);
     load_global_data_API("doubNeg", OpndSize_64, 2, false);
     alu_binary_reg_reg(OpndSize_64, xor_opc, 2, false, 1, false);
@@ -135,8 +135,8 @@ int op_neg_double(const MIR * mir) {
  */
 int op_int_to_long(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_INT_TO_LONG);
-    u2 vA = mir->dalvikInsn.vA; //destination
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA; //destination
+    int vB = mir->dalvikInsn.vB;
     get_virtual_reg(vB, OpndSize_32, PhysicalReg_EAX, true);
     convert_integer(OpndSize_32, OpndSize_64);
     set_virtual_reg(vA, OpndSize_32, PhysicalReg_EAX, true);
@@ -152,8 +152,8 @@ int op_int_to_long(const MIR * mir) {
  */
 int op_int_to_float(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_INT_TO_FLOAT);
-    u2 vA = mir->dalvikInsn.vA; //destination
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA; //destination
+    int vB = mir->dalvikInsn.vB;
     load_int_fp_stack_VR(OpndSize_32, vB); //fildl
     store_fp_stack_VR(true, OpndSize_32, vA); //fstps
     return 0;
@@ -167,8 +167,8 @@ int op_int_to_float(const MIR * mir) {
  */
 int op_int_to_double(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_INT_TO_DOUBLE);
-    u2 vA = mir->dalvikInsn.vA; //destination
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA; //destination
+    int vB = mir->dalvikInsn.vB;
     get_virtual_reg(vB, OpndSize_32, 1, false);
     convert_int_to_fp(1, false, 2, false, true /* isDouble */);
     set_virtual_reg(vA, OpndSize_64, 2, false);
@@ -183,8 +183,8 @@ int op_int_to_double(const MIR * mir) {
  */
 int op_long_to_float(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_LONG_TO_FLOAT);
-    u2 vA = mir->dalvikInsn.vA; //destination
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA; //destination
+    int vB = mir->dalvikInsn.vB;
     load_int_fp_stack_VR(OpndSize_64, vB); //fildll
     store_fp_stack_VR(true, OpndSize_32, vA); //fstps
     return 0;
@@ -198,8 +198,8 @@ int op_long_to_float(const MIR * mir) {
  */
 int op_long_to_double(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_LONG_TO_DOUBLE);
-    u2 vA = mir->dalvikInsn.vA; //destination
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA; //destination
+    int vB = mir->dalvikInsn.vB;
     load_int_fp_stack_VR(OpndSize_64, vB); //fildll
     store_fp_stack_VR(true, OpndSize_64, vA); //fstpl
     return 0;
@@ -213,8 +213,8 @@ int op_long_to_double(const MIR * mir) {
  */
 int op_float_to_double(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_FLOAT_TO_DOUBLE);
-    u2 vA = mir->dalvikInsn.vA; //destination
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA; //destination
+    int vB = mir->dalvikInsn.vB;
     load_fp_stack_VR(OpndSize_32, vB); //flds
     store_fp_stack_VR(true, OpndSize_64, vA); //fstpl
     return 0;
@@ -228,8 +228,8 @@ int op_float_to_double(const MIR * mir) {
  */
 int op_double_to_float(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_DOUBLE_TO_FLOAT);
-    u2 vA = mir->dalvikInsn.vA; //destination
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA; //destination
+    int vB = mir->dalvikInsn.vB;
     load_fp_stack_VR(OpndSize_64, vB); //fldl
     store_fp_stack_VR(true, OpndSize_32, vA); //fstps
     return 0;
@@ -244,8 +244,8 @@ int op_double_to_float(const MIR * mir) {
  */
 int op_long_to_int(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_LONG_TO_INT);
-    u2 vA = mir->dalvikInsn.vA; //destination
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA; //destination
+    int vB = mir->dalvikInsn.vB;
     get_virtual_reg(vB, OpndSize_32, 1, false);
     set_virtual_reg(vA, OpndSize_32, 1, false);
     return 0;
@@ -255,7 +255,7 @@ int op_long_to_int(const MIR * mir) {
 //! common code to convert a float or double to integer
 
 //! It uses FP stack
-int common_fp_to_int(bool isDouble, u2 vA, u2 vB) {
+int common_fp_to_int(bool isDouble, int vA, int vB) {
     if(isDouble) {
         load_fp_stack_VR(OpndSize_64, vB); //fldl
     }
@@ -324,8 +324,8 @@ int common_fp_to_int(bool isDouble, u2 vA, u2 vB) {
  */
 int op_float_to_int(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_FLOAT_TO_INT);
-    u2 vA = mir->dalvikInsn.vA; //destination
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA; //destination
+    int vB = mir->dalvikInsn.vB;
     int retval = common_fp_to_int(false, vA, vB);
     return retval;
 }
@@ -337,8 +337,8 @@ int op_float_to_int(const MIR * mir) {
  */
 int op_double_to_int(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_DOUBLE_TO_INT);
-    u2 vA = mir->dalvikInsn.vA; //destination
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA; //destination
+    int vB = mir->dalvikInsn.vB;
     int retval = common_fp_to_int(true, vA, vB);
     return retval;
 }
@@ -346,7 +346,7 @@ int op_double_to_int(const MIR * mir) {
 //! common code to convert float or double to long
 
 //! It uses FP stack
-int common_fp_to_long(bool isDouble, u2 vA, u2 vB) {
+int common_fp_to_long(bool isDouble, int vA, int vB) {
     if(isDouble) {
         load_fp_stack_VR(OpndSize_64, vB); //fldl
     }
@@ -437,8 +437,8 @@ int common_fp_to_long(bool isDouble, u2 vA, u2 vB) {
  */
 int op_float_to_long(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_FLOAT_TO_LONG);
-    u2 vA = mir->dalvikInsn.vA; //destination
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA; //destination
+    int vB = mir->dalvikInsn.vB;
     int retval = common_fp_to_long(false, vA, vB);
     return retval;
 }
@@ -450,8 +450,8 @@ int op_float_to_long(const MIR * mir) {
  */
 int op_double_to_long(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_DOUBLE_TO_LONG);
-    u2 vA = mir->dalvikInsn.vA; //destination
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA; //destination
+    int vB = mir->dalvikInsn.vB;
     int retval = common_fp_to_long(true, vA, vB);
     return retval;
 }
@@ -465,8 +465,8 @@ int op_double_to_long(const MIR * mir) {
  */
 int op_int_to_byte(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_INT_TO_BYTE);
-    u2 vA = mir->dalvikInsn.vA; //destination
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA; //destination
+    int vB = mir->dalvikInsn.vB;
     get_virtual_reg(vB, OpndSize_32, 1, false);
     moves_reg_to_reg(OpndSize_8, 1, false, 1, false);
     set_virtual_reg(vA, OpndSize_32, 1, false);
@@ -481,8 +481,8 @@ int op_int_to_byte(const MIR * mir) {
  */
 int op_int_to_char(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_INT_TO_CHAR);
-    u2 vA = mir->dalvikInsn.vA; //destination
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA; //destination
+    int vB = mir->dalvikInsn.vB;
     get_virtual_reg(vB, OpndSize_32, 1, false);
     alu_binary_imm_reg(OpndSize_32, sal_opc, 16, 1, false);
     alu_binary_imm_reg(OpndSize_32, shr_opc, 16, 1, false);
@@ -498,8 +498,8 @@ int op_int_to_char(const MIR * mir) {
  */
 int op_int_to_short(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_INT_TO_SHORT);
-    u2 vA = mir->dalvikInsn.vA; //destination
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA; //destination
+    int vB = mir->dalvikInsn.vB;
     get_virtual_reg(vB, OpndSize_32, 1, false);
     moves_reg_to_reg(OpndSize_16, 1, false, 1, false);
     set_virtual_reg(vA, OpndSize_32, 1, false);
@@ -508,7 +508,7 @@ int op_int_to_short(const MIR * mir) {
 //! common code to handle integer ALU ops
 
 //! It uses GPR
-int common_alu_int(ALU_Opcode opc, u2 vA, u2 v1, u2 v2) { //except div and rem
+int common_alu_int(ALU_Opcode opc, int vA, int v1, int v2) { //except div and rem
     get_virtual_reg(v1, OpndSize_32, 1, false);
     //in encoder, reg is first operand, which is the destination
     //gpr_1 op v2(rFP) --> gpr_1
@@ -522,7 +522,7 @@ int common_alu_int(ALU_Opcode opc, u2 vA, u2 v1, u2 v2) { //except div and rem
 //! common code to handle integer shift ops
 
 //! It uses GPR
-int common_shift_int(ALU_Opcode opc, u2 vA, u2 v1, u2 v2) {
+int common_shift_int(ALU_Opcode opc, int vA, int v1, int v2) {
     get_virtual_reg(v2, OpndSize_32, PhysicalReg_ECX, true);
     get_virtual_reg(v1, OpndSize_32, 1, false);
     //in encoder, reg2 is first operand, which is the destination
@@ -541,7 +541,7 @@ int common_shift_int(ALU_Opcode opc, u2 vA, u2 v1, u2 v2) {
  */
 int op_add_int(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_ADD_INT);
-    u2 vA, v1, v2;
+    int vA, v1, v2;
     vA = mir->dalvikInsn.vA;
     v1 = mir->dalvikInsn.vB;
     v2 = mir->dalvikInsn.vC;
@@ -556,7 +556,7 @@ int op_add_int(const MIR * mir) {
  */
 int op_sub_int(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_SUB_INT);
-    u2 vA, v1, v2;
+    int vA, v1, v2;
     vA = mir->dalvikInsn.vA;
     v1 = mir->dalvikInsn.vB;
     v2 = mir->dalvikInsn.vC;
@@ -571,7 +571,7 @@ int op_sub_int(const MIR * mir) {
  */
 int op_mul_int(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_MUL_INT);
-    u2 vA, v1, v2;
+    int vA, v1, v2;
     vA = mir->dalvikInsn.vA;
     v1 = mir->dalvikInsn.vB;
     v2 = mir->dalvikInsn.vC;
@@ -586,7 +586,7 @@ int op_mul_int(const MIR * mir) {
  */
 int op_and_int(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_AND_INT);
-    u2 vA, v1, v2;
+    int vA, v1, v2;
     vA = mir->dalvikInsn.vA;
     v1 = mir->dalvikInsn.vB;
     v2 = mir->dalvikInsn.vC;
@@ -601,7 +601,7 @@ int op_and_int(const MIR * mir) {
  */
 int op_or_int(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_OR_INT);
-    u2 vA, v1, v2;
+    int vA, v1, v2;
     vA = mir->dalvikInsn.vA;
     v1 = mir->dalvikInsn.vB;
     v2 = mir->dalvikInsn.vC;
@@ -616,7 +616,7 @@ int op_or_int(const MIR * mir) {
  */
 int op_xor_int(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_XOR_INT);
-    u2 vA, v1, v2;
+    int vA, v1, v2;
     vA = mir->dalvikInsn.vA;
     v1 = mir->dalvikInsn.vB;
     v2 = mir->dalvikInsn.vC;
@@ -631,7 +631,7 @@ int op_xor_int(const MIR * mir) {
  */
 int op_shl_int(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_SHL_INT);
-    u2 vA, v1, v2;
+    int vA, v1, v2;
     vA = mir->dalvikInsn.vA;
     v1 = mir->dalvikInsn.vB;
     v2 = mir->dalvikInsn.vC;
@@ -646,7 +646,7 @@ int op_shl_int(const MIR * mir) {
  */
 int op_shr_int(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_SHR_INT);
-    u2 vA, v1, v2;
+    int vA, v1, v2;
     vA = mir->dalvikInsn.vA;
     v1 = mir->dalvikInsn.vB;
     v2 = mir->dalvikInsn.vC;
@@ -661,7 +661,7 @@ int op_shr_int(const MIR * mir) {
  */
 int op_ushr_int(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_USHR_INT);
-    u2 vA, v1, v2;
+    int vA, v1, v2;
     vA = mir->dalvikInsn.vA;
     v1 = mir->dalvikInsn.vB;
     v2 = mir->dalvikInsn.vC;
@@ -676,7 +676,7 @@ int op_ushr_int(const MIR * mir) {
  */
 int op_add_int_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_ADD_INT_2ADDR);
-    u2 vA, v1, v2;
+    int vA, v1, v2;
     vA = mir->dalvikInsn.vA;
     v1 = vA;
     v2 = mir->dalvikInsn.vB;
@@ -691,7 +691,7 @@ int op_add_int_2addr(const MIR * mir) {
  */
 int op_sub_int_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_SUB_INT_2ADDR);
-    u2 vA, v1, v2;
+    int vA, v1, v2;
     vA = mir->dalvikInsn.vA;
     v1 = vA;
     v2 = mir->dalvikInsn.vB;
@@ -706,7 +706,7 @@ int op_sub_int_2addr(const MIR * mir) {
  */
 int op_mul_int_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_MUL_INT_2ADDR);
-    u2 vA, v1, v2;
+    int vA, v1, v2;
     vA = mir->dalvikInsn.vA;
     v1 = vA;
     v2 = mir->dalvikInsn.vB;
@@ -721,7 +721,7 @@ int op_mul_int_2addr(const MIR * mir) {
  */
 int op_and_int_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_AND_INT_2ADDR);
-    u2 vA, v1, v2;
+    int vA, v1, v2;
     vA = mir->dalvikInsn.vA;
     v1 = vA;
     v2 = mir->dalvikInsn.vB;
@@ -736,7 +736,7 @@ int op_and_int_2addr(const MIR * mir) {
  */
 int op_or_int_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_OR_INT_2ADDR);
-    u2 vA, v1, v2;
+    int vA, v1, v2;
     vA = mir->dalvikInsn.vA;
     v1 = vA;
     v2 = mir->dalvikInsn.vB;
@@ -751,7 +751,7 @@ int op_or_int_2addr(const MIR * mir) {
  */
 int op_xor_int_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_XOR_INT_2ADDR);
-    u2 vA, v1, v2;
+    int vA, v1, v2;
     vA = mir->dalvikInsn.vA;
     v1 = vA;
     v2 = mir->dalvikInsn.vB;
@@ -766,7 +766,7 @@ int op_xor_int_2addr(const MIR * mir) {
  */
 int op_shl_int_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_SHL_INT_2ADDR);
-    u2 vA, v1, v2;
+    int vA, v1, v2;
     vA = mir->dalvikInsn.vA;
     v1 = vA;
     v2 = mir->dalvikInsn.vB;
@@ -781,7 +781,7 @@ int op_shl_int_2addr(const MIR * mir) {
  */
 int op_shr_int_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_SHR_INT_2ADDR);
-    u2 vA, v1, v2;
+    int vA, v1, v2;
     vA = mir->dalvikInsn.vA;
     v1 = vA;
     v2 = mir->dalvikInsn.vB;
@@ -796,7 +796,7 @@ int op_shr_int_2addr(const MIR * mir) {
  */
 int op_ushr_int_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_USHR_INT_2ADDR);
-    u2 vA, v1, v2;
+    int vA, v1, v2;
     vA = mir->dalvikInsn.vA;
     v1 = vA;
     v2 = mir->dalvikInsn.vB;
@@ -810,7 +810,7 @@ int op_ushr_int_2addr(const MIR * mir) {
 //!The special case: when op0 == minint && op1 == -1, return 0 for isRem, return 0x80000000 for isDiv
 //!There are four merge points in the control flow for this bytecode
 //!make sure the reg. alloc. state is the same at merge points by calling transferToState
-int common_div_rem_int(bool isRem, u2 vA, u2 v1, u2 v2) {
+int common_div_rem_int(bool isRem, int vA, int v1, int v2) {
     get_virtual_reg(v1, OpndSize_32, PhysicalReg_EAX, true);
     get_virtual_reg(v2, OpndSize_32, 2, false);
     compare_imm_reg(OpndSize_32, 0, 2, false);
@@ -915,7 +915,7 @@ int common_div_rem_int(bool isRem, u2 vA, u2 v1, u2 v2) {
  */
 int op_div_int(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_DIV_INT);
-    u2 vA, v1, v2;
+    int vA, v1, v2;
     vA = mir->dalvikInsn.vA;
     v1 = mir->dalvikInsn.vB;
     v2 = mir->dalvikInsn.vC;
@@ -930,7 +930,7 @@ int op_div_int(const MIR * mir) {
  */
 int op_rem_int(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_REM_INT);
-    u2 vA, v1, v2;
+    int vA, v1, v2;
     vA = mir->dalvikInsn.vA;
     v1 = mir->dalvikInsn.vB;
     v2 = mir->dalvikInsn.vC;
@@ -945,9 +945,9 @@ int op_rem_int(const MIR * mir) {
  */
 int op_div_int_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_DIV_INT_2ADDR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = vA;
-    u2 v2 = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = vA;
+    int v2 = mir->dalvikInsn.vB;
     int retval = common_div_rem_int(false, vA, v1, v2);
     return retval;
 }
@@ -959,9 +959,9 @@ int op_div_int_2addr(const MIR * mir) {
  */
 int op_rem_int_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_REM_INT_2ADDR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = vA;
-    u2 v2 = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = vA;
+    int v2 = mir->dalvikInsn.vB;
     int retval = common_div_rem_int(true, vA, v1, v2);
     return retval;
 }
@@ -975,7 +975,7 @@ int op_rem_int_2addr(const MIR * mir) {
  * @param imm The literal value
  * @return value >= 0 when handled
  */
-int common_alu_int_lit(ALU_Opcode opc, u2 vA, u2 vB, s2 imm) { //except div and rem
+int common_alu_int_lit(ALU_Opcode opc, int vA, int vB, s2 imm) { //except div and rem
     // For add and sub, try if we can operate directly on VRs
     if ((opc == add_opc) || (opc == sub_opc)) {
         bool success = alu_imm_to_VR(OpndSize_32, opc, vB, vA, imm, 1, false);
@@ -992,7 +992,7 @@ int common_alu_int_lit(ALU_Opcode opc, u2 vA, u2 vB, s2 imm) { //except div and
     return 0;
 }
 //! calls common_alu_int_lit
-int common_shift_int_lit(ALU_Opcode opc, u2 vA, u2 vB, s2 imm) {
+int common_shift_int_lit(ALU_Opcode opc, int vA, int vB, s2 imm) {
     return common_alu_int_lit(opc, vA, vB, imm);
 }
 #undef p_GPR_1
@@ -1004,14 +1004,14 @@ int common_shift_int_lit(ALU_Opcode opc, u2 vA, u2 vB, s2 imm) {
  */
 int op_add_int_lit16(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_ADD_INT_LIT16);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 literal = mir->dalvikInsn.vC;
     int retval = common_alu_int_lit(add_opc, vA, vB, literal);
     return retval;
 }
 
-int alu_rsub_int(ALU_Opcode opc, u2 vA, s2 imm, u2 vB) {
+int alu_rsub_int(ALU_Opcode opc, int vA, s2 imm, int vB) {
     move_imm_to_reg(OpndSize_32, imm, 2, false);
     get_virtual_reg(vB, OpndSize_32, 1, false);
     alu_binary_reg_reg(OpndSize_32, opc, 1, false, 2, false);
@@ -1026,8 +1026,8 @@ int alu_rsub_int(ALU_Opcode opc, u2 vA, s2 imm, u2 vB) {
  */
 int op_rsub_int(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_RSUB_INT);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 literal = mir->dalvikInsn.vC;
     int retval = alu_rsub_int(sub_opc, vA, literal, vB);
     return retval;
@@ -1040,8 +1040,8 @@ int op_rsub_int(const MIR * mir) {
  */
 int op_mul_int_lit16(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_MUL_INT_LIT16);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 literal = mir->dalvikInsn.vC;
     int retval = common_alu_int_lit(imul_opc, vA, vB, literal);
     return retval;
@@ -1054,8 +1054,8 @@ int op_mul_int_lit16(const MIR * mir) {
  */
 int op_and_int_lit16(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_AND_INT_LIT16);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 literal = mir->dalvikInsn.vC;
     int retval = common_alu_int_lit(and_opc, vA, vB, literal);
     return retval;
@@ -1068,8 +1068,8 @@ int op_and_int_lit16(const MIR * mir) {
  */
 int op_or_int_lit16(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_OR_INT_LIT16);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 literal = mir->dalvikInsn.vC;
     int retval = common_alu_int_lit(or_opc, vA, vB, literal);
     return retval;
@@ -1082,8 +1082,8 @@ int op_or_int_lit16(const MIR * mir) {
  */
 int op_xor_int_lit16(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_XOR_INT_LIT16);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 literal = mir->dalvikInsn.vC;
     int retval = common_alu_int_lit(xor_opc, vA, vB, literal);
     return retval;
@@ -1096,8 +1096,8 @@ int op_xor_int_lit16(const MIR * mir) {
  */
 int op_add_int_lit8(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_ADD_INT_LIT8);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 literal = mir->dalvikInsn.vC;
     int retval = common_alu_int_lit(add_opc, vA, vB, literal);
     return retval;
@@ -1110,8 +1110,8 @@ int op_add_int_lit8(const MIR * mir) {
  */
 int op_rsub_int_lit8(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_RSUB_INT_LIT8);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 literal = mir->dalvikInsn.vC;
     int retval = alu_rsub_int(sub_opc, vA, literal, vB);
     return retval;
@@ -1124,8 +1124,8 @@ int op_rsub_int_lit8(const MIR * mir) {
  */
 int op_mul_int_lit8(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_MUL_INT_LIT8);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 literal = mir->dalvikInsn.vC;
     int retval = common_alu_int_lit(imul_opc, vA, vB, literal);
     return retval;
@@ -1138,8 +1138,8 @@ int op_mul_int_lit8(const MIR * mir) {
  */
 int op_and_int_lit8(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_AND_INT_LIT8);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 literal = mir->dalvikInsn.vC;
     int retval = common_alu_int_lit(and_opc, vA, vB, literal);
     return retval;
@@ -1152,8 +1152,8 @@ int op_and_int_lit8(const MIR * mir) {
  */
 int op_or_int_lit8(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_OR_INT_LIT8);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 literal = mir->dalvikInsn.vC;
     int retval = common_alu_int_lit(or_opc, vA, vB, literal);
     return retval;
@@ -1166,8 +1166,8 @@ int op_or_int_lit8(const MIR * mir) {
  */
 int op_xor_int_lit8(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_XOR_INT_LIT8);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 literal = mir->dalvikInsn.vC;
     int retval = common_alu_int_lit(xor_opc, vA, vB, literal);
     return retval;
@@ -1180,8 +1180,8 @@ int op_xor_int_lit8(const MIR * mir) {
  */
 int op_shl_int_lit8(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_SHL_INT_LIT8);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 literal = mir->dalvikInsn.vC;
     int retval = common_shift_int_lit(shl_opc, vA, vB, literal);
     return retval;
@@ -1194,8 +1194,8 @@ int op_shl_int_lit8(const MIR * mir) {
  */
 int op_shr_int_lit8(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_SHR_INT_LIT8);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 literal = mir->dalvikInsn.vC;
     int retval = common_shift_int_lit(sar_opc, vA, vB, literal);
     return retval;
@@ -1208,8 +1208,8 @@ int op_shr_int_lit8(const MIR * mir) {
  */
 int op_ushr_int_lit8(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_USHR_INT_LIT8);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 literal = mir->dalvikInsn.vC;
     int retval = common_shift_int_lit(shr_opc, vA, vB, literal);
     return retval;
@@ -1224,7 +1224,7 @@ int isPowerOfTwo(int imm) {
 }
 
 #define P_GPR_1 PhysicalReg_EBX
-int div_lit_strength_reduction(u2 vA, u2 vB, s2 imm) {
+int div_lit_strength_reduction(int vA, int vB, s2 imm) {
     if(gDvm.executionMode == kExecutionModeNcgO1) {
         //strength reduction for div by 2,4,8,...
         int power = isPowerOfTwo(imm);
@@ -1265,7 +1265,7 @@ int div_lit_strength_reduction(u2 vA, u2 vB, s2 imm) {
 //! common code to handle integer DIV & REM with literal
 
 //! It uses GPR
-int common_div_rem_int_lit(bool isRem, u2 vA, u2 vB, s2 imm) {
+int common_div_rem_int_lit(bool isRem, int vA, int vB, s2 imm) {
     if(!isRem) {
         int retCode = div_lit_strength_reduction(vA, vB, imm);
         if(retCode > 0) return 0;
@@ -1324,8 +1324,8 @@ int common_div_rem_int_lit(bool isRem, u2 vA, u2 vB, s2 imm) {
  */
 int op_div_int_lit16(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_DIV_INT_LIT16);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 literal = mir->dalvikInsn.vC;
     int retval = common_div_rem_int_lit(false, vA, vB, literal);
     return retval;
@@ -1338,8 +1338,8 @@ int op_div_int_lit16(const MIR * mir) {
  */
 int op_rem_int_lit16(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_REM_INT_LIT16);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 literal = mir->dalvikInsn.vC;
     int retval = common_div_rem_int_lit(true, vA, vB, literal);
     return retval;
@@ -1352,8 +1352,8 @@ int op_rem_int_lit16(const MIR * mir) {
  */
 int op_div_int_lit8(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_DIV_INT_LIT8);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 literal = mir->dalvikInsn.vC;
     int retval = common_div_rem_int_lit(false, vA, vB, literal);
     return retval;
@@ -1366,8 +1366,8 @@ int op_div_int_lit8(const MIR * mir) {
  */
 int op_rem_int_lit8(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_REM_INT_LIT8);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 literal = mir->dalvikInsn.vC;
     int retval = common_div_rem_int_lit(true, vA, vB, literal);
     return retval;
@@ -1375,7 +1375,7 @@ int op_rem_int_lit8(const MIR * mir) {
 //! common code to hanle long ALU ops
 
 //! It uses XMM
-int common_alu_long(ALU_Opcode opc, u2 vA, u2 v1, u2 v2) { //except div and rem
+int common_alu_long(ALU_Opcode opc, int vA, int v1, int v2) { //except div and rem
     get_virtual_reg(v1, OpndSize_64, 1, false);
     get_virtual_reg(v2, OpndSize_64, 2, false);
     alu_binary_reg_reg(OpndSize_64, opc, 2, false, 1, false);
@@ -1384,7 +1384,7 @@ int common_alu_long(ALU_Opcode opc, u2 vA, u2 v1, u2 v2) { //except div and rem
 }
 
 //! Use general purpose registers during the lowering for add-long and add-long/2addr
-int common_add_long(u2 vA, u2 v1, u2 v2) {
+int common_add_long(int vA, int v1, int v2) {
     get_virtual_reg(v1, OpndSize_32, 1, false);
     get_virtual_reg(v1+1, OpndSize_32, 2, false);
     alu_binary_VR_reg(OpndSize_32, add_opc, v2, 1, false);
@@ -1401,9 +1401,9 @@ int common_add_long(u2 vA, u2 v1, u2 v2) {
  */
 int op_add_long(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_ADD_LONG);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = mir->dalvikInsn.vB;
-    u2 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     int retval = common_add_long(vA, v1, v2);
     return retval;
 }
@@ -1415,9 +1415,9 @@ int op_add_long(const MIR * mir) {
  */
 int op_sub_long(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_SUB_LONG);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = mir->dalvikInsn.vB;
-    u2 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     int retval = common_alu_long(sub_opc, vA, v1, v2);
     return retval;
 }
@@ -1429,9 +1429,9 @@ int op_sub_long(const MIR * mir) {
  */
 int op_and_long(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_AND_LONG);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = mir->dalvikInsn.vB;
-    u2 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     int retval = common_alu_long(and_opc, vA, v1, v2);
     return retval;
 }
@@ -1443,9 +1443,9 @@ int op_and_long(const MIR * mir) {
  */
 int op_or_long(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_OR_LONG);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = mir->dalvikInsn.vB;
-    u2 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     int retval = common_alu_long(or_opc, vA, v1, v2);
     return retval;
 }
@@ -1457,9 +1457,9 @@ int op_or_long(const MIR * mir) {
  */
 int op_xor_long(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_XOR_LONG);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = mir->dalvikInsn.vB;
-    u2 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     int retval = common_alu_long(xor_opc, vA, v1, v2);
     return retval;
 }
@@ -1471,9 +1471,9 @@ int op_xor_long(const MIR * mir) {
  */
 int op_add_long_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_ADD_LONG_2ADDR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = vA;
-    u2 v2 = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = vA;
+    int v2 = mir->dalvikInsn.vB;
     int retval = common_add_long(vA, v1, v2);
     return retval;
 }
@@ -1485,9 +1485,9 @@ int op_add_long_2addr(const MIR * mir) {
  */
 int op_sub_long_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_SUB_LONG_2ADDR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = vA;
-    u2 v2 = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = vA;
+    int v2 = mir->dalvikInsn.vB;
     int retval = common_alu_long(sub_opc, vA, v1, v2);
     return retval;
 }
@@ -1499,9 +1499,9 @@ int op_sub_long_2addr(const MIR * mir) {
  */
 int op_and_long_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_AND_LONG_2ADDR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = vA;
-    u2 v2 = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = vA;
+    int v2 = mir->dalvikInsn.vB;
     int retval = common_alu_long(and_opc, vA, v1, v2);
     return retval;
 }
@@ -1513,9 +1513,9 @@ int op_and_long_2addr(const MIR * mir) {
  */
 int op_or_long_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_OR_LONG_2ADDR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = vA;
-    u2 v2 = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = vA;
+    int v2 = mir->dalvikInsn.vB;
     int retval = common_alu_long(or_opc, vA, v1, v2);
     return retval;
 }
@@ -1527,9 +1527,9 @@ int op_or_long_2addr(const MIR * mir) {
  */
 int op_xor_long_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_XOR_LONG_2ADDR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = vA;
-    u2 v2 = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = vA;
+    int v2 = mir->dalvikInsn.vB;
     int retval = common_alu_long(xor_opc, vA, v1, v2);
     return retval;
 }
@@ -1538,7 +1538,7 @@ int op_xor_long_2addr(const MIR * mir) {
 //! common code to handle multiplication of long
 
 //! It uses GPR
-int common_mul_long(u2 vA, u2 v1, u2 v2) {
+int common_mul_long(int vA, int v1, int v2) {
     get_virtual_reg(v2, OpndSize_32, 1, false);
     move_reg_to_reg(OpndSize_32, 1, false, PhysicalReg_EAX, true);
     //imul: 2L * 1H update temporary 1
@@ -1558,7 +1558,7 @@ int common_mul_long(u2 vA, u2 v1, u2 v2) {
 //! common code to handle multiplication when multiplicands of long type are the same
 
 //! It uses GPR
-int common_mul_long_square(u2 vA, u2 v1) {
+int common_mul_long_square(int vA, int v1) {
     get_virtual_reg(v1, OpndSize_32, 1, false);
     move_reg_to_reg(OpndSize_32, 1, false, PhysicalReg_EAX, true);
     move_reg_to_reg(OpndSize_32,1, false, PhysicalReg_EDX, true);
@@ -1581,9 +1581,9 @@ int common_mul_long_square(u2 vA, u2 v1) {
  */
 int op_mul_long(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_MUL_LONG);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = mir->dalvikInsn.vB;
-    u2 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     int retval;
     if (v1 != v2){
       retval = common_mul_long(vA, v1, v2);
@@ -1602,9 +1602,9 @@ int op_mul_long(const MIR * mir) {
  */
 int op_mul_long_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_MUL_LONG_2ADDR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = vA;
-    u2 v2 = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = vA;
+    int v2 = mir->dalvikInsn.vB;
     int retval;
     if (v1 != v2){
       retval = common_mul_long(vA, v1, v2);
@@ -1620,7 +1620,7 @@ int op_mul_long_2addr(const MIR * mir) {
 //! common code to handle DIV & REM of long
 
 //! It uses GPR & XMM; and calls call_moddi3 & call_divdi3
-int common_div_rem_long(bool isRem, u2 vA, u2 v1, u2 v2) {
+int common_div_rem_long(bool isRem, int vA, int v1, int v2) {
     get_virtual_reg(v2, OpndSize_32, 1, false);
     get_virtual_reg(v2+1, OpndSize_32, 2, false);
     //save to native stack before changing register P_GPR_1
@@ -1655,9 +1655,9 @@ int common_div_rem_long(bool isRem, u2 vA, u2 v1, u2 v2) {
  */
 int op_div_long(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_DIV_LONG);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = mir->dalvikInsn.vB;
-    u2 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     int retval = common_div_rem_long(false, vA, v1, v2);
     return retval;
 }
@@ -1669,9 +1669,9 @@ int op_div_long(const MIR * mir) {
  */
 int op_rem_long(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_REM_LONG);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = mir->dalvikInsn.vB;
-    u2 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     int retval = common_div_rem_long(true, vA, v1, v2);
     return retval;
 }
@@ -1683,9 +1683,9 @@ int op_rem_long(const MIR * mir) {
  */
 int op_div_long_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_DIV_LONG_2ADDR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = vA;
-    u2 v2 = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = vA;
+    int v2 = mir->dalvikInsn.vB;
     int retval = common_div_rem_long(false, vA, v1, v2);
     return retval;
 }
@@ -1697,9 +1697,9 @@ int op_div_long_2addr(const MIR * mir) {
  */
 int op_rem_long_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_REM_LONG_2ADDR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = vA;
-    u2 v2 = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = vA;
+    int v2 = mir->dalvikInsn.vB;
     int retval = common_div_rem_long(true, vA, v1, v2);
     return retval;
 }
@@ -1707,7 +1707,7 @@ int op_rem_long_2addr(const MIR * mir) {
 //! common code to handle SHL long
 
 //! It uses XMM
-int common_shl_long(u2 vA, u2 v1, u2 v2) {
+int common_shl_long(int vA, int v1, int v2) {
     get_VR_ss(v2, 2, false);
     get_virtual_reg(v1, OpndSize_64, 1, false);
 
@@ -1728,7 +1728,7 @@ int common_shl_long(u2 vA, u2 v1, u2 v2) {
 //! common code to handle SHR long
 
 //! It uses XMM
-int common_shr_long(u2 vA, u2 v1, u2 v2) {
+int common_shr_long(int vA, int v1, int v2) {
     get_VR_ss(v2, 2, false);
 
     load_global_data_API("shiftMask", OpndSize_64, 3, false);
@@ -1765,7 +1765,7 @@ int common_shr_long(u2 vA, u2 v1, u2 v2) {
 //! common code to handle USHR long
 
 //! It uses XMM
-int common_ushr_long(u2 vA, u2 v1, u2 v2) {
+int common_ushr_long(int vA, int v1, int v2) {
     get_VR_sd(v1, 1, false);
     get_VR_ss(v2, 2, false);
 
@@ -1790,9 +1790,9 @@ int common_ushr_long(u2 vA, u2 v1, u2 v2) {
  */
 int op_shl_long(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_SHL_LONG);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = mir->dalvikInsn.vB;
-    u2 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     int retval = common_shl_long(vA, v1, v2);
     return retval;
 }
@@ -1804,9 +1804,9 @@ int op_shl_long(const MIR * mir) {
  */
 int op_shl_long_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_SHL_LONG_2ADDR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = vA;
-    u2 v2 = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = vA;
+    int v2 = mir->dalvikInsn.vB;
     int retval = common_shl_long(vA, v1, v2);
     return retval;
 }
@@ -1818,9 +1818,9 @@ int op_shl_long_2addr(const MIR * mir) {
  */
 int op_shr_long(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_SHR_LONG);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = mir->dalvikInsn.vB;
-    u2 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     int retval = common_shr_long(vA, v1, v2);
     return retval;
 }
@@ -1832,9 +1832,9 @@ int op_shr_long(const MIR * mir) {
  */
 int op_shr_long_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_SHR_LONG_2ADDR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = vA;
-    u2 v2 = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = vA;
+    int v2 = mir->dalvikInsn.vB;
     int retval = common_shr_long(vA, v1, v2);
     return retval;
 }
@@ -1846,9 +1846,9 @@ int op_shr_long_2addr(const MIR * mir) {
  */
 int op_ushr_long(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_USHR_LONG);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = mir->dalvikInsn.vB;
-    u2 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     int retval = common_ushr_long(vA, v1, v2);
     return retval;
 }
@@ -1860,9 +1860,9 @@ int op_ushr_long(const MIR * mir) {
  */
 int op_ushr_long_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_USHR_LONG_2ADDR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = vA;
-    u2 v2 = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = vA;
+    int v2 = mir->dalvikInsn.vB;
     int retval = common_ushr_long(vA, v1, v2);
     return retval;
 }
@@ -1871,7 +1871,7 @@ int op_ushr_long_2addr(const MIR * mir) {
 //! common code to handle ALU of floats
 
 //! It uses XMM
-int common_alu_float(ALU_Opcode opc, u2 vA, u2 v1, u2 v2) {//add, sub, mul
+int common_alu_float(ALU_Opcode opc, int vA, int v1, int v2) {//add, sub, mul
     get_VR_ss(v1, 1, false);
 #ifdef USE_MEM_OPERAND
     alu_sd_binary_VR_reg(opc, v2, 1, false, false/*isSD*/);
@@ -1890,9 +1890,9 @@ int common_alu_float(ALU_Opcode opc, u2 vA, u2 v1, u2 v2) {//add, sub, mul
  */
 int op_add_float(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_ADD_FLOAT);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = mir->dalvikInsn.vB;
-    u2 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     int retval = common_alu_float(add_opc, vA, v1, v2);
     return retval;
 }
@@ -1904,9 +1904,9 @@ int op_add_float(const MIR * mir) {
  */
 int op_sub_float(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_SUB_FLOAT);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = mir->dalvikInsn.vB;
-    u2 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     int retval = common_alu_float(sub_opc, vA, v1, v2);
     return retval;
 }
@@ -1918,9 +1918,9 @@ int op_sub_float(const MIR * mir) {
  */
 int op_mul_float(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_MUL_FLOAT);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = mir->dalvikInsn.vB;
-    u2 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     int retval = common_alu_float(mul_opc, vA, v1, v2);
     return retval;
 }
@@ -1932,9 +1932,9 @@ int op_mul_float(const MIR * mir) {
  */
 int op_add_float_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_ADD_FLOAT_2ADDR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = vA;
-    u2 v2 = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = vA;
+    int v2 = mir->dalvikInsn.vB;
     int retval = common_alu_float(add_opc, vA, v1, v2);
     return retval;
 }
@@ -1946,9 +1946,9 @@ int op_add_float_2addr(const MIR * mir) {
  */
 int op_sub_float_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_SUB_FLOAT_2ADDR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = vA;
-    u2 v2 = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = vA;
+    int v2 = mir->dalvikInsn.vB;
     int retval = common_alu_float(sub_opc, vA, v1, v2);
     return retval;
 }
@@ -1960,16 +1960,16 @@ int op_sub_float_2addr(const MIR * mir) {
  */
 int op_mul_float_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_MUL_FLOAT_2ADDR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = vA;
-    u2 v2 = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = vA;
+    int v2 = mir->dalvikInsn.vB;
     int retval = common_alu_float(mul_opc, vA, v1, v2);
     return retval;
 }
 //! common code to handle DIV of float
 
 //! It uses FP stack
-int common_div_float(u2 vA, u2 v1, u2 v2) {
+int common_div_float(int vA, int v1, int v2) {
     load_fp_stack_VR(OpndSize_32, v1); //flds
     fpu_VR(div_opc, OpndSize_32, v2);
     store_fp_stack_VR(true, OpndSize_32, vA); //fstps
@@ -1983,9 +1983,9 @@ int common_div_float(u2 vA, u2 v1, u2 v2) {
  */
 int op_div_float(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_DIV_FLOAT);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = mir->dalvikInsn.vB;
-    u2 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     int retval = common_alu_float(div_opc, vA, v1, v2);
     return retval;
 }
@@ -1997,16 +1997,16 @@ int op_div_float(const MIR * mir) {
  */
 int op_div_float_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_DIV_FLOAT_2ADDR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = vA;
-    u2 v2 = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = vA;
+    int v2 = mir->dalvikInsn.vB;
     int retval = common_alu_float(div_opc, vA, v1, v2);
     return retval;
 }
 //! common code to handle DIV of double
 
 //! It uses XMM
-int common_alu_double(ALU_Opcode opc, u2 vA, u2 v1, u2 v2) {//add, sub, mul
+int common_alu_double(ALU_Opcode opc, int vA, int v1, int v2) {//add, sub, mul
     get_VR_sd(v1, 1, false);
 #ifdef USE_MEM_OPERAND
     alu_sd_binary_VR_reg(opc, v2, 1, false, true /*isSD*/);
@@ -2025,9 +2025,9 @@ int common_alu_double(ALU_Opcode opc, u2 vA, u2 v1, u2 v2) {//add, sub, mul
  */
 int op_add_double(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_ADD_DOUBLE);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = mir->dalvikInsn.vB;
-    u2 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     int retval = common_alu_double(add_opc, vA, v1, v2);
     return retval;
 }
@@ -2039,9 +2039,9 @@ int op_add_double(const MIR * mir) {
  */
 int op_sub_double(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_SUB_DOUBLE);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = mir->dalvikInsn.vB;
-    u2 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     int retval = common_alu_double(sub_opc, vA, v1, v2);
     return retval;
 }
@@ -2053,9 +2053,9 @@ int op_sub_double(const MIR * mir) {
  */
 int op_mul_double(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_MUL_DOUBLE);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = mir->dalvikInsn.vB;
-    u2 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     int retval = common_alu_double(mul_opc, vA, v1, v2);
     return retval;
 }
@@ -2067,9 +2067,9 @@ int op_mul_double(const MIR * mir) {
  */
 int op_add_double_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_ADD_DOUBLE_2ADDR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = vA;
-    u2 v2 = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = vA;
+    int v2 = mir->dalvikInsn.vB;
     int retval = common_alu_double(add_opc, vA, v1, v2);
     return retval;
 }
@@ -2081,9 +2081,9 @@ int op_add_double_2addr(const MIR * mir) {
  */
 int op_sub_double_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_SUB_DOUBLE_2ADDR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = vA;
-    u2 v2 = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = vA;
+    int v2 = mir->dalvikInsn.vB;
     int retval = common_alu_double(sub_opc, vA, v1, v2);
     return retval;
 }
@@ -2095,16 +2095,16 @@ int op_sub_double_2addr(const MIR * mir) {
  */
 int op_mul_double_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_MUL_DOUBLE_2ADDR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = vA;
-    u2 v2 = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = vA;
+    int v2 = mir->dalvikInsn.vB;
     int retval = common_alu_double(mul_opc, vA, v1, v2);
     return retval;
 }
 //! common code to handle DIV of double
 
 //! It uses FP stack
-int common_div_double(u2 vA, u2 v1, u2 v2) {
+int common_div_double(int vA, int v1, int v2) {
     load_fp_stack_VR(OpndSize_64, v1); //fldl
     fpu_VR(div_opc, OpndSize_64, v2); //fdivl
     store_fp_stack_VR(true, OpndSize_64, vA); //fstpl
@@ -2118,9 +2118,9 @@ int common_div_double(u2 vA, u2 v1, u2 v2) {
  */
 int op_div_double(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_DIV_DOUBLE);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = mir->dalvikInsn.vB;
-    u2 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     int retval = common_alu_double(div_opc, vA, v1, v2);
     return retval;
 }
@@ -2132,9 +2132,9 @@ int op_div_double(const MIR * mir) {
  */
 int op_div_double_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_DIV_DOUBLE_2ADDR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = vA;
-    u2 v2 = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = vA;
+    int v2 = mir->dalvikInsn.vB;
     int retval = common_alu_double(div_opc, vA, v1, v2);
     return retval;
 }
@@ -2143,7 +2143,7 @@ int op_div_double_2addr(const MIR * mir) {
 //! common code to handle REM of float
 
 //! It uses GPR & calls call_fmodf
-int common_rem_float(u2 vA, u2 v1, u2 v2) {
+int common_rem_float(int vA, int v1, int v2) {
     get_virtual_reg(v1, OpndSize_32, 1, false);
     get_virtual_reg(v2, OpndSize_32, 2, false);
     load_effective_addr(-8, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
@@ -2165,9 +2165,9 @@ int common_rem_float(u2 vA, u2 v1, u2 v2) {
  */
 int op_rem_float(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_REM_FLOAT);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = mir->dalvikInsn.vB;
-    u2 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     int retval = common_rem_float(vA, v1, v2);
     return retval;
 }
@@ -2179,16 +2179,16 @@ int op_rem_float(const MIR * mir) {
  */
 int op_rem_float_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_REM_FLOAT_2ADDR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = vA;
-    u2 v2 = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = vA;
+    int v2 = mir->dalvikInsn.vB;
     int retval = common_rem_float(vA, v1, v2);
     return retval;
 }
 //! common code to handle REM of double
 
 //! It uses XMM & calls call_fmod
-int common_rem_double(u2 vA, u2 v1, u2 v2) {
+int common_rem_double(int vA, int v1, int v2) {
     get_virtual_reg(v1, OpndSize_64, 1, false);
     get_virtual_reg(v2, OpndSize_64, 2, false);
     load_effective_addr(-16, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
@@ -2208,9 +2208,9 @@ int common_rem_double(u2 vA, u2 v1, u2 v2) {
  */
 int op_rem_double(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_REM_DOUBLE);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = mir->dalvikInsn.vB;
-    u2 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     int retval = common_rem_double(vA, v1, v2);
     return retval;
 }
@@ -2222,9 +2222,9 @@ int op_rem_double(const MIR * mir) {
  */
 int op_rem_double_2addr(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_REM_DOUBLE_2ADDR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 v1 = vA;
-    u2 v2 = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = vA;
+    int v2 = mir->dalvikInsn.vB;
     int retval = common_rem_double(vA, v1, v2);
     return retval;
 }
@@ -2236,9 +2236,9 @@ int op_rem_double_2addr(const MIR * mir) {
  */
 int op_cmpl_float(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_CMPL_FLOAT);
-    u2 vA = mir->dalvikInsn.vA;
-    u4 v1 = mir->dalvikInsn.vB;
-    u4 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     get_VR_ss(v1, 1, false); //xmm
     move_imm_to_reg(OpndSize_32, 0, 1, false);
     move_imm_to_reg(OpndSize_32, 1, 2, false);
@@ -2266,9 +2266,9 @@ int op_cmpl_float(const MIR * mir) {
  */
 int op_cmpg_float(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_CMPG_FLOAT);
-    u2 vA = mir->dalvikInsn.vA;
-    u4 v1 = mir->dalvikInsn.vB;
-    u4 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
 
     //Operands are reversed here. Comparing vCC and vBB
     get_VR_ss(v2, 1, false);
@@ -2316,9 +2316,9 @@ int op_cmpg_float(const MIR * mir) {
  */
 int op_cmpl_double(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_CMPL_DOUBLE);
-    u2 vA = mir->dalvikInsn.vA;
-    u4 v1 = mir->dalvikInsn.vB;
-    u4 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     get_VR_sd(v1, 1, false);
     compare_VR_sd_reg(v2, 1, false);
     move_imm_to_reg(OpndSize_32, 0, 1, false);
@@ -2344,9 +2344,9 @@ int op_cmpl_double(const MIR * mir) {
  */
 int op_cmpg_double(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_CMPG_DOUBLE);
-    u2 vA = mir->dalvikInsn.vA;
-    u4 v1 = mir->dalvikInsn.vB;
-    u4 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
 
     //Operands are reversed here. Comparing vCC and vBB
     get_VR_sd(v2, 1, false);
@@ -2400,9 +2400,9 @@ int op_cmpg_double(const MIR * mir) {
  */
 int op_cmp_long(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_CMP_LONG);
-    u2 vA = mir->dalvikInsn.vA;
-    u4 v1 = mir->dalvikInsn.vB;
-    u4 v2 = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int v1 = mir->dalvikInsn.vB;
+    int v2 = mir->dalvikInsn.vC;
     get_virtual_reg(v1+1, OpndSize_32, 2, false);
 
     //Compare higher 32 bits
diff --git a/vm/compiler/codegen/x86/LowerConst.cpp b/vm/compiler/codegen/x86/LowerConst.cpp
index 1f77537..0fe1860 100644
--- a/vm/compiler/codegen/x86/LowerConst.cpp
+++ b/vm/compiler/codegen/x86/LowerConst.cpp
@@ -44,7 +44,7 @@
 //!   we define an interface between the lowering module and register allocator:
 //!     rememberState, gotoState, transferToState
 //!   to make sure at the control flow merge point the state of registers is the same
-int const_string_common_nohelper(u4 tmp, u2 vA) {
+int const_string_common_nohelper(u4 tmp, int vA) {
     /* for trace-based JIT, the string is already resolved since this code has been executed */
     void *strPtr = (void*)
               (currentMethod->clazz->pDvmDex->pResStrings[tmp]);
@@ -55,7 +55,7 @@ int const_string_common_nohelper(u4 tmp, u2 vA) {
 //! dispatcher to select either const_string_common_helper or const_string_common_nohelper
 
 //!
-int const_string_common(u4 tmp, u2 vA) {
+int const_string_common(u4 tmp, int vA) {
     return const_string_common_nohelper(tmp, vA);
 }
 #undef P_GPR_1
@@ -68,7 +68,7 @@ int const_string_common(u4 tmp, u2 vA) {
  */
 int op_const_4(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_CONST_4);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     s4 tmp = mir->dalvikInsn.vB;
     set_VR_to_imm(vA, OpndSize_32, tmp);
     return 1;
@@ -82,7 +82,7 @@ int op_const_4(const MIR * mir) {
 int op_const_16(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_CONST_16);
     u2 BBBB = mir->dalvikInsn.vB;
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     set_VR_to_imm(vA, OpndSize_32, (s2)BBBB);
     return 1;
 }
@@ -94,7 +94,7 @@ int op_const_16(const MIR * mir) {
  */
 int op_const(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_CONST);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     u4 tmp = mir->dalvikInsn.vB;
     set_VR_to_imm(vA, OpndSize_32, (s4)tmp);
     return 1;
@@ -107,7 +107,7 @@ int op_const(const MIR * mir) {
  */
 int op_const_high16(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_CONST_HIGH16);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     u2 tmp = mir->dalvikInsn.vB;
     set_VR_to_imm(vA, OpndSize_32, ((s4)tmp)<<16);
     return 1;
@@ -120,7 +120,7 @@ int op_const_high16(const MIR * mir) {
  */
 int op_const_wide_16(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_CONST_WIDE_16);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     u2 tmp = mir->dalvikInsn.vB;
     set_VR_to_imm(vA, OpndSize_32, (s2)tmp);
     set_VR_to_imm(vA+1, OpndSize_32, ((s2)tmp)>>31);
@@ -134,7 +134,7 @@ int op_const_wide_16(const MIR * mir) {
  */
 int op_const_wide_32(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_CONST_WIDE_32);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     u4 tmp = mir->dalvikInsn.vB;
     set_VR_to_imm(vA, OpndSize_32, (s4)tmp);
     set_VR_to_imm(vA+1, OpndSize_32, ((s4)tmp)>>31);
@@ -148,7 +148,7 @@ int op_const_wide_32(const MIR * mir) {
  */
 int op_const_wide(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_CONST_WIDE);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     u8 tmp = mir->dalvikInsn.vB_wide;
     set_VR_to_imm(vA, OpndSize_32, (s4)tmp);
     set_VR_to_imm(vA+1, OpndSize_32, (s4)(tmp >> 32));
@@ -162,7 +162,7 @@ int op_const_wide(const MIR * mir) {
  */
 int op_const_wide_high16(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_CONST_WIDE_HIGH16);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     u2 tmp = mir->dalvikInsn.vB;
     set_VR_to_imm(vA, OpndSize_32, 0);
     set_VR_to_imm(vA+1, OpndSize_32, ((s4)tmp)<<16);
@@ -176,7 +176,7 @@ int op_const_wide_high16(const MIR * mir) {
  */
 int op_const_string(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_CONST_STRING);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     u4 tmp = mir->dalvikInsn.vB;
     int retval = const_string_common(tmp, vA);
     return retval;
@@ -189,7 +189,7 @@ int op_const_string(const MIR * mir) {
  */
 int op_const_string_jumbo(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_CONST_STRING_JUMBO);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     u4 tmp = mir->dalvikInsn.vB;
     int retval = const_string_common(tmp, vA);
     return retval;
@@ -203,7 +203,7 @@ int op_const_string_jumbo(const MIR * mir) {
  */
 int op_const_class(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_CONST_CLASS);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     u4 tmp = mir->dalvikInsn.vB;
 #if !defined(WITH_JIT)
     // It calls class_resolve (%ebx is live across the call)
diff --git a/vm/compiler/codegen/x86/LowerGetPut.cpp b/vm/compiler/codegen/x86/LowerGetPut.cpp
index 5306b8b..e799708 100644
--- a/vm/compiler/codegen/x86/LowerGetPut.cpp
+++ b/vm/compiler/codegen/x86/LowerGetPut.cpp
@@ -39,7 +39,7 @@
  * @param mirOptFlags optimization flags for current bytecode
  * @return value >= 0 when handled
  */
-int aget_common_nohelper(ArrayAccess flag, u2 vA, u2 vref, u2 vindex, int mirOptFlags) {
+int aget_common_nohelper(ArrayAccess flag, int vA, int vref, int vindex, int mirOptFlags) {
     ////////////////////////////
     // Request VR free delays before register allocation for the temporaries
     if(!(mirOptFlags & MIR_IGNORE_NULL_CHECK))
@@ -73,10 +73,10 @@ int aget_common_nohelper(ArrayAccess flag, u2 vA, u2 vref, u2 vindex, int mirOpt
 
     if(flag == AGET) {
 #ifndef WITH_SELF_VERIFICATION
-        move_mem_disp_scale_to_reg(OpndSize_32, 1, false, offArrayObject_contents, 2, false, 4, 4, false);
+        move_mem_disp_scale_to_reg(OpndSize_32, 1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 4, 4, false);
 #else
         // Load address into temp 5
-        load_effective_addr_scale_disp(1, false, offArrayObject_contents, 2, false, 4, 5, false);
+        load_effective_addr_scale_disp(1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 4, 5, false);
         // push caller saved registers
         pushCallerSavedRegs();
         // Set up arguments
@@ -99,10 +99,10 @@ int aget_common_nohelper(ArrayAccess flag, u2 vA, u2 vref, u2 vindex, int mirOpt
     }
     else if(flag == AGET_WIDE) {
 #ifndef WITH_SELF_VERIFICATION
-        move_mem_disp_scale_to_reg(OpndSize_64, 1, false, offArrayObject_contents, 2, false, 8, 1, false);
+        move_mem_disp_scale_to_reg(OpndSize_64, 1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 8, 1, false);
 #else
         // Load address into temp 5 (scale of 8 due to opnd size 64), temp 1 is base gp
-        load_effective_addr_scale_disp(1, false, offArrayObject_contents, 2, false, 8, 5, false);
+        load_effective_addr_scale_disp(1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 8, 5, false);
         // push caller saved registers
         pushCallerSavedRegs();
         // Set up arguments
@@ -123,10 +123,10 @@ int aget_common_nohelper(ArrayAccess flag, u2 vA, u2 vref, u2 vindex, int mirOpt
     }
     else if(flag == AGET_CHAR) {
 #ifndef WITH_SELF_VERIFICATION
-        movez_mem_disp_scale_to_reg(OpndSize_16, 1, false, offArrayObject_contents, 2, false, 2, 4, false);
+        movez_mem_disp_scale_to_reg(OpndSize_16, 1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 2, 4, false);
 #else
         // Load address into temp 5
-        load_effective_addr_scale_disp(1, false, offArrayObject_contents, 2, false, 2, 5, false);
+        load_effective_addr_scale_disp(1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 2, 5, false);
         // push caller saved registers
         pushCallerSavedRegs();
         // Set up arguments
@@ -149,10 +149,10 @@ int aget_common_nohelper(ArrayAccess flag, u2 vA, u2 vref, u2 vindex, int mirOpt
     }
     else if(flag == AGET_SHORT) {
 #ifndef WITH_SELF_VERIFICATION
-        moves_mem_disp_scale_to_reg(OpndSize_16, 1, false, offArrayObject_contents, 2, false, 2, 4, false);
+        moves_mem_disp_scale_to_reg(OpndSize_16, 1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 2, 4, false);
 #else
         // Load address into temp 5
-        load_effective_addr_scale_disp(1, false, offArrayObject_contents, 2, false, 2, 5, false);
+        load_effective_addr_scale_disp(1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 2, 5, false);
         // push caller saved registers
         pushCallerSavedRegs();
         // Set up arguments
@@ -176,10 +176,10 @@ int aget_common_nohelper(ArrayAccess flag, u2 vA, u2 vref, u2 vindex, int mirOpt
     else if(flag == AGET_BOOLEAN) {
 
 #ifndef WITH_SELF_VERIFICATION
-        movez_mem_disp_scale_to_reg(OpndSize_8, 1, false, offArrayObject_contents, 2, false, 1, 4, false);
+        movez_mem_disp_scale_to_reg(OpndSize_8, 1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 1, 4, false);
 #else
         // Load address into temp 5
-        load_effective_addr_scale_disp(1, false, offArrayObject_contents, 2, false, 1, 5, false);
+        load_effective_addr_scale_disp(1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 1, 5, false);
         // push caller saved registers
         pushCallerSavedRegs();
         // Set up arguments
@@ -202,10 +202,10 @@ int aget_common_nohelper(ArrayAccess flag, u2 vA, u2 vref, u2 vindex, int mirOpt
     }
     else if(flag == AGET_BYTE) {
 #ifndef WITH_SELF_VERIFICATION
-        moves_mem_disp_scale_to_reg(OpndSize_8, 1, false, offArrayObject_contents, 2, false, 1, 4, false);
+        moves_mem_disp_scale_to_reg(OpndSize_8, 1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 1, 4, false);
 #else
         // Load address into temp 5
-        load_effective_addr_scale_disp(1, false, offArrayObject_contents, 2, false, 1, 5, false);
+        load_effective_addr_scale_disp(1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 1, 5, false);
         // push caller saved registers
         pushCallerSavedRegs();
         // Set up arguments
@@ -241,7 +241,7 @@ int aget_common_nohelper(ArrayAccess flag, u2 vA, u2 vref, u2 vindex, int mirOpt
 //! wrapper to call either aget_common_helper or aget_common_nohelper
 
 //!
-int aget_common(int flag, u2 vA, u2 vref, u2 vindex) {
+int aget_common(int flag, int vA, int vref, int vindex) {
     return aget_common_nohelper(flag, vA, vref, vindex);
 }
 #endif
@@ -258,9 +258,9 @@ int aget_common(int flag, u2 vA, u2 vref, u2 vindex) {
 int op_aget(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_AGET
             || mir->dalvikInsn.opcode == OP_AGET_OBJECT);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vref = mir->dalvikInsn.vB;
-    u2 vindex = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int vref = mir->dalvikInsn.vB;
+    int vindex = mir->dalvikInsn.vC;
     int retval = aget_common_nohelper(AGET, vA, vref, vindex,
             mir->OptimizationFlags);
     return retval;
@@ -273,9 +273,9 @@ int op_aget(const MIR * mir) {
  */
 int op_aget_wide(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_AGET_WIDE);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vref = mir->dalvikInsn.vB;
-    u2 vindex = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int vref = mir->dalvikInsn.vB;
+    int vindex = mir->dalvikInsn.vC;
     int retval = aget_common_nohelper(AGET_WIDE, vA, vref, vindex,
             mir->OptimizationFlags);
     return retval;
@@ -298,9 +298,9 @@ int op_aget_object(const MIR * mir) {
  */
 int op_aget_boolean(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_AGET_BOOLEAN);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vref = mir->dalvikInsn.vB;
-    u2 vindex = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int vref = mir->dalvikInsn.vB;
+    int vindex = mir->dalvikInsn.vC;
     int retval = aget_common_nohelper(AGET_BOOLEAN, vA, vref, vindex,
             mir->OptimizationFlags);
     return retval;
@@ -313,9 +313,9 @@ int op_aget_boolean(const MIR * mir) {
  */
 int op_aget_byte(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_AGET_BYTE);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vref = mir->dalvikInsn.vB;
-    u2 vindex = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int vref = mir->dalvikInsn.vB;
+    int vindex = mir->dalvikInsn.vC;
     int retval = aget_common_nohelper(AGET_BYTE, vA, vref, vindex,
             mir->OptimizationFlags);
     return retval;
@@ -328,9 +328,9 @@ int op_aget_byte(const MIR * mir) {
  */
 int op_aget_char(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_AGET_CHAR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vref = mir->dalvikInsn.vB;
-    u2 vindex = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int vref = mir->dalvikInsn.vB;
+    int vindex = mir->dalvikInsn.vC;
     int retval = aget_common_nohelper(AGET_CHAR, vA, vref, vindex,
             mir->OptimizationFlags);
     return retval;
@@ -343,9 +343,9 @@ int op_aget_char(const MIR * mir) {
  */
 int op_aget_short(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_AGET_SHORT);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vref = mir->dalvikInsn.vB;
-    u2 vindex = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int vref = mir->dalvikInsn.vB;
+    int vindex = mir->dalvikInsn.vC;
     int retval = aget_common_nohelper(AGET_SHORT, vA, vref, vindex,
             mir->OptimizationFlags);
     return retval;
@@ -366,7 +366,7 @@ int op_aget_short(const MIR * mir) {
  * @param mirOptFlags optimization flags for current bytecode
  * @return value >= 0 when handled
  */
-int aput_common_nohelper(ArrayAccess flag, u2 vA, u2 vref, u2 vindex, int mirOptFlags) {
+int aput_common_nohelper(ArrayAccess flag, int vA, int vref, int vindex, int mirOptFlags) {
     //////////////////////////////////////
     // Request VR free delays before register allocation for the temporaries.
     // No need to request delay for vA since it will be transferred to temporary
@@ -408,10 +408,10 @@ int aput_common_nohelper(ArrayAccess flag, u2 vA, u2 vref, u2 vindex, int mirOpt
     }
     if(flag == APUT) {
 #ifndef WITH_SELF_VERIFICATION
-        move_reg_to_mem_disp_scale(OpndSize_32, 4, false, 1, false, offArrayObject_contents, 2, false, 4);
+        move_reg_to_mem_disp_scale(OpndSize_32, 4, false, 1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 4);
 #else
         // Load address into temp 5
-        load_effective_addr_scale_disp(1, false, offArrayObject_contents, 2, false, 4, 5, false);
+        load_effective_addr_scale_disp(1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 4, 5, false);
         // push caller saved registers
         pushCallerSavedRegs();
         // Set up arguments
@@ -433,10 +433,10 @@ int aput_common_nohelper(ArrayAccess flag, u2 vA, u2 vref, u2 vindex, int mirOpt
 #endif
     } else if(flag == APUT_WIDE) {
 #ifndef WITH_SELF_VERIFICATION
-        move_reg_to_mem_disp_scale(OpndSize_64, 1, false, 1, false, offArrayObject_contents, 2, false, 8);
+        move_reg_to_mem_disp_scale(OpndSize_64, 1, false, 1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 8);
 #else
         // Load address into temp 4
-        load_effective_addr_scale_disp(1, false, offArrayObject_contents, 2, false, 8, 4, false);
+        load_effective_addr_scale_disp(1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 8, 4, false);
         // push caller saved registers
         pushCallerSavedRegs();
         // Set up arguments
@@ -457,10 +457,10 @@ int aput_common_nohelper(ArrayAccess flag, u2 vA, u2 vref, u2 vindex, int mirOpt
     }
     else if(flag == APUT_CHAR || flag == APUT_SHORT) {
 #ifndef WITH_SELF_VERIFICATION
-        move_reg_to_mem_disp_scale(OpndSize_16, 4, false, 1, false, offArrayObject_contents, 2, false, 2);
+        move_reg_to_mem_disp_scale(OpndSize_16, 4, false, 1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 2);
 #else
         // Load address into temp 5
-        load_effective_addr_scale_disp(1, false, offArrayObject_contents, 2, false, 2, 5, false);
+        load_effective_addr_scale_disp(1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 2, 5, false);
         // push caller saved registers
         pushCallerSavedRegs();
         // Set up arguments
@@ -483,10 +483,10 @@ int aput_common_nohelper(ArrayAccess flag, u2 vA, u2 vref, u2 vindex, int mirOpt
     }
     else if(flag == APUT_BOOLEAN || flag == APUT_BYTE) {
 #ifndef WITH_SELF_VERIFICATION
-        move_reg_to_mem_disp_scale(OpndSize_8, 4, false, 1, false, offArrayObject_contents, 2, false, 1);
+        move_reg_to_mem_disp_scale(OpndSize_8, 4, false, 1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 1);
 #else
         // Load address into temp 5
-        load_effective_addr_scale_disp(1, false, offArrayObject_contents, 2, false, 1, 5, false);
+        load_effective_addr_scale_disp(1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 1, 5, false);
         // push caller saved registers
         pushCallerSavedRegs();
         // Set up arguments
@@ -515,7 +515,7 @@ int aput_common_nohelper(ArrayAccess flag, u2 vA, u2 vref, u2 vindex, int mirOpt
 //! wrapper to call either aput_common_helper or aput_common_nohelper
 
 //!
-int aput_common(int flag, u2 vA, u2 vref, u2 vindex) {
+int aput_common(int flag, int vA, int vref, int vindex) {
     return aput_common_nohelper(flag, vA, vref, vindex);
 }
 #endif
@@ -531,9 +531,9 @@ int aput_common(int flag, u2 vA, u2 vref, u2 vindex) {
  */
 int op_aput(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_APUT);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vref = mir->dalvikInsn.vB;
-    u2 vindex = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int vref = mir->dalvikInsn.vB;
+    int vindex = mir->dalvikInsn.vC;
     int retval = aput_common_nohelper(APUT, vA, vref, vindex,
             mir->OptimizationFlags);
     return retval;
@@ -546,9 +546,9 @@ int op_aput(const MIR * mir) {
  */
 int op_aput_wide(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_APUT_WIDE);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vref = mir->dalvikInsn.vB;
-    u2 vindex = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int vref = mir->dalvikInsn.vB;
+    int vindex = mir->dalvikInsn.vC;
     int retval = aput_common_nohelper(APUT_WIDE, vA, vref, vindex,
             mir->OptimizationFlags);
     return retval;
@@ -561,9 +561,9 @@ int op_aput_wide(const MIR * mir) {
  */
 int op_aput_boolean(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_APUT_BOOLEAN);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vref = mir->dalvikInsn.vB;
-    u2 vindex = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int vref = mir->dalvikInsn.vB;
+    int vindex = mir->dalvikInsn.vC;
     int retval = aput_common_nohelper(APUT_BOOLEAN, vA, vref, vindex,
             mir->OptimizationFlags);
     return retval;
@@ -576,9 +576,9 @@ int op_aput_boolean(const MIR * mir) {
  */
 int op_aput_byte(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_APUT_BYTE);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vref = mir->dalvikInsn.vB;
-    u2 vindex = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int vref = mir->dalvikInsn.vB;
+    int vindex = mir->dalvikInsn.vC;
     int retval = aput_common_nohelper(APUT_BYTE, vA, vref, vindex,
             mir->OptimizationFlags);
     return retval;
@@ -591,9 +591,9 @@ int op_aput_byte(const MIR * mir) {
  */
 int op_aput_char(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_APUT_CHAR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vref = mir->dalvikInsn.vB;
-    u2 vindex = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int vref = mir->dalvikInsn.vB;
+    int vindex = mir->dalvikInsn.vC;
     int retval = aput_common_nohelper(APUT_CHAR, vA, vref, vindex,
             mir->OptimizationFlags);
     return retval;
@@ -606,9 +606,9 @@ int op_aput_char(const MIR * mir) {
  */
 int op_aput_short(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_APUT_SHORT);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vref = mir->dalvikInsn.vB;
-    u2 vindex = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int vref = mir->dalvikInsn.vB;
+    int vindex = mir->dalvikInsn.vC;
     int retval = aput_common_nohelper(APUT_SHORT, vA, vref, vindex,
             mir->OptimizationFlags);
     return retval;
@@ -630,9 +630,9 @@ void markCard_notNull(int tgtAddrReg, int scratchReg, bool isPhysical);
  */
 int op_aput_object(const MIR * mir) { //type checking
     assert(mir->dalvikInsn.opcode == OP_APUT_OBJECT);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vref = mir->dalvikInsn.vB;
-    u2 vindex = mir->dalvikInsn.vC;
+    int vA = mir->dalvikInsn.vA;
+    int vref = mir->dalvikInsn.vB;
+    int vindex = mir->dalvikInsn.vC;
 #ifdef INC_NCG_O0
     if(gDvm.helper_switch[6]) {
         export_pc(); //use %edx
@@ -672,7 +672,7 @@ int op_aput_object(const MIR * mir) { //type checking
 
         get_virtual_reg(vindex, OpndSize_32, 2, false); //index
         if(!(mir->OptimizationFlags & MIR_IGNORE_RANGE_CHECK)) {
-            compare_mem_reg(OpndSize_32, offArrayObject_length, 1, false, 2, false);
+            compare_mem_reg(OpndSize_32, OFFSETOF_MEMBER(ArrayObject, length), 1, false, 2, false);
             conditional_jump_global_API(Condition_NC, "common_errArrayIndex", false);
             cancelVRFreeDelayRequest(vref,VRDELAY_BOUNDCHECK);
             cancelVRFreeDelayRequest(vindex,VRDELAY_BOUNDCHECK);
@@ -685,10 +685,10 @@ int op_aput_object(const MIR * mir) { //type checking
     compare_imm_reg(OpndSize_32, 0, 4, false);
     conditional_jump(Condition_E, ".aput_object_skip_check", true);
     rememberState(1);
-    move_mem_to_reg(OpndSize_32, offObject_clazz, 4, false, 5, false);
+    move_mem_to_reg(OpndSize_32, OFFSETOF_MEMBER(Object, clazz), 4, false, 5, false);
     load_effective_addr(-12, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
     move_reg_to_mem(OpndSize_32, 5, false, 0, PhysicalReg_ESP, true);
-    move_mem_to_reg(OpndSize_32, offObject_clazz, 1, false, 6, false);
+    move_mem_to_reg(OpndSize_32, OFFSETOF_MEMBER(Object, clazz), 1, false, 6, false);
     move_reg_to_mem(OpndSize_32, 6, false, 4, PhysicalReg_ESP, true);
 
     scratchRegs[0] = PhysicalReg_SCRATCH_1;
@@ -699,10 +699,10 @@ int op_aput_object(const MIR * mir) { //type checking
 
 #ifndef WITH_SELF_VERIFICATION
     //NOTE: "2, false" is live through function call
-    move_reg_to_mem_disp_scale(OpndSize_32, 4, false, 1, false, offArrayObject_contents, 2, false, 4);
+    move_reg_to_mem_disp_scale(OpndSize_32, 4, false, 1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 4);
 #else
     // lea to temp 7, temp 4 contains the data
-    load_effective_addr_scale_disp(1, false, offArrayObject_contents, 2, false, 4, 7, false);
+    load_effective_addr_scale_disp(1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 4, 7, false);
     pushCallerSavedRegs();
     // make space on the stack and push 3 args (address, data, operand size)
     load_effective_addr(-12, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
@@ -724,10 +724,10 @@ int op_aput_object(const MIR * mir) { //type checking
     goToState(1);
 #ifndef WITH_SELF_VERIFICATION
     //NOTE: "2, false" is live through function call
-    move_reg_to_mem_disp_scale(OpndSize_32, 4, false, 1, false, offArrayObject_contents, 2, false, 4);
+    move_reg_to_mem_disp_scale(OpndSize_32, 4, false, 1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 4);
 #else
     // lea to temp 7, temp 4 contains the data
-    load_effective_addr_scale_disp(1, false, offArrayObject_contents, 2, false, 4, 7, false);
+    load_effective_addr_scale_disp(1, false, OFFSETOF_MEMBER(ArrayObject, contents), 2, false, 4, 7, false);
     pushCallerSavedRegs();
     // make space on the stack and push 3 args (address, data, operand size)
     load_effective_addr(-12, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
@@ -807,8 +807,8 @@ void markCard_filled(int tgtAddrReg, bool isTgtPhysical, int scratchReg, bool is
  * @param mir bytecode representation
  * @return value >= 0 when handled
  */
-int iget_iput_common_nohelper(u2 referenceIndex, InstanceAccess flag, u2 vA,
-        u2 vB, bool isObj, bool isVolatile, const MIR * mir) {
+int iget_iput_common_nohelper(u2 referenceIndex, InstanceAccess flag, int vA,
+        int vB, bool isObj, bool isVolatile, const MIR * mir) {
 #if !defined(WITH_JIT)
     ///////////////////////////////
     scratchRegs[2] = PhysicalReg_Null; scratchRegs[3] = PhysicalReg_Null;
@@ -1029,7 +1029,7 @@ int iget_iput_common_nohelper(u2 referenceIndex, InstanceAccess flag, u2 vA,
 //! wrapper to call either iget_iput_common_helper or iget_iput_common_nohelper
 
 //!
-int iget_iput_common(int tmp, int flag, u2 vA, u2 vB, int isObj, bool isVolatile) {
+int iget_iput_common(int tmp, int flag, int vA, int vB, int isObj, bool isVolatile) {
     return iget_iput_common_nohelper(tmp, flag, vA, vB, isObj, isVolatile);
 }
 #endif
@@ -1051,8 +1051,8 @@ int op_iget(const MIR * mir) {
             || mir->dalvikInsn.opcode == OP_IGET_CHAR
             || mir->dalvikInsn.opcode == OP_IGET_SHORT
             || mir->dalvikInsn.opcode == OP_IGET_VOLATILE);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     u2 referenceIndex = mir->dalvikInsn.vC;
     int retval = iget_iput_common_nohelper(referenceIndex, IGET, vA, vB, false,
             false, mir);
@@ -1068,8 +1068,8 @@ int op_iget(const MIR * mir) {
 int op_iget_wide(const MIR * mir, bool isVolatile) {
     assert(mir->dalvikInsn.opcode == OP_IGET_WIDE
             || mir->dalvikInsn.opcode == OP_IGET_WIDE_VOLATILE);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     u2 referenceIndex = mir->dalvikInsn.vC;
     int retval = iget_iput_common_nohelper(referenceIndex, IGET_WIDE, vA, vB,
             false, isVolatile, mir);
@@ -1085,8 +1085,8 @@ int op_iget_wide(const MIR * mir, bool isVolatile) {
 int op_iget_object(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_IGET_OBJECT
             || mir->dalvikInsn.opcode == OP_IGET_OBJECT_VOLATILE);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     u2 referenceIndex = mir->dalvikInsn.vC;
     int retval = iget_iput_common_nohelper(referenceIndex, IGET, vA, vB, true,
             false, mir);
@@ -1146,8 +1146,8 @@ int op_iput(const MIR * mir) {
             || mir->dalvikInsn.opcode == OP_IPUT_CHAR
             || mir->dalvikInsn.opcode == OP_IPUT_SHORT
             || mir->dalvikInsn.opcode == OP_IPUT_VOLATILE);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     u2 referenceIndex = mir->dalvikInsn.vC;
     int retval = iget_iput_common_nohelper(referenceIndex, IPUT, vA, vB, false,
             false, mir);
@@ -1163,8 +1163,8 @@ int op_iput(const MIR * mir) {
 int op_iput_wide(const MIR * mir, bool isVolatile) {
     assert(mir->dalvikInsn.opcode == OP_IPUT_WIDE
             || mir->dalvikInsn.opcode == OP_IPUT_WIDE_VOLATILE);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     u2 referenceIndex = mir->dalvikInsn.vC;
     int retval = iget_iput_common_nohelper(referenceIndex, IPUT_WIDE, vA, vB,
             false, isVolatile, mir);
@@ -1180,8 +1180,8 @@ int op_iput_wide(const MIR * mir, bool isVolatile) {
 int op_iput_object(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_IPUT_OBJECT
             || mir->dalvikInsn.opcode == OP_IPUT_OBJECT_VOLATILE);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     u2 referenceIndex = mir->dalvikInsn.vC;
     int retval = iget_iput_common_nohelper(referenceIndex, IPUT, vA, vB, true,
             false, mir);
@@ -1243,7 +1243,7 @@ int op_iput_short(const MIR * mir) {
  * @param mir bytecode representation
  * @return value >= 0 when handled
  */
-int sget_sput_common(StaticAccess flag, u2 vA, u2 referenceIndex, bool isObj,
+int sget_sput_common(StaticAccess flag, int vA, u2 referenceIndex, bool isObj,
         bool isVolatile, const MIR * mir) {
 #ifdef INC_NCG_O0
     if(gDvm.helper_switch[5]) {
@@ -1300,11 +1300,11 @@ int sget_sput_common(StaticAccess flag, u2 vA, u2 referenceIndex, bool isObj,
 #endif
     if(flag == SGET) {
 #ifndef WITH_SELF_VERIFICATION
-        move_mem_to_reg(OpndSize_32, offStaticField_value, PhysicalReg_EAX, true, 7, false); //access field
+        move_mem_to_reg(OpndSize_32, OFFSETOF_MEMBER(StaticField, value), PhysicalReg_EAX, true, 7, false); //access field
         set_virtual_reg(vA, OpndSize_32, 7, false);
 #else
             // Load address into temp reg 8
-            load_effective_addr(offStaticField_value, PhysicalReg_EAX, true, 8, false);
+            load_effective_addr(OFFSETOF_MEMBER(StaticField, value), PhysicalReg_EAX, true, 8, false);
             // push caller saved registers
             pushCallerSavedRegs();
             // Set up arguments
@@ -1329,7 +1329,7 @@ int sget_sput_common(StaticAccess flag, u2 vA, u2 referenceIndex, bool isObj,
 #ifndef WITH_SELF_VERIFICATION
         if(isVolatile) {
             /* call dvmQuasiAtomicRead64(addr) */
-            load_effective_addr(offStaticField_value, PhysicalReg_EAX, true, 9, false);
+            load_effective_addr(OFFSETOF_MEMBER(StaticField, value), PhysicalReg_EAX, true, 9, false);
             move_reg_to_mem(OpndSize_32, 9, false, -4, PhysicalReg_ESP, true); //1st argument
             load_effective_addr(-4, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
             nextVersionOfHardReg(PhysicalReg_EAX, 2);
@@ -1342,14 +1342,14 @@ int sget_sput_common(StaticAccess flag, u2 vA, u2 referenceIndex, bool isObj,
             set_virtual_reg(vA+1, OpndSize_32, PhysicalReg_EDX, true);
         }
         else {
-            move_mem_to_reg(OpndSize_64, offStaticField_value, PhysicalReg_EAX, true, 1, false); //access field
+            move_mem_to_reg(OpndSize_64, OFFSETOF_MEMBER(StaticField, value), PhysicalReg_EAX, true, 1, false); //access field
             set_virtual_reg(vA, OpndSize_64, 1, false);
         }
 #else
             // TODO: the volatile 64 bit type is not handled;
             // write a C function to only return the mapped shadow address(Read)
             // Load address into temp 4
-            load_effective_addr(offStaticField_value, PhysicalReg_EAX, true, 4, false);
+            load_effective_addr(OFFSETOF_MEMBER(StaticField, value), PhysicalReg_EAX, true, 4, false);
             // push caller saved registers
             pushCallerSavedRegs();
             // Set up arguments
@@ -1371,10 +1371,10 @@ int sget_sput_common(StaticAccess flag, u2 vA, u2 referenceIndex, bool isObj,
     } else if(flag == SPUT) {
         get_virtual_reg(vA, OpndSize_32, 7, false);
 #ifndef WITH_SELF_VERIFICATION
-        move_reg_to_mem(OpndSize_32, 7, false, offStaticField_value, PhysicalReg_EAX, true); //access field
+        move_reg_to_mem(OpndSize_32, 7, false, OFFSETOF_MEMBER(StaticField, value), PhysicalReg_EAX, true); //access field
 #else
             // Load address into temp 8; reg temp 7 will contain the data
-            load_effective_addr(offStaticField_value, PhysicalReg_EAX, true, 8, false);
+            load_effective_addr(OFFSETOF_MEMBER(StaticField, value), PhysicalReg_EAX, true, 8, false);
             // push caller saved registers
             pushCallerSavedRegs();
             // Set up arguments
@@ -1396,7 +1396,7 @@ int sget_sput_common(StaticAccess flag, u2 vA, u2 referenceIndex, bool isObj,
 #endif
         if(isObj) {
             /* get clazz object, then use clazz object to mark card */
-            move_mem_to_reg(OpndSize_32, offField_clazz, PhysicalReg_EAX, true, 12, false);
+            move_mem_to_reg(OpndSize_32, OFFSETOF_MEMBER(Field, clazz), PhysicalReg_EAX, true, 12, false);
             markCard(7/*valReg*/, 12, false, 11, false);
         }
     } else if(flag == SPUT_WIDE) {
@@ -1404,7 +1404,7 @@ int sget_sput_common(StaticAccess flag, u2 vA, u2 referenceIndex, bool isObj,
 #ifndef WITH_SELF_VERIFICATION
         if(isVolatile) {
             /* call dvmQuasiAtomicSwap64(val, addr) */
-            load_effective_addr(offStaticField_value, PhysicalReg_EAX, true, 9, false);
+            load_effective_addr(OFFSETOF_MEMBER(StaticField, value), PhysicalReg_EAX, true, 9, false);
             move_reg_to_mem(OpndSize_32, 9, false, -4, PhysicalReg_ESP, true); //2nd argument
             move_reg_to_mem(OpndSize_64, 1, false, -12, PhysicalReg_ESP, true); //1st argument
             load_effective_addr(-12, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
@@ -1413,11 +1413,11 @@ int sget_sput_common(StaticAccess flag, u2 vA, u2 referenceIndex, bool isObj,
             load_effective_addr(12, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
         }
         else {
-            move_reg_to_mem(OpndSize_64, 1, false, offStaticField_value, PhysicalReg_EAX, true); //access field
+            move_reg_to_mem(OpndSize_64, 1, false, OFFSETOF_MEMBER(StaticField, value), PhysicalReg_EAX, true); //access field
         }
 #else
             // Load address into temp 4; reg temp 1 will contain the data
-            load_effective_addr(offStaticField_value, PhysicalReg_EAX, true, 4, false);
+            load_effective_addr(OFFSETOF_MEMBER(StaticField, value), PhysicalReg_EAX, true, 4, false);
             // push caller saved registers
             pushCallerSavedRegs();
             // Set up arguments
@@ -1459,7 +1459,7 @@ int op_sget(const MIR * mir) {
             || mir->dalvikInsn.opcode == OP_SGET_SHORT
             || mir->dalvikInsn.opcode == OP_SGET_VOLATILE
             || mir->dalvikInsn.opcode == OP_SGET_OBJECT_VOLATILE);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     u2 referenceIndex = mir->dalvikInsn.vB;
     int retval = sget_sput_common(SGET, vA, referenceIndex, false, false, mir);
     return retval;
@@ -1474,7 +1474,7 @@ int op_sget(const MIR * mir) {
 int op_sget_wide(const MIR * mir, bool isVolatile) {
     assert(mir->dalvikInsn.opcode == OP_SGET_WIDE
             || mir->dalvikInsn.opcode == OP_SGET_WIDE_VOLATILE);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     u2 referenceIndex = mir->dalvikInsn.vB;
     int retval = sget_sput_common(SGET_WIDE, vA, referenceIndex, false,
             isVolatile, mir);
@@ -1548,7 +1548,7 @@ int op_sput(const MIR * mir, bool isObj) {
             || mir->dalvikInsn.opcode == OP_SPUT_SHORT
             || mir->dalvikInsn.opcode == OP_SPUT_VOLATILE
             || mir->dalvikInsn.opcode == OP_SPUT_OBJECT_VOLATILE);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     u2 referenceIndex = mir->dalvikInsn.vB;
     int retval = sget_sput_common(SPUT, vA, referenceIndex, isObj, false, mir);
     return retval;
@@ -1563,7 +1563,7 @@ int op_sput(const MIR * mir, bool isObj) {
 int op_sput_wide(const MIR * mir, bool isVolatile) {
     assert(mir->dalvikInsn.opcode == OP_SPUT_WIDE
             || mir->dalvikInsn.opcode == OP_SPUT_WIDE_VOLATILE);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     u2 referenceIndex = mir->dalvikInsn.vB;
     int retval = sget_sput_common(SPUT_WIDE, vA, referenceIndex, false,
             isVolatile, mir);
@@ -1632,8 +1632,8 @@ int op_sput_short(const MIR * mir) {
 int op_iget_quick(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_IGET_QUICK
             || mir->dalvikInsn.opcode == OP_IGET_OBJECT_QUICK);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB; //object
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB; //object
     u2 fieldByteOffset = mir->dalvikInsn.vC;
 
     if((mir->OptimizationFlags & MIR_IGNORE_NULL_CHECK) == 0)
@@ -1689,8 +1689,8 @@ int op_iget_quick(const MIR * mir) {
  */
 int op_iget_wide_quick(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_IGET_WIDE_QUICK);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB; //object
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB; //object
     u2 fieldByteOffset = mir->dalvikInsn.vC;
 
     if((mir->OptimizationFlags & MIR_IGNORE_NULL_CHECK) == 0)
@@ -1753,8 +1753,8 @@ int op_iget_object_quick(const MIR * mir) {
  * @return
  */
 int iput_quick_common(const MIR * mir, bool isObj) {
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB; //object
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB; //object
     u2 fieldByteOffset = mir->dalvikInsn.vC;
 
     // Request VR delay before transfer to temporary. Only vB needs delay.
@@ -1824,8 +1824,8 @@ int op_iput_quick(const MIR * mir) {
  */
 int op_iput_wide_quick(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_IPUT_WIDE_QUICK);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB; //object
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB; //object
     u2 fieldByteOffset = mir->dalvikInsn.vC;
 
     // Request VR delay before transfer to temporary. Only vB needs delay.
diff --git a/vm/compiler/codegen/x86/LowerHelper.cpp b/vm/compiler/codegen/x86/LowerHelper.cpp
index ddb4b0b..67a080d 100644
--- a/vm/compiler/codegen/x86/LowerHelper.cpp
+++ b/vm/compiler/codegen/x86/LowerHelper.cpp
@@ -1763,7 +1763,7 @@ void alu_binary_imm_reg(OpndSize size, ALU_Opcode opc, int imm, int reg, bool is
  * @return whether we were successful. If false, caller needs to perform
  *         get_VR, alu_op, set_VR separately
  */
-bool alu_imm_to_VR(OpndSize size, ALU_Opcode opc, u2 srcVR, u2 destVR, int imm, int tempReg, bool isTempPhysical) {
+bool alu_imm_to_VR(OpndSize size, ALU_Opcode opc, int srcVR, int destVR, int imm, int tempReg, bool isTempPhysical) {
     const LowOpndRegType pType = getTypeFromIntSize(size); //gp or xmm
 
     //We accept only add_opc and sub_opc for now
@@ -2349,7 +2349,7 @@ void move_imm_to_mem(OpndSize size, int imm,
 //! set a VR to an immediate
 
 //!
-void set_VR_to_imm(u2 vA, OpndSize size, int imm) {
+void set_VR_to_imm(int vA, OpndSize size, int imm) {
     assert(size != OpndSize_64);
     if(size == OpndSize_64) {
         ALOGI("JIT_INFO: Trying to set VR with 64-bit imm");
@@ -2380,13 +2380,13 @@ void set_VR_to_imm(u2 vA, OpndSize size, int imm) {
         dump_imm_mem(m, ATOM_NORMAL, size, imm, 4*vA, PhysicalReg_FP, true, MemoryAccess_VR, vA, false);
     }
 }
-void set_VR_to_imm_noupdateref(LowOp* op, u2 vA, OpndSize size, int imm) {
+void set_VR_to_imm_noupdateref(LowOp* op, int vA, OpndSize size, int imm) {
     return;
 }
 //! set a VR to an immediate
 
 //! Do not allocate a physical register for the VR
-void set_VR_to_imm_noalloc(u2 vA, OpndSize size, int imm) {
+void set_VR_to_imm_noalloc(int vA, OpndSize size, int imm) {
     assert(size != OpndSize_64);
     if(size == OpndSize_64) {
         ALOGI("JIT_INFO: Trying to move 64-bit imm to memory (noalloc)");
@@ -2468,7 +2468,7 @@ void move_sd_reg_to_mem(LowOp* op, int reg, bool isPhysical,
 //!load from VR to a temporary
 
 //!
-void get_virtual_reg_all(u2 vR, OpndSize size, int reg, bool isPhysical, Mnemonic m) {
+void get_virtual_reg_all(int vR, OpndSize size, int reg, bool isPhysical, Mnemonic m) {
     LowOpndRegType type = getTypeFromIntSize(size);
     LowOpndRegType pType = type;//gp or xmm
     OpndSize size2 = size;
@@ -2625,11 +2625,11 @@ void get_virtual_reg_all(u2 vR, OpndSize size, int reg, bool isPhysical, Mnemoni
             MemoryAccess_VR, vR, reg, isPhysical, pType, NULL);
     }
 }
-void get_virtual_reg(u2 vB, OpndSize size, int reg, bool isPhysical) {
+void get_virtual_reg(int vB, OpndSize size, int reg, bool isPhysical) {
     Mnemonic m = (size == OpndSize_64) ? Mnemonic_MOVQ : Mnemonic_MOV;
     return get_virtual_reg_all(vB, size, reg, isPhysical, m);
 }
-void get_virtual_reg_noalloc(u2 vB, OpndSize size, int reg, bool isPhysical) {
+void get_virtual_reg_noalloc(int vB, OpndSize size, int reg, bool isPhysical) {
     Mnemonic m = (size == OpndSize_64) ? Mnemonic_MOVQ : Mnemonic_MOV;
     dump_mem_reg_noalloc(m, size, 4*vB, PhysicalReg_FP, true,
         MemoryAccess_VR, vB, reg, isPhysical, getTypeFromIntSize(size));
@@ -2639,7 +2639,7 @@ void get_virtual_reg_noalloc(u2 vB, OpndSize size, int reg, bool isPhysical) {
 //!load from a temporary to a VR
 
 //!
-void set_virtual_reg_all(u2 vA, OpndSize size, int reg, bool isPhysical, Mnemonic m) {
+void set_virtual_reg_all(int vA, OpndSize size, int reg, bool isPhysical, Mnemonic m) {
     LowOpndRegType type = getTypeFromIntSize(size);
     LowOpndRegType pType = type;//gp or xmm
     OpndSize size2 = size;
@@ -2699,11 +2699,11 @@ void set_virtual_reg_all(u2 vA, OpndSize size, int reg, bool isPhysical, Mnemoni
             MemoryAccess_VR, vA, pType);
     }
 }
-void set_virtual_reg(u2 vA, OpndSize size, int reg, bool isPhysical) {
+void set_virtual_reg(int vA, OpndSize size, int reg, bool isPhysical) {
     Mnemonic m = (size == OpndSize_64) ? Mnemonic_MOVQ : Mnemonic_MOV;
     return set_virtual_reg_all(vA, size, reg, isPhysical, m);
 }
-void set_virtual_reg_noalloc(u2 vA, OpndSize size, int reg, bool isPhysical) {
+void set_virtual_reg_noalloc(int vA, OpndSize size, int reg, bool isPhysical) {
     Mnemonic m = (size == OpndSize_64) ? Mnemonic_MOVQ : Mnemonic_MOV;
     dump_reg_mem_noalloc(m, size, reg, isPhysical, 4*vA, PhysicalReg_FP, true,
         MemoryAccess_VR, vA, getTypeFromIntSize(size));
@@ -2721,13 +2721,6 @@ void set_VR_sd(int vA, int reg, bool isPhysical) {
     return set_virtual_reg_all(vA, OpndSize_64, reg, isPhysical, Mnemonic_MOVSD);
 }
 ////////////////////////////////// END: IA32 native instructions //////////////
-//! generate native instructions to get current PC in the stack frame
-
-//!
-int get_currentpc(int reg, bool isPhysical) {
-    move_mem_to_reg(OpndSize_32, -sizeofStackSaveArea+offStackSaveArea_localRefTop, PhysicalReg_FP, true, reg, isPhysical);
-    return 1;
-}
 
 //! \brief generate native code to perform null check
 //!
@@ -2762,7 +2755,7 @@ int boundCheck(int vr_array, int reg_array, bool isPhysical_array,
         return 0;
     }
 #endif
-    compare_mem_reg(OpndSize_32, offArrayObject_length,
+    compare_mem_reg(OpndSize_32, OFFSETOF_MEMBER(ArrayObject, length),
                     reg_array, isPhysical_array,
                     reg_index, isPhysical_index);
 
@@ -2902,6 +2895,7 @@ int handlePotentialException(
 
     return 0;
 }
+
 //!generate native code to get the self pointer from glue
 
 //!It uses one scratch register
@@ -2909,40 +2903,7 @@ int get_self_pointer(int reg, bool isPhysical) {
     move_mem_to_reg(OpndSize_32, offEBP_self, PhysicalReg_EBP, true, reg, isPhysical);
     return 0;
 }
-//!generate native code to get ResStrings from glue
 
-//!It uses two scratch registers
-int get_res_strings(int reg, bool isPhysical) {
-    int retCode = 0;
-    //if spill_loc_index > 0 || reg != NULL, use registerAlloc
-    if(isGlueHandled(PhysicalReg_GLUE_DVMDEX)) {
-        //if spill_loc_index > 0
-        //  load from spilled location, update spill_loc_index & physicalReg
-#if 0
-        updateRefCount2(C_SCRATCH_1, LowOpndRegType_gp, isScratchPhysical);
-        updateRefCount2(C_SCRATCH_1, LowOpndRegType_gp, isScratchPhysical);
-        updateRefCount2(C_SCRATCH_2, LowOpndRegType_gp, isScratchPhysical);
-        updateRefCount2(C_SCRATCH_2, LowOpndRegType_gp, isScratchPhysical);
-#endif
-        startNativeCode(-1, -1);
-        freeReg(true);
-        int regAll = registerAlloc(LowOpndRegType_gp, PhysicalReg_GLUE_DVMDEX, false, false/*updateRefCount*/, true);
-        donotSpillReg(regAll);
-        dump_mem_reg_noalloc_mem(Mnemonic_MOV, ATOM_NORMAL, OpndSize_32, offDvmDex_pResStrings, regAll, true, MemoryAccess_Unknown, -1, reg, isPhysical, LowOpndRegType_gp);
-        endNativeCode();
-    }
-    else
-        {
-            get_self_pointer(C_SCRATCH_1, isScratchPhysical);
-            move_mem_to_reg(OpndSize_32, offsetof(Thread, interpSave.methodClassDex), C_SCRATCH_1, isScratchPhysical, C_SCRATCH_2, isScratchPhysical);
-            //glue is not in a physical reg nor in a spilled location
-            retCode = updateGlue(C_SCRATCH_2, isScratchPhysical, PhysicalReg_GLUE_DVMDEX); //spill_loc_index is -1, set physicalReg
-            if (retCode < 0)
-                return retCode;
-            move_mem_to_reg(OpndSize_32, offDvmDex_pResStrings, C_SCRATCH_2, isScratchPhysical, reg, isPhysical);
-        }
-    return 0;
-}
 int get_res_classes(int reg, bool isPhysical) {
     int retCode = 0;
     //if spill_loc_index > 0 || reg != NULL, use registerAlloc
@@ -2953,7 +2914,7 @@ int get_res_classes(int reg, bool isPhysical) {
         freeReg(true);
         int regAll = registerAlloc(LowOpndRegType_gp, PhysicalReg_GLUE_DVMDEX, false, false/*updateRefCount*/, true);
         donotSpillReg(regAll);
-        dump_mem_reg_noalloc_mem(Mnemonic_MOV, ATOM_NORMAL, OpndSize_32, offDvmDex_pResClasses, regAll, true, MemoryAccess_Unknown, -1, reg, isPhysical, LowOpndRegType_gp);
+        dump_mem_reg_noalloc_mem(Mnemonic_MOV, ATOM_NORMAL, OpndSize_32, OFFSETOF_MEMBER(DvmDex, pResClasses), regAll, true, MemoryAccess_Unknown, -1, reg, isPhysical, LowOpndRegType_gp);
         endNativeCode();
     }
     else
@@ -2964,38 +2925,11 @@ int get_res_classes(int reg, bool isPhysical) {
             retCode = updateGlue(C_SCRATCH_2, isScratchPhysical, PhysicalReg_GLUE_DVMDEX); //spill_loc_index is -1, set physicalReg
             if (retCode < 0)
                 return retCode;
-            move_mem_to_reg(OpndSize_32, offDvmDex_pResClasses, C_SCRATCH_2, isScratchPhysical, reg, isPhysical);
+            move_mem_to_reg(OpndSize_32, OFFSETOF_MEMBER(DvmDex, pResClasses), C_SCRATCH_2, isScratchPhysical, reg, isPhysical);
         }
     return 0;
 }
-//!generate native code to get ResFields from glue
 
-//!It uses two scratch registers
-int get_res_fields(int reg, bool isPhysical) {
-    int retCode = 0;
-    //if spill_loc_index > 0 || reg != NULL, use registerAlloc
-    if(isGlueHandled(PhysicalReg_GLUE_DVMDEX)) {
-        //if spill_loc_index > 0
-        //  load from spilled location, updte spill_loc_index & physicalReg
-        startNativeCode(-1, -1);
-        freeReg(true);
-        int regAll = registerAlloc(LowOpndRegType_gp, PhysicalReg_GLUE_DVMDEX, false, false/*updateRefCount*/, true);
-        donotSpillReg(regAll);
-        dump_mem_reg_noalloc_mem(Mnemonic_MOV, ATOM_NORMAL, OpndSize_32, offDvmDex_pResFields, regAll, true, MemoryAccess_Unknown, -1, reg, isPhysical, LowOpndRegType_gp);
-        endNativeCode();
-    }
-    else
-        {
-            get_self_pointer(C_SCRATCH_1, isScratchPhysical);
-            move_mem_to_reg(OpndSize_32, offsetof(Thread, interpSave.methodClassDex), C_SCRATCH_1, isScratchPhysical, C_SCRATCH_2, isScratchPhysical);
-            //glue is not in a physical reg nor in a spilled location
-            retCode = updateGlue(C_SCRATCH_2, isScratchPhysical, PhysicalReg_GLUE_DVMDEX); //spill_loc_index is -1, set physicalReg
-            if (retCode < 0)
-                return retCode;
-            move_mem_to_reg(OpndSize_32, offDvmDex_pResFields, C_SCRATCH_2, isScratchPhysical, reg, isPhysical);
-        }
-    return 0;
-}
 //!generate native code to get ResMethods from glue
 
 //!It uses two scratch registers
@@ -3009,7 +2943,7 @@ int get_res_methods(int reg, bool isPhysical) {
         freeReg(true);
         int regAll = registerAlloc(LowOpndRegType_gp, PhysicalReg_GLUE_DVMDEX, false, false/*updateRefCount*/, true);
         donotSpillReg(regAll);
-        dump_mem_reg_noalloc_mem(Mnemonic_MOV, ATOM_NORMAL, OpndSize_32, offDvmDex_pResMethods, regAll, true, MemoryAccess_Unknown, -1, reg, isPhysical, LowOpndRegType_gp);
+        dump_mem_reg_noalloc_mem(Mnemonic_MOV, ATOM_NORMAL, OpndSize_32, OFFSETOF_MEMBER(DvmDex, pResMethods), regAll, true, MemoryAccess_Unknown, -1, reg, isPhysical, LowOpndRegType_gp);
         endNativeCode();
     }
     else
@@ -3020,7 +2954,7 @@ int get_res_methods(int reg, bool isPhysical) {
             retCode = updateGlue(C_SCRATCH_2, isScratchPhysical, PhysicalReg_GLUE_DVMDEX); //spill_loc_index is -1, set physicalReg
             if (retCode < 0)
                 return retCode;
-            move_mem_to_reg(OpndSize_32, offDvmDex_pResMethods, C_SCRATCH_2, isScratchPhysical, reg, isPhysical);
+            move_mem_to_reg(OpndSize_32, OFFSETOF_MEMBER(DvmDex, pResMethods), C_SCRATCH_2, isScratchPhysical, reg, isPhysical);
         }
     return 0;
 }
@@ -3030,7 +2964,7 @@ int get_res_methods(int reg, bool isPhysical) {
 int get_glue_method_class(int reg, bool isPhysical) {
     get_self_pointer(C_SCRATCH_1, isScratchPhysical);
     move_mem_to_reg(OpndSize_32, offsetof(Thread, interpSave.method), C_SCRATCH_1, isScratchPhysical, C_SCRATCH_2, isScratchPhysical);
-    move_mem_to_reg(OpndSize_32, offMethod_clazz, C_SCRATCH_2, isScratchPhysical, reg, isPhysical);
+    move_mem_to_reg(OpndSize_32, OFFSETOF_MEMBER(Method, clazz), C_SCRATCH_2, isScratchPhysical, reg, isPhysical);
     return 0;
 }
 //!generate native code to get the current method from glue
@@ -3159,22 +3093,12 @@ int set_exception(int reg, bool isPhysical) {
     move_reg_to_mem(OpndSize_32, reg, isPhysical, offsetof(Thread, exception), C_SCRATCH_2, isScratchPhysical);
     return 0;
 }
-//!generate native code to save frame pointer and current PC in stack frame to glue
 
-//!It uses two scratch registers
-int save_pc_fp_to_glue() {
-    get_self_pointer(C_SCRATCH_1, isScratchPhysical);
-    move_reg_to_mem(OpndSize_32, PhysicalReg_FP, true, offsetof(Thread, interpSave.curFrame), C_SCRATCH_1, isScratchPhysical);
-
-    //from stack-save currentPc
-    move_mem_to_reg(OpndSize_32, -sizeofStackSaveArea+offStackSaveArea_localRefTop, PhysicalReg_FP, true, C_SCRATCH_2, isScratchPhysical);
-    move_reg_to_mem(OpndSize_32, C_SCRATCH_2, isScratchPhysical, offsetof(Thread, interpSave.pc), C_SCRATCH_1, isScratchPhysical);
-    return 0;
-}
 //! get SaveArea pointer
 
 //!
 int savearea_from_fp(int reg, bool isPhysical) {
+    int sizeofStackSaveArea = sizeof(StackSaveArea);
     load_effective_addr(-sizeofStackSaveArea, PhysicalReg_FP, true, reg, isPhysical);
     return 0;
 }
diff --git a/vm/compiler/codegen/x86/LowerInvoke.cpp b/vm/compiler/codegen/x86/LowerInvoke.cpp
index 801917f..d294c86 100644
--- a/vm/compiler/codegen/x86/LowerInvoke.cpp
+++ b/vm/compiler/codegen/x86/LowerInvoke.cpp
@@ -82,7 +82,7 @@ static void genLandingPadForMispredictedCallee(MIR* mir) {
 //! LOWER bytecode INVOKE_VIRTUAL without usage of helper function
 
 //!
-int common_invoke_virtual_nohelper(bool isRange, u2 tmp, u2 vD, const MIR *mir)
+int common_invoke_virtual_nohelper(bool isRange, u2 tmp, int vD, const MIR *mir)
 {
     const DecodedInstruction &decodedInst = mir->dalvikInsn;
 
@@ -133,7 +133,7 @@ int common_invoke_virtual_nohelper(bool isRange, u2 tmp, u2 vD, const MIR *mir)
 //! wrapper to call either common_invoke_virtual_helper or common_invoke_virtual_nohelper
 
 //!
-int common_invoke_virtual(bool isRange, u2 tmp, u2 vD) {
+int common_invoke_virtual(bool isRange, u2 tmp, int vD) {
     return common_invoke_virtual_nohelper(isRange, tmp, vD);
 }
 #endif
@@ -216,7 +216,7 @@ int invoke_super_nsm(void) {
     if (insertLabel(".invoke_super_nsm", false) == -1)
         return -1;
     //NOTE: it seems that the name in %edx is not used in common_errNoSuchMethod
-    move_mem_to_reg(OpndSize_32, offMethod_name, PhysicalReg_EAX, true, PhysicalReg_EDX, true); //method name
+    move_mem_to_reg(OpndSize_32, OFFSETOF_MEMBER(Method, name), PhysicalReg_EAX, true, PhysicalReg_EDX, true); //method name
     unconditional_jump("common_errNoSuchMethod", false);
     return 0;
 }
@@ -234,7 +234,7 @@ int invoke_super_nsm(void) {
 //! common section to lower INVOKE_DIRECT
 
 //! It will use helper function if the switch is on
-int common_invoke_direct(bool isRange, u2 tmp, u2 vD, const MIR *mir)
+int common_invoke_direct(bool isRange, u2 tmp, int vD, const MIR *mir)
 {
     const DecodedInstruction &decodedInst = mir->dalvikInsn;
     //%ecx can be used as scratch when calling export_pc, get_res_methods and resolve_method
@@ -354,7 +354,7 @@ int common_invoke_static(bool isRange, u2 tmp,
 //! common section to lower INVOKE_INTERFACE
 
 //! It will use helper function if the switch is on
-int common_invoke_interface(bool isRange, u2 tmp, u2 vD, const MIR *mir) {
+int common_invoke_interface(bool isRange, u2 tmp, int vD, const MIR *mir) {
 
     const DecodedInstruction &decodedInst = mir->dalvikInsn;
 
@@ -432,7 +432,7 @@ int op_invoke_virtual(const MIR * mir) {
     // C: the first argument, which is the "this" pointer
     // A: argument count
     // C, D, E, F, G: arguments
-    u2 vD = mir->dalvikInsn.vC; /* Note: variable is still named vD because
+    int vD = mir->dalvikInsn.vC; /* Note: variable is still named vD because
                                                of historical reasons. In reality, first
                                                argument is in vC */
     u2 tmp = mir->dalvikInsn.vB;
@@ -477,7 +477,7 @@ int op_invoke_direct(const MIR * mir) {
     // C: the first argument, which is the "this" pointer
     // A: argument count
     // C, D, E, F, G: arguments
-    u2 vD = mir->dalvikInsn.vC; /* Note: variable is still named vD because
+    int vD = mir->dalvikInsn.vC; /* Note: variable is still named vD because
                                                of historical reasons. In reality, first
                                                argument is in vC */
     u2 tmp = mir->dalvikInsn.vB;
@@ -522,7 +522,7 @@ int op_invoke_interface(const MIR * mir) {
     // C: the first argument, which is the "this" pointer
     // A: argument count
     // C, D, E, F, G: arguments
-    u2 vD = mir->dalvikInsn.vC; /* Note: variable is still named vD because
+    int vD = mir->dalvikInsn.vC; /* Note: variable is still named vD because
                                                of historical reasons. In reality, first
                                                argument is in vC */
     u2 tmp = mir->dalvikInsn.vB;
@@ -545,7 +545,7 @@ int op_invoke_virtual_range(const MIR * mir) {
     //AA|op BBBB CCCC
     //CCCC: the first argument, which is the "this" pointer
     //AA: argument count
-    u2 vD = mir->dalvikInsn.vC; /* Note: variable is still named vD because
+    int vD = mir->dalvikInsn.vC; /* Note: variable is still named vD because
                                                of historical reasons. In reality, first
                                                argument is in vCCCC */
     u2 tmp = mir->dalvikInsn.vB; //BBBB, method index
@@ -582,7 +582,7 @@ int op_invoke_direct_range(const MIR * mir) {
     if (mir->OptimizationFlags & MIR_INLINED)
         return 0;
 #endif
-    u2 vD = mir->dalvikInsn.vC; /* Note: variable is still named vD because
+    int vD = mir->dalvikInsn.vC; /* Note: variable is still named vD because
                                                of historical reasons. In reality, first
                                                argument is in vCCCC */
     u2 tmp = mir->dalvikInsn.vB; //BBBB, method index
@@ -619,7 +619,7 @@ int op_invoke_interface_range(const MIR * mir) {
     if (mir->OptimizationFlags & MIR_INLINED)
         return 0;
 #endif
-    u2 vD = mir->dalvikInsn.vC; /* Note: variable is still named vD because
+    int vD = mir->dalvikInsn.vC; /* Note: variable is still named vD because
                                                of historical reasons. In reality, first
                                                argument is in vCCCC */
     u2 tmp = mir->dalvikInsn.vB; //BBBB, method index
@@ -649,6 +649,7 @@ int common_invokeMethodNoRange_noJmp(const DecodedInstruction &decodedInst) {
     int startStreamPtr = (int)stream;
 #endif
     u2 count = decodedInst.vA;
+    int sizeofStackSaveArea = sizeof(StackSaveArea);
     int offsetFromSaveArea = -4 * count;
     int numQuad = 0; // keeping track of xmm moves
     int numMov = 0; // keeping track of gp moves
@@ -795,7 +796,7 @@ int common_invokeMethodRange_noJmp(const DecodedInstruction &decodedInst) {
 #endif
 
     u2 count = decodedInst.vA;
-    u2 vD = decodedInst.vC; //the first argument
+    int vD = decodedInst.vC; //the first argument
 
     savearea_from_fp(21, false);
     //vD to rFP-4*count-20
@@ -928,6 +929,7 @@ int common_invokeArgsDone(ArgsDoneType form) {
 #if defined VTUNE_DALVIK
     int startStreamPtr = (int)stream;
 #endif
+    int sizeofStackSaveArea = sizeof(StackSaveArea);
 
     // Define scratch registers
     scratchRegs[0] = PhysicalReg_EBX;
@@ -1139,6 +1141,8 @@ int common_invokeArgsDone(ArgsDoneType form) {
      with the interpreter or with JIT'ed code if chained
 */
 int generate_invokeNative() {
+    int sizeofStackSaveArea = sizeof(StackSaveArea);
+
     if (insertLabel(".invokeNative", true) == -1)
         return -1;
 
@@ -1154,9 +1158,9 @@ int generate_invokeNative() {
     move_reg_to_mem(OpndSize_32, PhysicalReg_EAX, true, 24, PhysicalReg_ESP, true);
     move_mem_to_reg(OpndSize_32, offThread_jniLocal_nextEntry, PhysicalReg_EAX, true, PhysicalReg_EDX, true); //get self->local_next
     scratchRegs[1] = PhysicalReg_EAX;
-    move_reg_to_mem(OpndSize_32, PhysicalReg_EDX, true, offStackSaveArea_localRefTop-sizeofStackSaveArea, PhysicalReg_EBX, true); //update jniLocalRef of stack
-    move_reg_to_mem(OpndSize_32, PhysicalReg_EBX, true, offThread_curFrame, PhysicalReg_EAX, true); //set self->curFrame
-    move_imm_to_mem(OpndSize_32, 0, offThread_inJitCodeCache, PhysicalReg_EAX, true); //clear self->inJitCodeCache
+    move_reg_to_mem(OpndSize_32, PhysicalReg_EDX, true, OFFSETOF_MEMBER(StackSaveArea, xtra.currentPc) - sizeofStackSaveArea, PhysicalReg_EBX, true); //update jniLocalRef of stack
+    move_reg_to_mem(OpndSize_32, PhysicalReg_EBX, true, OFFSETOF_MEMBER(Thread, interpSave.curFrame), PhysicalReg_EAX, true); //set self->curFrame
+    move_imm_to_mem(OpndSize_32, 0, OFFSETOF_MEMBER(Thread, inJitCodeCache), PhysicalReg_EAX, true); //clear self->inJitCodeCache
     load_effective_addr(OFFSETOF_MEMBER(Thread, interpSave.retval), PhysicalReg_EAX, true, PhysicalReg_EAX, true); //self->retval
     move_reg_to_mem(OpndSize_32, PhysicalReg_EAX, true, 4, PhysicalReg_ESP, true);
     //NOTE: native method checks the interpreted stack for arguments
@@ -1167,11 +1171,11 @@ int generate_invokeNative() {
     move_mem_to_reg(OpndSize_32, 20, PhysicalReg_ESP, true, PhysicalReg_ESI, true); //new FP
     move_mem_to_reg(OpndSize_32, 24, PhysicalReg_ESP, true, PhysicalReg_EBX, true); //glue->self
     load_effective_addr(28, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
-    move_mem_to_reg(OpndSize_32, offStackSaveArea_localRefTop-sizeofStackSaveArea, PhysicalReg_ESI, true, PhysicalReg_EAX, true); //newSaveArea->jniLocal
-    compare_imm_mem(OpndSize_32, 0, offThread_exception, PhysicalReg_EBX, true); //self->exception
+    move_mem_to_reg(OpndSize_32, OFFSETOF_MEMBER(StackSaveArea, xtra.currentPc) - sizeofStackSaveArea, PhysicalReg_ESI, true, PhysicalReg_EAX, true); //newSaveArea->jniLocal
+    compare_imm_mem(OpndSize_32, 0, OFFSETOF_MEMBER(Thread, exception), PhysicalReg_EBX, true); //self->exception
     load_effective_addr(8, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
     //NOTE: PhysicalReg_FP should be callee-saved register
-    move_reg_to_mem(OpndSize_32, PhysicalReg_FP, true, offThread_curFrame, PhysicalReg_EBX, true); //set self->curFrame
+    move_reg_to_mem(OpndSize_32, PhysicalReg_FP, true, OFFSETOF_MEMBER(Thread, interpSave.curFrame), PhysicalReg_EBX, true); //set self->curFrame
     move_reg_to_mem(OpndSize_32, PhysicalReg_EAX, true, offThread_jniLocal_nextEntry, PhysicalReg_EBX, true); //set self->jniLocal
     conditional_jump(Condition_NE, "common_exceptionThrown", false);
 
@@ -1181,10 +1185,10 @@ int generate_invokeNative() {
        update returnAddr and check returnAddr after done with the native method
        if returnAddr is set to NULL during code cache reset,
        the execution will correctly continue with interpreter */
-    move_mem_to_reg(OpndSize_32, offStackSaveArea_returnAddr-sizeofStackSaveArea, PhysicalReg_ESI, true, PhysicalReg_EDX, true);
+    move_mem_to_reg(OpndSize_32, OFFSETOF_MEMBER(StackSaveArea, returnAddr)-sizeofStackSaveArea, PhysicalReg_ESI, true, PhysicalReg_EDX, true);
     //set self->inJitCodeCache to returnAddr (PhysicalReg_EBX is in %ebx)
-    move_reg_to_mem(OpndSize_32, PhysicalReg_EDX, true, offThread_inJitCodeCache, PhysicalReg_EBX, true);
-    move_mem_to_reg(OpndSize_32, offStackSaveArea_savedPc-sizeofStackSaveArea, PhysicalReg_ESI, true, PhysicalReg_EBX, true); //savedPc
+    move_reg_to_mem(OpndSize_32, PhysicalReg_EDX, true, OFFSETOF_MEMBER(Thread, inJitCodeCache), PhysicalReg_EBX, true);
+    move_mem_to_reg(OpndSize_32, OFFSETOF_MEMBER(StackSaveArea, savedPc) - sizeofStackSaveArea, PhysicalReg_ESI, true, PhysicalReg_EBX, true); //savedPc
     compare_imm_reg(OpndSize_32, 0, PhysicalReg_EDX, true);
     conditional_jump(Condition_E, ".nativeToInterp", true);
     unconditional_jump_reg(PhysicalReg_EDX, true);
@@ -1232,7 +1236,7 @@ int op_execute_inline(const MIR * mir, bool isRange) {
             || mir->dalvikInsn.opcode == OP_EXECUTE_INLINE_RANGE);
     int num = mir->dalvikInsn.vA;
     u2 tmp = mir->dalvikInsn.vB;
-    u2 vC, vD, vE, vF;
+    int vC, vD, vE, vF;
     if(!isRange) {
         // Note that vC, vD, vE, and vF might have bad values
         // depending on count. The variable "num" should be
@@ -1264,7 +1268,7 @@ int op_execute_inline(const MIR * mir, bool isRange) {
                 return -1;
             move_mem_to_reg(OpndSize_32, 0x14, 1, false, 2, false);
             get_self_pointer(3, false);
-            move_reg_to_mem(OpndSize_32, 2, false, offsetof(Thread, interpSave.retval), 3, false);
+            move_reg_to_mem(OpndSize_32, 2, false, OFFSETOF_MEMBER(Thread, interpSave.retval), 3, false);
             return 0;
         case INLINE_STRING_IS_EMPTY:
             get_virtual_reg(vC, OpndSize_32, 1, false);
@@ -1281,12 +1285,12 @@ int op_execute_inline(const MIR * mir, bool isRange) {
             conditional_jump(Condition_E, ".inlined_string_length_return_true",
                              true);
             get_self_pointer(2, false);
-            move_imm_to_mem(OpndSize_32, 0, offsetof(Thread, interpSave.retval), 2, false);
+            move_imm_to_mem(OpndSize_32, 0, OFFSETOF_MEMBER(Thread, interpSave.retval), 2, false);
             unconditional_jump(".inlined_string_length_done", true);
             if (insertLabel(".inlined_string_length_return_true", true) == -1)
                 return -1;
             get_self_pointer(2, false);
-            move_imm_to_mem(OpndSize_32, 1, offsetof(Thread, interpSave.retval), 2, false);
+            move_imm_to_mem(OpndSize_32, 1, OFFSETOF_MEMBER(Thread, interpSave.retval), 2, false);
             if (insertLabel(".inlined_string_length_done", true) == -1)
                 return -1;
             return 0;
@@ -1297,7 +1301,7 @@ int op_execute_inline(const MIR * mir, bool isRange) {
             alu_binary_reg_reg(OpndSize_32, xor_opc, 2, false, 1, false);
             alu_binary_reg_reg(OpndSize_32, sub_opc, 2, false, 1, false);
             get_self_pointer(3, false);
-            move_reg_to_mem(OpndSize_32, 1, false, offsetof(Thread, interpSave.retval), 3, false);
+            move_reg_to_mem(OpndSize_32, 1, false, OFFSETOF_MEMBER(Thread, interpSave.retval), 3, false);
             return 0;
         case INLINE_MATH_ABS_LONG:
             get_virtual_reg(vD, OpndSize_32, 1, false);
@@ -1308,11 +1312,11 @@ int op_execute_inline(const MIR * mir, bool isRange) {
             get_virtual_reg(vC, OpndSize_32, 5, false);
             alu_binary_reg_reg(OpndSize_32, xor_opc, 5, false, 1, false);
             get_self_pointer(6, false);
-            move_reg_to_mem(OpndSize_32, 1, false, offsetof(Thread, interpSave.retval), 6, false);
+            move_reg_to_mem(OpndSize_32, 1, false, OFFSETOF_MEMBER(Thread, interpSave.retval), 6, false);
             alu_binary_reg_reg(OpndSize_32, xor_opc, 2, false, 3, false);
-            move_reg_to_mem(OpndSize_32, 3, false, 4 + offsetof(Thread, interpSave.retval), 6, false);
-            alu_binary_reg_mem(OpndSize_32, sub_opc, 4, false, offsetof(Thread, interpSave.retval), 6, false);
-            alu_binary_reg_mem(OpndSize_32, sbb_opc, 4, false, 4 + offsetof(Thread, interpSave.retval), 6, false);
+            move_reg_to_mem(OpndSize_32, 3, false, 4 + OFFSETOF_MEMBER(Thread, interpSave.retval), 6, false);
+            alu_binary_reg_mem(OpndSize_32, sub_opc, 4, false, OFFSETOF_MEMBER(Thread, interpSave.retval), 6, false);
+            alu_binary_reg_mem(OpndSize_32, sbb_opc, 4, false, 4 + OFFSETOF_MEMBER(Thread, interpSave.retval), 6, false);
             return 0;
         case INLINE_MATH_MAX_INT:
             get_virtual_reg(vC, OpndSize_32, 1, false);
@@ -1321,7 +1325,7 @@ int op_execute_inline(const MIR * mir, bool isRange) {
             conditional_move_reg_to_reg(OpndSize_32, Condition_GE, 2,
                                         false/*src*/, 1, false/*dst*/);
             get_self_pointer(3, false);
-            move_reg_to_mem(OpndSize_32, 1, false, offsetof(Thread, interpSave.retval), 3, false);
+            move_reg_to_mem(OpndSize_32, 1, false, OFFSETOF_MEMBER(Thread, interpSave.retval), 3, false);
             return 0;
         case INLINE_MATH_MIN_INT:
             get_virtual_reg(vC, OpndSize_32, 1, false);
@@ -1330,21 +1334,21 @@ int op_execute_inline(const MIR * mir, bool isRange) {
             conditional_move_reg_to_reg(OpndSize_32, Condition_LE, 2,
                                         false/*src*/, 1, false/*dst*/);
             get_self_pointer(3, false);
-            move_reg_to_mem(OpndSize_32, 1, false, offsetof(Thread, interpSave.retval), 3, false);
+            move_reg_to_mem(OpndSize_32, 1, false, OFFSETOF_MEMBER(Thread, interpSave.retval), 3, false);
             return 0;
         case INLINE_MATH_ABS_FLOAT:
             get_virtual_reg(vC, OpndSize_32, 1, false);
             alu_binary_imm_reg(OpndSize_32, and_opc, 0x7fffffff, 1, false);
             get_self_pointer(2, false);
-            move_reg_to_mem(OpndSize_32, 1, false, offsetof(Thread, interpSave.retval), 2, false);
+            move_reg_to_mem(OpndSize_32, 1, false, OFFSETOF_MEMBER(Thread, interpSave.retval), 2, false);
             return 0;
         case INLINE_MATH_ABS_DOUBLE:
             get_virtual_reg(vC, OpndSize_32, 1, false);
             get_virtual_reg(vD, OpndSize_32, 2, false);
             alu_binary_imm_reg(OpndSize_32, and_opc, 0x7fffffff, 2, false);
             get_self_pointer(3, false);
-            move_reg_to_mem(OpndSize_32, 1, false, offsetof(Thread, interpSave.retval), 3, false);
-            move_reg_to_mem(OpndSize_32, 2, false, 4 + offsetof(Thread, interpSave.retval), 3, false);
+            move_reg_to_mem(OpndSize_32, 1, false, OFFSETOF_MEMBER(Thread, interpSave.retval), 3, false);
+            move_reg_to_mem(OpndSize_32, 2, false, 4 + OFFSETOF_MEMBER(Thread, interpSave.retval), 3, false);
             return 0;
         case INLINE_STRING_CHARAT:
             get_virtual_reg(vC, OpndSize_32, 1, false);
@@ -1375,9 +1379,9 @@ int op_execute_inline(const MIR * mir, bool isRange) {
                 return -1;
             alu_binary_mem_reg(OpndSize_32, add_opc, 0x10, 1, false, 2, false);
             move_mem_to_reg(OpndSize_32, 0x8, 1, false, 1, false);
-            movez_mem_disp_scale_to_reg(OpndSize_16, 1, false, offsetof(ArrayObject, contents)/*disp*/, 2, false, 2, 2, false);
+            movez_mem_disp_scale_to_reg(OpndSize_16, 1, false, OFFSETOF_MEMBER(ArrayObject, contents)/*disp*/, 2, false, 2, 2, false);
             get_self_pointer(3, false);
-            move_reg_to_mem(OpndSize_32, 2, false, offsetof(Thread, interpSave.retval), 3, false);
+            move_reg_to_mem(OpndSize_32, 2, false, OFFSETOF_MEMBER(Thread, interpSave.retval), 3, false);
             return 0;
         case INLINE_STRING_FASTINDEXOF_II:
 #if defined(USE_GLOBAL_STRING_DEFS)
@@ -1406,7 +1410,7 @@ int op_execute_inline(const MIR * mir, bool isRange) {
             compare_reg_reg(4, false, 1, false);
             conditional_jump(Condition_GE,
                              ".do_inlined_string_fastIndexof_exitfalse", true);
-            dump_mem_scale_reg(Mnemonic_LEA, OpndSize_32, 5, false, offsetof(ArrayObject, contents)/*disp*/,
+            dump_mem_scale_reg(Mnemonic_LEA, OpndSize_32, 5, false, OFFSETOF_MEMBER(ArrayObject, contents)/*disp*/,
                                6, false, 2, 5, false, LowOpndRegType_gp);
             movez_mem_disp_scale_to_reg(OpndSize_16, 5, false, 0, 1, false, 2,
                                         3, false);
@@ -1442,38 +1446,38 @@ int op_execute_inline(const MIR * mir, bool isRange) {
             if (insertLabel(".do_inlined_string_fastIndexof_exit", true) == -1)
                 return -1;
             get_self_pointer(7, false);
-            move_reg_to_mem(OpndSize_32, 1, false, offsetof(Thread, interpSave.retval), 7, false);
+            move_reg_to_mem(OpndSize_32, 1, false, OFFSETOF_MEMBER(Thread, interpSave.retval), 7, false);
             return 0;
         case INLINE_FLOAT_TO_RAW_INT_BITS:
             get_virtual_reg(vC, OpndSize_32, 1, false);
             get_self_pointer(2, false);
-            move_reg_to_mem(OpndSize_32, 1, false, offsetof(Thread, interpSave.retval), 2, false);
+            move_reg_to_mem(OpndSize_32, 1, false, OFFSETOF_MEMBER(Thread, interpSave.retval), 2, false);
             return 0;
         case INLINE_INT_BITS_TO_FLOAT:
             get_virtual_reg(vC, OpndSize_32, 1, false);
             get_self_pointer(2, false);
-            move_reg_to_mem(OpndSize_32, 1, false, offsetof(Thread, interpSave.retval), 2, false);
+            move_reg_to_mem(OpndSize_32, 1, false, OFFSETOF_MEMBER(Thread, interpSave.retval), 2, false);
             return 0;
         case INLINE_DOUBLE_TO_RAW_LONG_BITS:
             get_virtual_reg(vC, OpndSize_32, 1, false);
             get_self_pointer(3, false);
-            move_reg_to_mem(OpndSize_32, 1, false, offsetof(Thread, interpSave.retval), 3, false);
+            move_reg_to_mem(OpndSize_32, 1, false, OFFSETOF_MEMBER(Thread, interpSave.retval), 3, false);
             get_virtual_reg(vD, OpndSize_32, 2, false);
-            move_reg_to_mem(OpndSize_32, 2, false, 4 + offsetof(Thread, interpSave.retval), 3, false);
+            move_reg_to_mem(OpndSize_32, 2, false, 4 + OFFSETOF_MEMBER(Thread, interpSave.retval), 3, false);
             return 0;
         case INLINE_LONG_BITS_TO_DOUBLE:
             get_virtual_reg(vC, OpndSize_32, 1, false);
             get_virtual_reg(vD, OpndSize_32, 2, false);
             get_self_pointer(3, false);
-            move_reg_to_mem(OpndSize_32, 2, false, 4 + offsetof(Thread, interpSave.retval), 3, false);
-            move_reg_to_mem(OpndSize_32, 1, false, offsetof(Thread, interpSave.retval), 3, false);
+            move_reg_to_mem(OpndSize_32, 2, false, 4 + OFFSETOF_MEMBER(Thread, interpSave.retval), 3, false);
+            move_reg_to_mem(OpndSize_32, 1, false, OFFSETOF_MEMBER(Thread, interpSave.retval), 3, false);
             return 0;
         default:
                 break;
     }
 #endif
     get_self_pointer(PhysicalReg_SCRATCH_1, false);
-    load_effective_addr(offsetof(Thread, interpSave.retval), PhysicalReg_SCRATCH_1, false, 1, false);
+    load_effective_addr(OFFSETOF_MEMBER(Thread, interpSave.retval), PhysicalReg_SCRATCH_1, false, 1, false);
     load_effective_addr(-24, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
     move_reg_to_mem(OpndSize_32, 1, false, 16, PhysicalReg_ESP, true);
     if(num >= 1) {
@@ -1525,7 +1529,7 @@ int op_execute_inline(const MIR * mir, bool isRange) {
 //! common code for INVOKE_VIRTUAL_QUICK
 
 //! It uses helper function if the switch is on
-int common_invoke_virtual_quick(bool hasRange, u2 vD, u2 IMMC, const MIR *mir) {
+int common_invoke_virtual_quick(bool hasRange, int vD, u2 IMMC, const MIR *mir) {
 
     const DecodedInstruction &decodedInst = mir->dalvikInsn;
 
@@ -1581,7 +1585,7 @@ int op_invoke_virtual_quick(const MIR * mir) {
     if (mir->OptimizationFlags & MIR_INLINED)
         return 0;
 #endif
-    u2 vD = mir->dalvikInsn.vC;
+    int vD = mir->dalvikInsn.vC;
     u2 IMMC = 4 * mir->dalvikInsn.vB;
     int retval = common_invoke_virtual_quick(false, vD, IMMC, mir);
 #if defined(ENABLE_TRACING) && !defined(TRACING_OPTION2)
@@ -1599,7 +1603,7 @@ int op_invoke_virtual_quick_range(const MIR * mir) {
     if (mir->OptimizationFlags & MIR_INLINED)
         return 0;
 #endif
-    u2 vD = mir->dalvikInsn.vC;
+    int vD = mir->dalvikInsn.vC;
     u2 IMMC = 4 * mir->dalvikInsn.vB;
     int retval = common_invoke_virtual_quick(true, vD, IMMC, mir);
 #if defined(ENABLE_TRACING) && !defined(TRACING_OPTION2)
@@ -1613,7 +1617,7 @@ int op_invoke_virtual_quick_range(const MIR * mir) {
 //! common code to lower INVOKE_SUPER_QUICK
 
 //!
-int common_invoke_super_quick(bool hasRange, u2 vD, u2 IMMC,
+int common_invoke_super_quick(bool hasRange, int vD, u2 IMMC,
         const DecodedInstruction &decodedInst) {
     export_pc();
     beforeCall("exception"); //dump GG, GL VRs
@@ -1647,7 +1651,7 @@ int op_invoke_super_quick(const MIR * mir) {
     if (mir->OptimizationFlags & MIR_INLINED)
         return 0;
 #endif
-    u2 vD = mir->dalvikInsn.vC;
+    int vD = mir->dalvikInsn.vC;
     u2 IMMC = 4 * mir->dalvikInsn.vB;
     int retval = common_invoke_super_quick(false, vD, IMMC, mir->dalvikInsn);
 #if defined(ENABLE_TRACING) && !defined(TRACING_OPTION2)
@@ -1665,7 +1669,7 @@ int op_invoke_super_quick_range(const MIR * mir) {
     if (mir->OptimizationFlags & MIR_INLINED)
         return 0;
 #endif
-    u2 vD = mir->dalvikInsn.vC;
+    int vD = mir->dalvikInsn.vC;
     u2 IMMC = 4 * mir->dalvikInsn.vB;
     int retval = common_invoke_super_quick(true, vD, IMMC, mir->dalvikInsn);
 #if defined(ENABLE_TRACING) && !defined(TRACING_OPTION2)
@@ -1767,14 +1771,14 @@ void predicted_chain_interface_O1(u2 tmp) {
     move_mem_to_reg(OpndSize_32, offChainingCell_clazz, 41, false, 45, false);
     move_imm_to_reg(OpndSize_32, 0, 43, false);
     get_self_pointer(PhysicalReg_SCRATCH_7, isScratchPhysical);
-    move_mem_to_reg(OpndSize_32, offsetof(Thread, icRechainCount), PhysicalReg_SCRATCH_7, isScratchPhysical, 33, false); //counter
+    move_mem_to_reg(OpndSize_32, OFFSETOF_MEMBER(Thread, icRechainCount), PhysicalReg_SCRATCH_7, isScratchPhysical, 33, false); //counter
     move_reg_to_reg(OpndSize_32, 33, false, 44, false);
     alu_binary_imm_reg(OpndSize_32, sub_opc, 0x1, 33, false);
     /* sub_opc will update control flags, so compare_imm_reg must happen after */
     compare_imm_reg(OpndSize_32, 0, 45, false);
     conditional_move_reg_to_reg(OpndSize_32, Condition_NZ, 33, false/*src*/, 43, false/*dst*/);
     conditional_move_reg_to_reg(OpndSize_32, Condition_NZ, 33, false/*src*/, 44, false/*dst*/);
-    move_reg_to_mem(OpndSize_32, 44, false, offsetof(Thread, icRechainCount), PhysicalReg_SCRATCH_7, isScratchPhysical);
+    move_reg_to_mem(OpndSize_32, 44, false, OFFSETOF_MEMBER(Thread, icRechainCount), PhysicalReg_SCRATCH_7, isScratchPhysical);
 #else
     /* reduce counter in chaining cell by 1 */
     move_mem_to_reg(OpndSize_32, offChainingCell_counter, 41, false, 33, false); //counter
@@ -1815,7 +1819,7 @@ void predicted_chain_virtual_O0(u2 IMMC) {
 
     /* reduce counter in chaining cell by 1 */
     move_mem_to_reg(OpndSize_32, offChainingCell_counter, P_GPR_1, true, P_GPR_2, true); //counter
-    move_mem_to_reg(OpndSize_32, offClassObject_vtable, P_GPR_3, true, P_SCRATCH_2, true);
+    move_mem_to_reg(OpndSize_32, OFFSETOF_MEMBER(ClassObject, vtable), P_GPR_3, true, P_SCRATCH_2, true);
     alu_binary_imm_reg(OpndSize_32, sub_opc, 0x1, P_GPR_2, true);
     move_mem_to_reg(OpndSize_32, IMMC, P_SCRATCH_2, true, PhysicalReg_ECX, true);
     move_reg_to_mem(OpndSize_32, P_GPR_2, true, offChainingCell_counter, P_GPR_1, true);
@@ -1852,15 +1856,15 @@ void predicted_chain_virtual_O1(u2 IMMC) {
     /* for gingerbread: t43 = 0 t44 = t33 t33-- cmov_ne t43 = t33 cmov_ne t44 = t33 */
     get_self_pointer(PhysicalReg_SCRATCH_7, isScratchPhysical);
     move_imm_to_reg(OpndSize_32, 0, 43, false);
-    move_mem_to_reg(OpndSize_32, offsetof(Thread, icRechainCount), PhysicalReg_SCRATCH_7, isScratchPhysical, 33, false); //counter
-    move_mem_to_reg(OpndSize_32, offClassObject_vtable, 40, false, 34, false);
+    move_mem_to_reg(OpndSize_32, OFFSETOF_MEMBER(Thread, icRechainCount), PhysicalReg_SCRATCH_7, isScratchPhysical, 33, false); //counter
+    move_mem_to_reg(OpndSize_32, OFFSETOF_MEMBER(ClassObject, vtable), 40, false, 34, false);
     move_reg_to_reg(OpndSize_32, 33, false, 44, false);
     alu_binary_imm_reg(OpndSize_32, sub_opc, 0x1, 33, false);
     compare_imm_reg(OpndSize_32, 0, 32, false); // after sub_opc
     move_mem_to_reg(OpndSize_32, IMMC, 34, false, PhysicalReg_ECX, true);
     conditional_move_reg_to_reg(OpndSize_32, Condition_NZ, 33, false/*src*/, 43, false/*dst*/);
     conditional_move_reg_to_reg(OpndSize_32, Condition_NZ, 33, false/*src*/, 44, false/*dst*/);
-    move_reg_to_mem(OpndSize_32, 44, false, offsetof(Thread, icRechainCount), PhysicalReg_SCRATCH_7, isScratchPhysical);
+    move_reg_to_mem(OpndSize_32, 44, false, OFFSETOF_MEMBER(Thread, icRechainCount), PhysicalReg_SCRATCH_7, isScratchPhysical);
 
     /* if counter is still greater than zero, skip prediction
        if it is zero, update predicted method */
@@ -1898,7 +1902,7 @@ void gen_predicted_chain_O0(bool isRange, u2 tmp, int IMMC, bool isInterface,
     ALOGI("TODO predicted_chain_O0");
 
     /* get current class object */
-    move_mem_to_reg(OpndSize_32, offObject_clazz, PhysicalReg_EBX, true,
+    move_mem_to_reg(OpndSize_32, OFFSETOF_MEMBER(Object, clazz), PhysicalReg_EBX, true,
              P_GPR_3, true);
 #ifdef DEBUG_CALL_STACK3
     scratchRegs[0] = PhysicalReg_EAX;
@@ -1996,7 +2000,7 @@ void gen_predicted_chain_O1(bool isRange, u2 tmp, int IMMC, bool isInterface,
         int inputReg, const DecodedInstruction &decodedInst) {
 
     /* get current class object */
-    move_mem_to_reg(OpndSize_32, offObject_clazz, inputReg, false,
+    move_mem_to_reg(OpndSize_32, OFFSETOF_MEMBER(Object, clazz), inputReg, false,
              40, false);
 
     /* get predicted clazz
diff --git a/vm/compiler/codegen/x86/LowerJump.cpp b/vm/compiler/codegen/x86/LowerJump.cpp
index 1f22f9a..644329d 100644
--- a/vm/compiler/codegen/x86/LowerJump.cpp
+++ b/vm/compiler/codegen/x86/LowerJump.cpp
@@ -1508,8 +1508,8 @@ int throw_exception_message(int exceptionPtrReg, int obj_reg, bool isPhysical,
     scratchRegs[0] = PhysicalReg_ESI; scratchRegs[1] = PhysicalReg_EDX;
     scratchRegs[2] = PhysicalReg_Null; scratchRegs[3] = PhysicalReg_Null;
 
-    move_mem_to_reg(OpndSize_32, offObject_clazz, obj_reg, isPhysical, C_SCRATCH_1, isScratchPhysical);
-    move_mem_to_reg(OpndSize_32, offClassObject_descriptor, C_SCRATCH_1, isScratchPhysical, C_SCRATCH_2, isScratchPhysical);
+    move_mem_to_reg(OpndSize_32, OFFSETOF_MEMBER(Object, clazz), obj_reg, isPhysical, C_SCRATCH_1, isScratchPhysical);
+    move_mem_to_reg(OpndSize_32, OFFSETOF_MEMBER(ClassObject, descriptor), C_SCRATCH_1, isScratchPhysical, C_SCRATCH_2, isScratchPhysical);
     load_effective_addr(-8, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
     move_reg_to_mem(OpndSize_32, C_SCRATCH_2, isScratchPhysical, 4, PhysicalReg_ESP, true);
     move_reg_to_mem(OpndSize_32, exceptionPtrReg, true, 0, PhysicalReg_ESP, true);
@@ -1618,7 +1618,7 @@ int op_goto_32(const MIR * mir) {
 int op_packed_switch(const MIR * mir, const u2 * dalvikPC) {
     int retCode = 0;
     assert(mir->dalvikInsn.opcode == OP_PACKED_SWITCH);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     u4 tmp = mir->dalvikInsn.vB;
 
 #ifdef DEBUG_EACH_BYTECODE
@@ -1687,7 +1687,7 @@ int op_packed_switch(const MIR * mir, const u2 * dalvikPC) {
 int op_sparse_switch(const MIR * mir, const u2 * dalvikPC) {
     int retCode = 0;
     assert(mir->dalvikInsn.opcode == OP_SPARSE_SWITCH);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     u4 tmp = mir->dalvikInsn.vB;
 #ifdef DEBUG_EACH_BYTECODE
     u2 tSize = 0;
@@ -1753,8 +1753,8 @@ int op_sparse_switch(const MIR * mir, const u2 * dalvikPC) {
  */
 int op_if_eq(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_IF_EQ);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 tmp = mir->dalvikInsn.vC;
     get_virtual_reg(vA, OpndSize_32, 1, false);
     compare_VR_reg(OpndSize_32, vB, 1, false);
@@ -1768,8 +1768,8 @@ int op_if_eq(const MIR * mir) {
  */
 int op_if_ne(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_IF_NE);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 tmp = mir->dalvikInsn.vC;
     get_virtual_reg(vA, OpndSize_32, 1, false);
     compare_VR_reg(OpndSize_32, vB, 1, false);
@@ -1783,8 +1783,8 @@ int op_if_ne(const MIR * mir) {
  */
 int op_if_lt(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_IF_LT);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 tmp = mir->dalvikInsn.vC;
     get_virtual_reg(vA, OpndSize_32, 1, false);
     compare_VR_reg(OpndSize_32, vB, 1, false);
@@ -1798,8 +1798,8 @@ int op_if_lt(const MIR * mir) {
  */
 int op_if_ge(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_IF_GE);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 tmp = mir->dalvikInsn.vC;
     get_virtual_reg(vA, OpndSize_32, 1, false);
     compare_VR_reg(OpndSize_32, vB, 1, false);
@@ -1813,8 +1813,8 @@ int op_if_ge(const MIR * mir) {
  */
 int op_if_gt(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_IF_GT);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 tmp = mir->dalvikInsn.vC;
     get_virtual_reg(vA, OpndSize_32, 1, false);
     compare_VR_reg(OpndSize_32, vB, 1, false);
@@ -1828,8 +1828,8 @@ int op_if_gt(const MIR * mir) {
  */
 int op_if_le(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_IF_LE);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     s2 tmp = mir->dalvikInsn.vC;
     get_virtual_reg(vA, OpndSize_32, 1, false);
     compare_VR_reg(OpndSize_32, vB, 1, false);
@@ -1844,7 +1844,7 @@ int op_if_le(const MIR * mir) {
  */
 int op_if_eqz(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_IF_EQZ);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     s2 tmp = mir->dalvikInsn.vB;
     compare_imm_VR(OpndSize_32, 0, vA);
     return common_if(tmp, Condition_NE, Condition_E);
@@ -1857,7 +1857,7 @@ int op_if_eqz(const MIR * mir) {
  */
 int op_if_nez(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_IF_NEZ);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     s2 tmp = mir->dalvikInsn.vB;
     compare_imm_VR(OpndSize_32, 0, vA);
     return common_if(tmp, Condition_E, Condition_NE);
@@ -1870,7 +1870,7 @@ int op_if_nez(const MIR * mir) {
  */
 int op_if_ltz(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_IF_LTZ);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     s2 tmp = mir->dalvikInsn.vB;
     compare_imm_VR(OpndSize_32, 0, vA);
     return common_if(tmp, Condition_GE, Condition_L);
@@ -1883,7 +1883,7 @@ int op_if_ltz(const MIR * mir) {
  */
 int op_if_gez(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_IF_GEZ);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     s2 tmp = mir->dalvikInsn.vB;
     compare_imm_VR(OpndSize_32, 0, vA);
     return common_if(tmp, Condition_L, Condition_GE);
@@ -1896,7 +1896,7 @@ int op_if_gez(const MIR * mir) {
  */
 int op_if_gtz(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_IF_GTZ);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     s2 tmp = mir->dalvikInsn.vB;
     compare_imm_VR(OpndSize_32, 0, vA);
     return common_if(tmp, Condition_LE, Condition_G);
@@ -1909,7 +1909,7 @@ int op_if_gtz(const MIR * mir) {
  */
 int op_if_lez(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_IF_LEZ);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     s2 tmp = mir->dalvikInsn.vB;
     compare_imm_VR(OpndSize_32, 0, vA);
     return common_if(tmp, Condition_G, Condition_LE);
diff --git a/vm/compiler/codegen/x86/LowerMove.cpp b/vm/compiler/codegen/x86/LowerMove.cpp
index 6a0e78b..03c69e6 100644
--- a/vm/compiler/codegen/x86/LowerMove.cpp
+++ b/vm/compiler/codegen/x86/LowerMove.cpp
@@ -34,8 +34,8 @@
 int op_move(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_MOVE
             || mir->dalvikInsn.opcode == OP_MOVE_OBJECT);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     get_virtual_reg(vB, OpndSize_32, 1, false/*isPhysical*/);
     set_virtual_reg(vA, OpndSize_32, 1, false);
     return 2;
@@ -50,8 +50,8 @@ int op_move(const MIR * mir) {
 int op_move_from16(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_MOVE_FROM16
             || mir->dalvikInsn.opcode == OP_MOVE_OBJECT_FROM16);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     get_virtual_reg(vB, OpndSize_32, 1, false);
     set_virtual_reg(vA, OpndSize_32, 1, false);
     return 2;
@@ -66,8 +66,8 @@ int op_move_from16(const MIR * mir) {
 int op_move_16(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_MOVE_16
             || mir->dalvikInsn.opcode == OP_MOVE_OBJECT_16);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     get_virtual_reg(vB, OpndSize_32, 1, false);
     set_virtual_reg(vA, OpndSize_32, 1, false);
     return 2;
@@ -81,8 +81,8 @@ int op_move_16(const MIR * mir) {
  */
 int op_move_wide(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_MOVE_WIDE);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     get_virtual_reg(vB, OpndSize_64, 1, false);
     set_virtual_reg(vA, OpndSize_64, 1, false);
     return 2;
@@ -95,8 +95,8 @@ int op_move_wide(const MIR * mir) {
  */
 int op_move_wide_from16(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_MOVE_WIDE_FROM16);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     get_virtual_reg(vB, OpndSize_64, 1, false);
     set_virtual_reg(vA, OpndSize_64, 1, false);
     return 2;
@@ -109,8 +109,8 @@ int op_move_wide_from16(const MIR * mir) {
  */
 int op_move_wide_16(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_MOVE_WIDE_16);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     get_virtual_reg(vB, OpndSize_64, 1, false);
     set_virtual_reg(vA, OpndSize_64, 1, false);
     return 2;
@@ -130,7 +130,7 @@ int op_move_result(const MIR * mir) {
     if (mir->OptimizationFlags & MIR_INLINED)
         return 0;
 #endif
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     scratchRegs[0] = PhysicalReg_SCRATCH_1;
     get_return_value(OpndSize_32, 1, false);
     set_virtual_reg(vA, OpndSize_32, 1, false);
@@ -149,7 +149,7 @@ int op_move_result_wide(const MIR * mir) {
     if (mir->OptimizationFlags & MIR_INLINED)
         return 0;
 #endif
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     scratchRegs[0] = PhysicalReg_SCRATCH_1;
     get_return_value(OpndSize_64, 1, false);
     set_virtual_reg(vA, OpndSize_64, 1, false);
@@ -168,12 +168,12 @@ int op_move_result_wide(const MIR * mir) {
  */
 int op_move_exception(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_MOVE_EXCEPTION);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     scratchRegs[2] = PhysicalReg_Null; scratchRegs[3] = PhysicalReg_Null;
     scratchRegs[0] = PhysicalReg_SCRATCH_1; scratchRegs[1] = PhysicalReg_Null;
     get_self_pointer(2, false);
-    move_mem_to_reg(OpndSize_32, offThread_exception, 2, false, 3, false);
-    move_imm_to_mem(OpndSize_32, 0, offThread_exception, 2, false);
+    move_mem_to_reg(OpndSize_32, OFFSETOF_MEMBER(Thread, exception), 2, false, 3, false);
+    move_imm_to_mem(OpndSize_32, 0, OFFSETOF_MEMBER(Thread, exception), 2, false);
     set_virtual_reg(vA, OpndSize_32, 3, false);
     return 0;
 }
diff --git a/vm/compiler/codegen/x86/LowerObject.cpp b/vm/compiler/codegen/x86/LowerObject.cpp
index 2c79201..cb8bc4f 100644
--- a/vm/compiler/codegen/x86/LowerObject.cpp
+++ b/vm/compiler/codegen/x86/LowerObject.cpp
@@ -32,7 +32,7 @@ extern void markCard_filled(int tgtAddrReg, bool isTgtPhysical, int scratchReg,
 //!   CALL class_resolve (%ebx is live across the call)
 //!        dvmInstanceofNonTrivial
 //!   NO register is live through function check_cast_helper
-int check_cast_nohelper(u2 vA, u4 tmp, bool instance, u2 vDest) {
+int check_cast_nohelper(int vA, u4 tmp, bool instance, int vDest) {
     get_virtual_reg(vA, OpndSize_32, 1, false); //object
     scratchRegs[2] = PhysicalReg_Null; scratchRegs[3] = PhysicalReg_Null;
     /* for trace-based JIT, it is likely that the class is already resolved */
@@ -93,7 +93,7 @@ int check_cast_nohelper(u2 vA, u4 tmp, bool instance, u2 vDest) {
         }
     }
 
-    move_mem_to_reg(OpndSize_32, offObject_clazz, 1, false, 6, false); //object->clazz
+    move_mem_to_reg(OpndSize_32, OFFSETOF_MEMBER(Object, clazz), 1, false, 6, false); //object->clazz
 
     //%eax: resolved class
     //compare resolved class and object->clazz
@@ -192,7 +192,7 @@ int check_cast_nohelper(u2 vA, u4 tmp, bool instance, u2 vDest) {
 //! common code to lower CHECK_CAST & INSTANCE_OF
 
 //!
-int common_check_cast_instance_of(u2 vA, u4 tmp, bool instance, u2 vDest) {
+int common_check_cast_instance_of(int vA, u4 tmp, bool instance, int vDest) {
     return check_cast_nohelper(vA, tmp, instance, vDest);
 }
 #undef P_GPR_1
@@ -206,7 +206,7 @@ int common_check_cast_instance_of(u2 vA, u4 tmp, bool instance, u2 vDest) {
  */
 int op_check_cast(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_CHECK_CAST);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     u4 tmp = mir->dalvikInsn.vB;
     return common_check_cast_instance_of(vA, tmp, false, 0);
 }
@@ -218,8 +218,8 @@ int op_check_cast(const MIR * mir) {
  */
 int op_instance_of(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_INSTANCE_OF);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
     u4 tmp = mir->dalvikInsn.vC;
     return common_check_cast_instance_of(vB, tmp, true, vA);
 }
@@ -229,7 +229,7 @@ int op_instance_of(const MIR * mir) {
 //! LOWER bytecode MONITOR_ENTER without usage of helper function
 
 //!   CALL dvmLockObject
-int monitor_enter_nohelper(u2 vA, const MIR *mir) {
+int monitor_enter_nohelper(int vA, const MIR *mir) {
     scratchRegs[0] = PhysicalReg_SCRATCH_1;
     scratchRegs[2] = PhysicalReg_Null; scratchRegs[3] = PhysicalReg_Null;
 
@@ -279,7 +279,7 @@ int monitor_enter_nohelper(u2 vA, const MIR *mir) {
  */
 int op_monitor_enter(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_MONITOR_ENTER);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
 #ifdef INC_NCG_O0
     if(gDvm.helper_switch[11]) {
         // .monitor_enter_helper
@@ -312,7 +312,7 @@ int op_monitor_enter(const MIR * mir) {
  */
 int op_monitor_exit(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_MONITOR_EXIT);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
 #ifdef INC_NCG_O0
     if(gDvm.helper_switch[11]) {
         export_pc();
@@ -389,8 +389,8 @@ int op_monitor_exit(const MIR * mir) {
  */
 int op_array_length(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_ARRAY_LENGTH);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
 #ifdef INC_NCG_O0
     if(gDvm.helper_switch[14]) {
         // .array_length_helper
@@ -421,7 +421,7 @@ int op_array_length(const MIR * mir) {
             cancelVRFreeDelayRequest(vB,VRDELAY_NULLCHECK);
         }
 
-        move_mem_to_reg(OpndSize_32, offArrayObject_length, 1, false, 2, false);
+        move_mem_to_reg(OpndSize_32, OFFSETOF_MEMBER(ArrayObject, length), 1, false, 2, false);
         set_virtual_reg(vA, OpndSize_32, 2, false);
         ///////////////////////
     }
@@ -442,7 +442,7 @@ int op_array_length(const MIR * mir) {
  */
 int op_new_instance(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_NEW_INSTANCE);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     u4 tmp = mir->dalvikInsn.vB;
 #ifdef INC_NCG_O0
     if(gDvm.helper_switch[4]) {
@@ -580,8 +580,8 @@ int new_instance_needinit() {
  */
 int op_new_array(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_NEW_ARRAY);
-    u2 vA = mir->dalvikInsn.vA; //destination
-    u2 vB = mir->dalvikInsn.vB; //length
+    int vA = mir->dalvikInsn.vA; //destination
+    int vB = mir->dalvikInsn.vB; //length
     u4 tmp = mir->dalvikInsn.vC;
 #ifdef INC_NCG_O0
     if(gDvm.helper_switch[17]) {
@@ -677,7 +677,7 @@ int op_new_array(const MIR * mir) {
 
 //! call: class_resolve call_dvmAllocPrimitiveArray
 //! exception: filled_new_array_notimpl common_exceptionThrown
-int common_filled_new_array(u2 length, u4 tmp, bool hasRange) {
+int common_filled_new_array(int length, u4 tmp, bool hasRange) {
     ClassObject *classPtr =
               (currentMethod->clazz->pDvmDex->pResClasses[tmp]);
     if(classPtr != NULL) ALOGI("FILLED_NEW_ARRAY class %s", classPtr->descriptor);
@@ -756,9 +756,9 @@ int common_filled_new_array(u2 length, u4 tmp, bool hasRange) {
  */
 int op_filled_new_array(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_FILLED_NEW_ARRAY);
-    u2 length = mir->dalvikInsn.vA;
+    u4 length = mir->dalvikInsn.vA;
     u4 tmp = mir->dalvikInsn.vB;
-    u2 v1, v2, v3, v4, v5;
+    int v1, v2, v3, v4, v5;
 
     // Note that v1, v2, v3, v4, and/or v5 may not be valid.
     // Always check "length" before using any of them.
@@ -773,27 +773,27 @@ int op_filled_new_array(const MIR * mir) {
     if(length >= 1) {
         //move from virtual register to contents of array object
         get_virtual_reg(v1, OpndSize_32, 7, false);
-        move_reg_to_mem(OpndSize_32, 7, false, offArrayObject_contents, PhysicalReg_EAX, true);
+        move_reg_to_mem(OpndSize_32, 7, false, OFFSETOF_MEMBER(ArrayObject, contents), PhysicalReg_EAX, true);
     }
     if(length >= 2) {
         //move from virtual register to contents of array object
         get_virtual_reg(v2, OpndSize_32, 8, false);
-        move_reg_to_mem(OpndSize_32, 8, false, offArrayObject_contents+4, PhysicalReg_EAX, true);
+        move_reg_to_mem(OpndSize_32, 8, false, OFFSETOF_MEMBER(ArrayObject, contents)+4, PhysicalReg_EAX, true);
     }
     if(length >= 3) {
         //move from virtual register to contents of array object
         get_virtual_reg(v3, OpndSize_32, 9, false);
-        move_reg_to_mem(OpndSize_32, 9, false, offArrayObject_contents+8, PhysicalReg_EAX, true);
+        move_reg_to_mem(OpndSize_32, 9, false, OFFSETOF_MEMBER(ArrayObject, contents)+8, PhysicalReg_EAX, true);
     }
     if(length >= 4) {
         //move from virtual register to contents of array object
         get_virtual_reg(v4, OpndSize_32, 10, false);
-        move_reg_to_mem(OpndSize_32, 10, false, offArrayObject_contents+12, PhysicalReg_EAX, true);
+        move_reg_to_mem(OpndSize_32, 10, false, OFFSETOF_MEMBER(ArrayObject, contents)+12, PhysicalReg_EAX, true);
     }
     if(length >= 5) {
         //move from virtual register to contents of array object
         get_virtual_reg(v5, OpndSize_32, 11, false);
-        move_reg_to_mem(OpndSize_32, 11, false, offArrayObject_contents+16, PhysicalReg_EAX, true);
+        move_reg_to_mem(OpndSize_32, 11, false, OFFSETOF_MEMBER(ArrayObject, contents)+16, PhysicalReg_EAX, true);
     }
     return 0;
 }
@@ -819,9 +819,9 @@ int filled_new_array_notimpl() {
  */
 int op_filled_new_array_range(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_FILLED_NEW_ARRAY_RANGE);
-    u2 length = mir->dalvikInsn.vA;
+    int length = mir->dalvikInsn.vA;
     u4 tmp = mir->dalvikInsn.vB;
-    u4 vC = mir->dalvikInsn.vC;
+    int vC = mir->dalvikInsn.vC;
     if (common_filled_new_array(length, tmp, true/*hasRange*/) == -1)
         return -1;
     //here, %eax points to the array object
@@ -834,7 +834,7 @@ int op_filled_new_array_range(const MIR * mir) {
         //address of the first virtual register that will be moved to the array object
         load_effective_addr(vC*4, PhysicalReg_FP, true, 7, false); //addr
         //start address for contents of the array object
-        load_effective_addr(offArrayObject_contents, PhysicalReg_EAX, true, 8, false); //addr
+        load_effective_addr(OFFSETOF_MEMBER(ArrayObject, contents), PhysicalReg_EAX, true, 8, false); //addr
         //loop counter
         move_imm_to_reg(OpndSize_32, length-1, 9, false); //counter
         //start of the loop
@@ -868,7 +868,7 @@ int op_filled_new_array_range(const MIR * mir) {
  */
 int op_fill_array_data(const MIR * mir, const u2 * dalvikPC) {
     assert(mir->dalvikInsn.opcode == OP_FILL_ARRAY_DATA);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     u4 tmp = mir->dalvikInsn.vB;
     scratchRegs[0] = PhysicalReg_SCRATCH_1;
     scratchRegs[1] = PhysicalReg_Null;
@@ -903,7 +903,7 @@ int op_fill_array_data(const MIR * mir, const u2 * dalvikPC) {
  */
 int op_throw(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_THROW);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     export_pc();
     get_virtual_reg(vA, OpndSize_32, 1, false);
     //null check
@@ -926,8 +926,8 @@ int op_throw(const MIR * mir) {
  */
 int op_throw_verification_error(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_THROW_VERIFICATION_ERROR);
-    u2 vA = mir->dalvikInsn.vA;
-    u2 vB = mir->dalvikInsn.vB;
+    int vA = mir->dalvikInsn.vA;
+    int vB = mir->dalvikInsn.vB;
 
     export_pc();
     scratchRegs[0] = PhysicalReg_SCRATCH_1;
diff --git a/vm/compiler/codegen/x86/LowerReturn.cpp b/vm/compiler/codegen/x86/LowerReturn.cpp
index 12f2a28..e82772b 100644
--- a/vm/compiler/codegen/x86/LowerReturn.cpp
+++ b/vm/compiler/codegen/x86/LowerReturn.cpp
@@ -29,6 +29,8 @@
  * @return value 0 when successful
  */
 inline int jumpTocommon_returnFromMethod() {
+    int sizeofStackSaveArea = sizeof(StackSaveArea);
+
     void * funcPtr = reinterpret_cast<void *>(dvmJitHelper_returnFromMethod);
 
     // Load save area into EDX
@@ -40,8 +42,8 @@ inline int jumpTocommon_returnFromMethod() {
     // We can just compute directly
     //   movl (offStackSaveArea_prevFrame - sizeofStackSaveArea)(rFP), rFP
     move_mem_to_reg(OpndSize_32,
-            offStackSaveArea_prevFrame - sizeofStackSaveArea, PhysicalReg_FP,
-            true, PhysicalReg_FP, true);
+            OFFSETOF_MEMBER(StackSaveArea, prevFrame) - sizeofStackSaveArea,
+            PhysicalReg_FP, true, PhysicalReg_FP, true);
 
     unconditional_jump_rel32(funcPtr);
     return 0;
@@ -72,7 +74,7 @@ int op_return_void(const MIR * mir) {
 int op_return(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_RETURN
             || mir->dalvikInsn.opcode == OP_RETURN_OBJECT);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     get_virtual_reg(vA, OpndSize_32, 1, false);
 
     set_return_value(OpndSize_32, 1, false, PhysicalReg_ECX, true);
@@ -87,7 +89,7 @@ int op_return(const MIR * mir) {
  */
 int op_return_wide(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_RETURN_WIDE);
-    u2 vA = mir->dalvikInsn.vA;
+    int vA = mir->dalvikInsn.vA;
     get_virtual_reg(vA, OpndSize_64, 1, false);
 
     set_return_value(OpndSize_64, 1, false, PhysicalReg_ECX, true);
diff --git a/vm/compiler/codegen/x86/NcgAot.cpp b/vm/compiler/codegen/x86/NcgAot.cpp
index b68e92f..75cd822 100644
--- a/vm/compiler/codegen/x86/NcgAot.cpp
+++ b/vm/compiler/codegen/x86/NcgAot.cpp
@@ -34,8 +34,10 @@ int get_eip_API() {
 int export_pc() {
     /* for trace-based JIT, pc points to bytecode
        for NCG, pc points to native code */
+    int sizeofStackSaveArea = sizeof(StackSaveArea);
+
     move_imm_to_mem(OpndSize_32, (int)rPC,
-                    -sizeofStackSaveArea+offStackSaveArea_localRefTop, PhysicalReg_FP, true);
+                    -sizeofStackSaveArea+OFFSETOF_MEMBER(StackSaveArea, xtra.currentPc), PhysicalReg_FP, true);
     return 1; //return number of ops
 }
 
diff --git a/vm/compiler/codegen/x86/StackExtensionX86.cpp b/vm/compiler/codegen/x86/StackExtensionX86.cpp
new file mode 100644
index 0000000..d32198b
--- /dev/null
+++ b/vm/compiler/codegen/x86/StackExtensionX86.cpp
@@ -0,0 +1,59 @@
+/*
+ * Copyright (C) 2013 Intel Corporation
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "Dalvik.h"
+#include "StackExtensionX86.h"
+
+/**
+ * @brief Gives number of available scratch registers for x86.
+ * @return Total number of scratch registers
+ */
+unsigned int dvmArchSpecGetNumberOfScratch (void)
+{
+    return StackTemporaries::getTotalScratchVRs ();
+}
+
+/**
+ * @brief Given a stratch register index, it gives the VR register number.
+ * @param idx Index of scratch register. Must be in range [0 .. N-1] where
+ * N is the maximum number of scratch registers available.
+ * @param method Method that contains the MIR for which we want to
+ * use scratch register.
+ * @param regnum virtual register number (modified by function)
+ * @return Return virtual register number when it finds one for the index.
+ * Otherwise, it returns -1.
+ */
+int dvmArchSpecGetScratchRegister (const Method * method, unsigned int idx)
+{
+    unsigned int maxScratch = dvmArchSpecGetNumberOfScratch ();
+
+    //Sanity check to make sure that requested index is in
+    //range [0 .. maxScratch-1]
+    if (idx > (maxScratch - 1))
+    {
+        return -1;
+    }
+
+    //We know the index is okay. Index of 0 corresponds to virtual register
+    //whose number is: 0 + locals + ins
+    int numLocals = method->registersSize - method->insSize;
+    int numIns = method->insSize;
+
+    //Calculate the regnum
+    int regnum = idx + numLocals + numIns;
+
+    return regnum;
+}
diff --git a/vm/compiler/codegen/x86/StackExtensionX86.h b/vm/compiler/codegen/x86/StackExtensionX86.h
new file mode 100644
index 0000000..5b976e7
--- /dev/null
+++ b/vm/compiler/codegen/x86/StackExtensionX86.h
@@ -0,0 +1,69 @@
+/*
+ * Copyright (C) 2013 Intel Corporation
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef STACKEXTENSIONX86_H_
+#define STACKEXTENSIONX86_H_
+
+/**
+ * @brief Space in frame to use for scratch registers.
+ */
+class StackTemporaries
+{
+public:
+    /**
+     * @brief Gives the total number of scratch VRs available for
+     * every frame.
+     * @return Maximum number of scratch VRs.
+     */
+    static unsigned int getTotalScratchVRs (void)
+    {
+        return numScratch;
+    }
+
+private:
+    /**
+     * @brief Hardcoded number of scratch registers per frame.
+     */
+#ifdef EXTRA_SCRATCH_VR
+    static const unsigned int numScratch = 4;
+#else
+    static const unsigned int numScratch = 0;
+#endif
+
+    /**
+     * @brief Allocated space for the scratch registers.
+     */
+    u4 scratchVirtualRegisters[numScratch];
+};
+
+/**
+ * @brief Stack frame extension for x86.
+ */
+struct ArchSpecificStackExtension
+{
+
+#ifdef EXTRA_SCRATCH_VR
+    /**
+     * @brief Allocated space for temporaries.
+     * @warning If this structure gets moved, dvmArchSpecGetScratchRegister
+     * must be updated to provide a new mapping.
+     */
+    StackTemporaries temps;
+#endif
+
+};
+
+#endif /* STACKEXTENSIONX86_H_ */
diff --git a/vm/interp/Stack.h b/vm/interp/Stack.h
index 06e7ec5..fe79918 100644
--- a/vm/interp/Stack.h
+++ b/vm/interp/Stack.h
@@ -105,8 +105,9 @@ for a discussion of how this is managed.  In particular note that it is
 possible to push additional call frames on without calling a method.
 */
 
-
-struct StackSaveArea;
+#ifdef WITH_JIT
+#include "vm/compiler/StackExtension.h"
+#endif
 
 //#define PAD_SAVE_AREA       /* help debug stack trampling */
 
@@ -122,6 +123,16 @@ struct StackSaveArea {
     u4          pad0, pad1, pad2;
 #endif
 
+#if defined(WITH_JIT) && defined(ARCH_IA32) && defined(EXTRA_SCRATCH_VR)
+    /*
+     * In case the JIT needs it, we allow it to extend the save area.
+     * Additionally, we guard with so many flags because if the arch
+     * specific extension might be empty, it will still have size of 1 and
+     * we don't want it to change size of StackSaveArea.
+     */
+    ArchSpecificStackExtension saveAreaExtension;
+#endif
+
 #ifdef EASY_GDB
     /* make it easier to trek through stack frames in GDB */
     StackSaveArea* prevSave;
@@ -147,6 +158,7 @@ struct StackSaveArea {
 
     /* Native return pointer for JIT, or 0 if interpreted */
     const u2* returnAddr;
+
 #ifdef PAD_SAVE_AREA
     u4          pad3, pad4, pad5;
 #endif
diff --git a/vm/mterp/common/asm-constants.h b/vm/mterp/common/asm-constants.h
index 80b36fc..1657cbd 100644
--- a/vm/mterp/common/asm-constants.h
+++ b/vm/mterp/common/asm-constants.h
@@ -89,6 +89,28 @@ MTERP_OFFSET(offDvmDex_pResFields,      DvmDex, pResFields, 20)
 MTERP_OFFSET(offDvmDex_pInterfaceCache, DvmDex, pInterfaceCache, 24)
 
 /* StackSaveArea fields */
+#if defined(WITH_JIT) && defined(ARCH_IA32) && defined(EXTRA_SCRATCH_VR)
+#ifdef EASY_GDB
+MTERP_OFFSET(offStackSaveArea_prevSave, StackSaveArea, prevSave, 16)
+MTERP_OFFSET(offStackSaveArea_prevFrame, StackSaveArea, prevFrame, 20)
+MTERP_OFFSET(offStackSaveArea_savedPc,  StackSaveArea, savedPc, 24)
+MTERP_OFFSET(offStackSaveArea_method,   StackSaveArea, method, 28)
+MTERP_OFFSET(offStackSaveArea_currentPc, StackSaveArea, xtra.currentPc, 32)
+MTERP_OFFSET(offStackSaveArea_localRefCookie, \
+                                        StackSaveArea, xtra.localRefCookie, 32)
+MTERP_OFFSET(offStackSaveArea_returnAddr, StackSaveArea, returnAddr, 36)
+MTERP_SIZEOF(sizeofStackSaveArea,       StackSaveArea, 40)
+#else //ifndef EASY_GDB
+MTERP_OFFSET(offStackSaveArea_prevFrame, StackSaveArea, prevFrame, 16)
+MTERP_OFFSET(offStackSaveArea_savedPc,  StackSaveArea, savedPc, 20)
+MTERP_OFFSET(offStackSaveArea_method,   StackSaveArea, method, 24)
+MTERP_OFFSET(offStackSaveArea_currentPc, StackSaveArea, xtra.currentPc, 28)
+MTERP_OFFSET(offStackSaveArea_localRefCookie, \
+                                        StackSaveArea, xtra.localRefCookie, 28)
+MTERP_OFFSET(offStackSaveArea_returnAddr, StackSaveArea, returnAddr, 32)
+MTERP_SIZEOF(sizeofStackSaveArea,       StackSaveArea, 36)
+#endif //EASY_GDB
+#else // ifndef WITH_JIT || ifndef ARCH_IA32 || ifndef EXTRA_SCRATCH_VR
 #ifdef EASY_GDB
 MTERP_OFFSET(offStackSaveArea_prevSave, StackSaveArea, prevSave, 0)
 MTERP_OFFSET(offStackSaveArea_prevFrame, StackSaveArea, prevFrame, 4)
@@ -99,7 +121,7 @@ MTERP_OFFSET(offStackSaveArea_localRefCookie, \
                                         StackSaveArea, xtra.localRefCookie, 16)
 MTERP_OFFSET(offStackSaveArea_returnAddr, StackSaveArea, returnAddr, 20)
 MTERP_SIZEOF(sizeofStackSaveArea,       StackSaveArea, 24)
-#else
+#else //ifndef EASY_GDB
 MTERP_OFFSET(offStackSaveArea_prevFrame, StackSaveArea, prevFrame, 0)
 MTERP_OFFSET(offStackSaveArea_savedPc,  StackSaveArea, savedPc, 4)
 MTERP_OFFSET(offStackSaveArea_method,   StackSaveArea, method, 8)
@@ -108,7 +130,8 @@ MTERP_OFFSET(offStackSaveArea_localRefCookie, \
                                         StackSaveArea, xtra.localRefCookie, 12)
 MTERP_OFFSET(offStackSaveArea_returnAddr, StackSaveArea, returnAddr, 16)
 MTERP_SIZEOF(sizeofStackSaveArea,       StackSaveArea, 20)
-#endif
+#endif //EASY_GDB
+#endif //WITH_JIT && ARCH_IA32 && EXTRA_SCRATCH_VR
 
   /* ShadowSpace fields */
 #if defined(WITH_JIT) && defined(WITH_SELF_VERIFICATION)
-- 
1.7.4.1

