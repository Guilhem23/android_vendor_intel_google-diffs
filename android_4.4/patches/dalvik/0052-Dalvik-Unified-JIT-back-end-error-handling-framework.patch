From 34462f86d5fc2adf65c296793db35085a2943d0d Mon Sep 17 00:00:00 2001
From: Udayan Banerji <udayan.banerji@intel.com>
Date: Mon, 21 Jan 2013 16:49:19 -0800
Subject: Dalvik: Unified JIT back-end error handling framework & Code cleanup

BZ: 36863

This change adds a framework to report all possible JIT failures through
a set of standard JIT errors, and attempt recovery from errors when
possible. This change removes most exit(-1), return -1 and dvmAbort calls.
Error flags may be set redundantly as the error trickles down. All errors
set will be reported at the end of dvmCompilerMIR2LIR.

Errors can be marked as fatal too. As of now malloc failures and scheduling
problems are treated as fatal. A dvmAbort call results.

The scope of the framework is at the cUnit level. Errors are cleared when
a new cUnit starts compilation. Errors which can propagate beyond the JIT
back-end are not handled, and a log message stating that is generated.

This change introduces JitCompilationError enum, with a set of error codes
which can be used in the code.

1. Errors can be set using SET_JIT_ERROR.
2. When reporting errors, a location specific error message is encouraged.
   At the handling location, a general error will be printed.
3. InsertLabel now returns an error code which needs to be handled.
4. To add errors, add them to JitCompilationErrors enum, and add the
   corresponding messages in jitErrorMessages array.

This patch also performs code clean-up, handles return values and fixes log
messages.

Category: device-enablement
Domain: AOSP-Dalvik-Compiler-CG; AOSP-Dalvik-Runtime
Origin: internal
Upstream-Candidate: no, needs rework

Change-Id: I171c497552d7fb8e2e4a1e5bad8792558638d7f9
Orig-MCG-Change-Id: I6a931881d754746e2bd362940e60caa81434b115
Signed-off-by: Udayan Banerji <udayan.banerji@intel.com>
Signed-off-by: Qiming Shi <qiming.shi@intel.com>
Signed-off-by: Serguei Katkov <serguei.i.katkov@intel.com>
---
 vm/Dvm.mk                                     |    1 +
 vm/Globals.h                                  |    3 +
 vm/compiler/codegen/Optimizer.h               |    1 +
 vm/compiler/codegen/x86/AnalysisO1.cpp        |  883 +++++++++++++++++--------
 vm/compiler/codegen/x86/AnalysisO1.h          |    5 +-
 vm/compiler/codegen/x86/BytecodeVisitor.cpp   |  296 ++++++---
 vm/compiler/codegen/x86/CodegenErrors.cpp     |  144 ++++
 vm/compiler/codegen/x86/CodegenErrors.h       |  116 ++++
 vm/compiler/codegen/x86/CodegenInterface.cpp  |  276 +++++---
 vm/compiler/codegen/x86/ExceptionHandling.cpp |    9 +-
 vm/compiler/codegen/x86/Lower.cpp             |   43 +-
 vm/compiler/codegen/x86/Lower.h               |   17 +-
 vm/compiler/codegen/x86/LowerAlu.cpp          |   71 ++-
 vm/compiler/codegen/x86/LowerConst.cpp        |    3 +-
 vm/compiler/codegen/x86/LowerGetPut.cpp       |   36 +-
 vm/compiler/codegen/x86/LowerHelper.cpp       |  223 +++++--
 vm/compiler/codegen/x86/LowerInvoke.cpp       |  128 +++--
 vm/compiler/codegen/x86/LowerJump.cpp         |  331 +++++++---
 vm/compiler/codegen/x86/LowerObject.cpp       |  102 ++-
 vm/compiler/codegen/x86/LowerReturn.cpp       |   14 +-
 vm/compiler/codegen/x86/NcgAot.cpp            |   22 +-
 vm/compiler/codegen/x86/Schedule.cpp          |   14 +-
 22 files changed, 1928 insertions(+), 810 deletions(-)
 create mode 100644 vm/compiler/codegen/x86/CodegenErrors.cpp
 create mode 100644 vm/compiler/codegen/x86/CodegenErrors.h

diff --git a/vm/Dvm.mk b/vm/Dvm.mk
index 6a876fe..1ddbd59 100644
--- a/vm/Dvm.mk
+++ b/vm/Dvm.mk
@@ -352,6 +352,7 @@ ifeq ($(dvm_arch),x86)
               compiler/codegen/$(dvm_arch_variant)/Schedule.cpp \
               compiler/codegen/$(dvm_arch_variant)/InstructionGeneration.cpp \
               compiler/codegen/$(dvm_arch_variant)/ExceptionHandling.cpp \
+              compiler/codegen/$(dvm_arch_variant)/CodegenErrors.cpp \
               compiler/LoopOpt.cpp \
               compiler/Checks.cpp
        # need apache harmony x86 encoder/decoder
diff --git a/vm/Globals.h b/vm/Globals.h
index 8490abb..7ef1f9a 100644
--- a/vm/Globals.h
+++ b/vm/Globals.h
@@ -851,6 +851,9 @@ struct DvmJitGlobals {
     /* Compiled code cache */
     void* codeCache;
 
+    /* Jit Errors Bit-field */
+    unsigned int jitErrorFlags;
+
     /*
      * This is used to store the base address of an in-flight compilation whose
      * class object pointers have been calculated to populate literal pool.
diff --git a/vm/compiler/codegen/Optimizer.h b/vm/compiler/codegen/Optimizer.h
index 43d98ed..f02f71c 100644
--- a/vm/compiler/codegen/Optimizer.h
+++ b/vm/compiler/codegen/Optimizer.h
@@ -30,6 +30,7 @@ enum optControlVector {
     kSuppressLoads,
     kMethodInlining,
     kMethodJit,
+    kShortJumpOffset
 };
 
 /* Forward declarations */
diff --git a/vm/compiler/codegen/x86/AnalysisO1.cpp b/vm/compiler/codegen/x86/AnalysisO1.cpp
index eb91dbb..4687199 100644
--- a/vm/compiler/codegen/x86/AnalysisO1.cpp
+++ b/vm/compiler/codegen/x86/AnalysisO1.cpp
@@ -254,10 +254,10 @@ int sortAllocConstraint(RegAllocConstraint* allocConstraints,
                         RegAllocConstraint* allocConstraintsSorted, bool fromHighToLow);
 
 //used in codeGenBasicBlock
-void insertFromVirtualInfo(BasicBlock_O1* bb, int k); //update compileTable
-void insertFromTempInfo(int k); //update compileTable
+int insertFromVirtualInfo(BasicBlock_O1* bb, int k); //update compileTable
+int insertFromTempInfo(int k); //update compileTable
 int updateXferPoints();
-void updateLiveTable();
+static int updateLiveTable();
 void printDefUseTable();
 bool isFirstOfHandler(BasicBlock_O1* bb);
 
@@ -269,9 +269,9 @@ RegAccessType updateAccess2(RegAccessType C1, RegAccessType C2);
 RegAccessType updateAccess3(RegAccessType C, RegAccessType B);
 
 void updateDefUseTable();
-void updateReachingDefA(int indexToA, OverlapCase isBPartiallyOverlapA);
-void updateReachingDefB1(int indexToA);
-void updateReachingDefB2();
+static int updateReachingDefA(int indexToA, OverlapCase isBPartiallyOverlapA);
+static int updateReachingDefB1(int indexToA);
+static int updateReachingDefB2();
 void updateReachingDefB3();
 
 RegAccessType insertAUse(DefUsePair* ptr, int offsetPC, int regNum, LowOpndRegType physicalType);
@@ -280,9 +280,9 @@ RegAccessType insertDefUsePair(int reachingDefIndex);
 
 //used in updateXferPoints
 int fakeUsageAtEndOfBB(BasicBlock_O1* bb);
-void insertLoadXfer(int offset, int regNum, LowOpndRegType pType);
+static int insertLoadXfer(int offset, int regNum, LowOpndRegType pType);
 int searchMemTable(int regNum);
-void mergeLiveRange(int tableIndex, int rangeStart, int rangeEnd);
+static int mergeLiveRange(int tableIndex, int rangeStart, int rangeEnd);
 //used in updateLiveTable
 RegAccessType setAccessTypeOfUse(OverlapCase isDefPartiallyOverlapUse, RegAccessType reachingDefLive);
 DefUsePair* searchDefUseTable(int offsetPC, int regNum, LowOpndRegType pType);
@@ -359,21 +359,25 @@ void syncAllRegs() {
     return;
 }
 
-//!sync up spillIndexUsed with compileTable
+//! \brief sync up spillIndexUsed with compileTable
 
-//!
-void updateSpillIndexUsed() {
+//! \return -1 if error, 0 otherwise
+static int updateSpillIndexUsed(void) {
     int k;
     for(k = 0; k <= MAX_SPILL_JIT_IA-1; k++) spillIndexUsed[k] = 0;
     for(k = 0; k < num_compile_entries; k++) {
         if(isVirtualReg(compileTable[k].physicalType)) continue;
         if(compileTable[k].spill_loc_index >= 0) {
-            if(compileTable[k].spill_loc_index > 4*(MAX_SPILL_JIT_IA-1))
-                ALOGE("spill_loc_index is wrong for entry %d: %d",
+            if(compileTable[k].spill_loc_index > 4*(MAX_SPILL_JIT_IA-1)) {
+                ALOGE("JIT_ERROR: spill_loc_index is wrong for entry %d: %d\n",
                       k, compileTable[k].spill_loc_index);
+                SET_JIT_ERROR(kJitErrorRegAllocFailed);
+                return -1;
+            }
             spillIndexUsed[compileTable[k].spill_loc_index >> 2] = 1;
         }
     }
+    return 0;
 }
 
 /* free memory used in all basic blocks */
@@ -414,7 +418,7 @@ void initializeRegStateOfBB(BasicBlock_O1* bb) {
                     /* at the beginning of an exception handler, GG VR is in the interpreted stack */
                     compileTable[k].physicalReg = PhysicalReg_Null;
 #ifdef DEBUG_COMPILE_TABLE
-                    ALOGI("at the first basic block of an exception handler, GG VR %d type %d is in memory",
+                    ALOGI("At the first basic block of an exception handler, GG VR %d type %d is in memory",
                           compileTable[k].regNum, compileTable[k].physicalType);
 #endif
                 } else {
@@ -454,8 +458,11 @@ void initializeNullCheck(int indexToMemVR) {
     memVRTable[indexToMemVR].nullCheckDone = found;
 }
 
-/* initialize memVRTable */
-void initializeMemVRTable() {
+/* @brief Initializes the MemVRTable
+ *
+ * @return -1 if error happened, 0 otherwise
+ */
+static int initializeMemVRTable(void) {
     num_memory_vr = 0;
     int k;
     for(k = 0; k < num_compile_entries; k++) {
@@ -482,8 +489,9 @@ void initializeMemVRTable() {
             /* the low half of VR is not in memVRTable
                add an entry for the low half in memVRTable */
             if(num_memory_vr >= NUM_MEM_VR_ENTRY) {
-                ALOGE("exceeds size of memVRTable");
-                dvmAbort();
+                ALOGE("JIT_ERROR: Index %d exceeds size of memVRTable\n", num_memory_vr);
+                SET_JIT_ERROR(kJitErrorRegAllocFailed);
+                return -1;
             }
             memVRTable[num_memory_vr].regNum = regNum;
             memVRTable[num_memory_vr].inMemory = setToInMemory;
@@ -498,8 +506,9 @@ void initializeMemVRTable() {
             /* the high half of VR is not in memVRTable
                add an entry for the high half in memVRTable */
             if(num_memory_vr >= NUM_MEM_VR_ENTRY) {
-                ALOGE("exceeds size of memVRTable");
-                dvmAbort();
+                ALOGE("JIT_ERROR: Index %d exceeds size of memVRTable for 64-bit OpndSize\n", num_memory_vr);
+                SET_JIT_ERROR(kJitErrorRegAllocFailed);
+                return -1;
             }
             memVRTable[num_memory_vr].regNum = regNum+1;
             memVRTable[num_memory_vr].inMemory = setToInMemory;
@@ -511,19 +520,27 @@ void initializeMemVRTable() {
             num_memory_vr++;
         }
     }
+    return 0;
 }
 
 /* create a O1 basic block from basic block constructed in JIT MIR */
 BasicBlock_O1* createBasicBlockO1(BasicBlock* bb) {
     BasicBlock_O1* bb1 = createBasicBlock(0, -1);
+    if (bb1 == NULL) return bb1;
     bb1->jitBasicBlock = bb;
     return bb1;
 }
 
-/* a basic block in JIT MIR can contain bytecodes that are not in program order
-   for example, a "goto" bytecode will be followed by the goto target */
-void preprocessingBB(BasicBlock* bb) {
+/* @brief Pre-process BasicBlocks
+ * @detail A basic block in JIT MIR can contain bytecodes
+ * that are not in program order. For example, a "goto"
+ * bytecode will be followed by the goto target
+ * @return -1 if error happened, 0 otherwise
+ */
+int preprocessingBB(BasicBlock* bb) {
     currentBB = createBasicBlockO1(bb);
+    if (currentBB == NULL)
+        return -1;
     /* initialize currentBB->allocConstraints */
     int ii;
     for(ii = 0; ii < 8; ii++) {
@@ -535,10 +552,15 @@ void preprocessingBB(BasicBlock* bb) {
     dumpVirtualInfoOfBasicBlock(currentBB);
 #endif
     currentBB = NULL;
+    return 0;
 }
 
-void preprocessingTrace() {
+//! \brief preprocess a trace
+//!
+//! \return -1 on error, 0 on success
+int preprocessingTrace() {
     int k, k2, k3, jj;
+    int retCode = 0;
     /* this is a simplified verson of setTypeOfVR()
         all VRs are assumed to be GL, no VR will be GG
     */
@@ -554,7 +576,9 @@ void preprocessingTrace() {
         currentBB = method_bbs_sorted[k2];
         /* update compileTable with virtual register from currentBB */
         for(k3 = 0; k3 < currentBB->num_regs; k3++) {
-            insertFromVirtualInfo(currentBB, k3);
+            retCode = insertFromVirtualInfo(currentBB, k3);
+            if (retCode < 0)
+                return retCode;
         }
 
         /* for each GL|GG type VR, insert fake usage at end of basic block to keep it live */
@@ -582,6 +606,7 @@ void preprocessingTrace() {
     dumpCompileTable();
 #endif
     currentBB = NULL;
+    return 0;
 }
 
 void printJitTraceInfoAtRunTime(const Method* method, int offset) {
@@ -654,8 +679,9 @@ int codeGenBasicBlockJit(const Method* method, BasicBlock* bb) {
             return cg_ret;
         }
     }
-    ALOGE("can't find the corresponding O1 basic block for id %d type %d",
+    ALOGE("JIT_ERROR: Cannot find the corresponding O1 basic block for id %d type %d",
          bb->id, bb->blockType);
+    SET_JIT_ERROR(kJitErrorInvalidBBId);
     return -1;
 }
 void endOfBasicBlock(BasicBlock* bb) {
@@ -718,10 +744,12 @@ int collectInfoOfBasicBlock(Method* method, BasicBlock_O1* bb) {
         for(kk = 0; kk < num_regs; kk++) {
             currentInfo = infoByteCode[kk];
 #ifdef DEBUG_MERGE_ENTRY
-            ALOGI("call mergeEntry2 at offsetPC %x kk %d VR %d %d", offsetPC, kk,
+            ALOGI("Call mergeEntry2 at offsetPC %x kk %d VR %d %d\n", offsetPC, kk,
                   currentInfo.regNum, currentInfo.physicalType);
 #endif
-            mergeEntry2(bb); //update defUseTable of the basic block
+            int retCode = mergeEntry2(bb); //update defUseTable of the basic block
+            if (retCode < 0)
+                return retCode;
         }
 
         //dumpVirtualInfoOfBasicBlock(bb);
@@ -732,14 +760,14 @@ int collectInfoOfBasicBlock(Method* method, BasicBlock_O1* bb) {
     //sort allocConstraints of each basic block
     for(kk = 0; kk < bb->num_regs; kk++) {
 #ifdef DEBUG_ALLOC_CONSTRAINT
-        ALOGI("sort virtual reg %d type %d -------", bb->infoBasicBlock[kk].regNum,
+        ALOGI("Sort virtual reg %d type %d -------", bb->infoBasicBlock[kk].regNum,
               bb->infoBasicBlock[kk].physicalType);
 #endif
         sortAllocConstraint(bb->infoBasicBlock[kk].allocConstraints,
                             bb->infoBasicBlock[kk].allocConstraintsSorted, true);
     }
 #ifdef DEBUG_ALLOC_CONSTRAINT
-    ALOGI("sort constraints for BB %d --------", bb->bb_index);
+    ALOGI("Sort constraints for BB %d --------", bb->bb_index);
 #endif
     sortAllocConstraint(bb->allocConstraints, bb->allocConstraintsSorted, false);
     return 0;
@@ -757,20 +785,27 @@ int collectInfoOfBasicBlock(Method* method, BasicBlock_O1* bb) {
     At end of the basic block, right before the jump instruction, handles constant VRs and GG VRs
 */
 int codeGenBasicBlock(const Method* method, BasicBlock_O1* bb) {
+    int retCode = 0;
     /* we assume at the beginning of each basic block,
        all GL VRs reside in memory and all GG VRs reside in predefined physical registers,
        so at the end of a basic block, recover a spilled GG VR, store a GL VR to memory */
     /* update compileTable with entries in bb->infoBasicBlock */
     int k;
     for(k = 0; k < bb->num_regs; k++) {
-        insertFromVirtualInfo(bb, k);
+        retCode = insertFromVirtualInfo(bb, k);
+        if (retCode < 0)
+            return retCode;
     }
-    updateXferPoints(); //call fakeUsageAtEndOfBB
+    retCode = updateXferPoints(); //call fakeUsageAtEndOfBB
+    if (retCode < 0)
+        return retCode;
 #ifdef DEBUG_REACHING_DEF
     printDefUseTable();
 #endif
 #ifdef DSE_OPT
-    removeDeadDefs();
+    retCode = removeDeadDefs();
+    if (retCode < 0)
+        return retCode;
     printDefUseTable();
 #endif
     //clear const section of compileTable
@@ -781,8 +816,12 @@ int codeGenBasicBlock(const Method* method, BasicBlock_O1* bb) {
     dumpCompileTable();
 #endif
     initializeRegStateOfBB(bb);
-    initializeMemVRTable();
-    updateLiveTable();
+    retCode = initializeMemVRTable();
+    if (retCode < 0)
+        return retCode;
+    retCode = updateLiveTable();
+    if (retCode < 0)
+        return retCode;
     freeReg(true);  //before code gen of a basic block, also called at end of a basic block?
 #ifdef DEBUG_COMPILE_TABLE
     ALOGI("At start of basic block %d (num of VRs %d) -------", bb->bb_index, bb->num_regs);
@@ -806,7 +845,9 @@ int codeGenBasicBlock(const Method* method, BasicBlock_O1* bb) {
         num_temp_regs_per_bytecode = getTempRegInfo(infoByteCodeTemp, mir);
         for(k = 0; k < num_temp_regs_per_bytecode; k++) {
             if(infoByteCodeTemp[k].versionNum > 0) continue;
-            insertFromTempInfo(k);
+            retCode = insertFromTempInfo(k);
+            if (retCode < 0)
+                return retCode;
         }
         startNativeCode(-1, -1);
         for(k = 0; k <= MAX_SPILL_JIT_IA-1; k++) spillIndexUsed[k] = 0;
@@ -823,7 +864,16 @@ int codeGenBasicBlock(const Method* method, BasicBlock_O1* bb) {
 #endif
         //set isConst to true for CONST & MOVE MOVE_OBJ?
         //clear isConst to true for MOVE, MOVE_OBJ, MOVE_RESULT, MOVE_EXCEPTION ...
-        bool isConst = getConstInfo(bb, mir); //will reset isConst if a VR is updated by the bytecode
+        bool isConst = false;
+        int retCode = getConstInfo(bb, mir); //will return 0 if a VR is updated by the bytecode
+        //if the bytecode generates a constant
+        if (retCode == 1)
+            isConst = true;
+        //if something went wrong at getConstInfo. getConstInfo has logged it
+        else if (retCode == -1)
+            return retCode;
+        //otherwise, bytecode does not generate a constant
+
         bool isDeadStmt = false;
 #ifdef DSE_OPT
         for(k = 0; k < num_dead_pc; k++) {
@@ -873,32 +923,29 @@ int codeGenBasicBlock(const Method* method, BasicBlock_O1* bb) {
                 lastByteCodeIsJump = true;
             //lowerByteCode will call globalVREndOfBB if it is jump
 
-            int retCode = lowerByteCodeJit(method, mir, rPC);
+            bool retCode = lowerByteCodeJit(method, mir, rPC);
             if(gDvmJit.codeCacheByteUsed + (stream - streamStart) +
                  CODE_CACHE_PADDING > gDvmJit.codeCacheSize) {
-                 ALOGE("JIT code cache full");
+                 ALOGE("JIT_ERROR: Code cache full while lowering bytecode %s", dexGetOpcodeName(mir->dalvikInsn.opcode));
                  gDvmJit.codeCacheFull = true;
+                 SET_JIT_ERROR(kJitErrorCodeCacheFull);
                  return -1;
             }
 
-            if (retCode == 1) {
-                // We always fall back to the interpreter for OP_INVOKE_OBJECT_INIT_RANGE,
-                // but any other failure is unexpected and should be logged.
-                if (mir->dalvikInsn.opcode != OP_INVOKE_OBJECT_INIT_RANGE) {
-                    ALOGE("JIT couldn't compile %s%s dex_pc=%d opcode=%d",
-                          method->clazz->descriptor,
-                          method->name,
-                          offsetPC,
-                          mir->dalvikInsn.opcode);
-                }
+            if (retCode){
+                SET_JIT_ERROR(kJitErrorUnsupportedBytecode);
+                ALOGE("JIT_ERROR: Unsupported bytecode %s\n", dexGetOpcodeName(mir->dalvikInsn.opcode));
                 return -1;
             }
+
+            //Check if an error happened while in the bytecode
+            if (IS_ANY_JIT_ERROR_SET()) {
+                SET_JIT_ERROR(kJitErrorCodegen);
+                return -1;
+            }
+
             updateConstInfo(bb);
             freeShortMap();
-            if(retCode < 0) {
-                ALOGE("error in lowering the bytecode");
-                return retCode;
-            }
             freeReg(true); //may dump GL VR to memory (this is necessary)
 
             //after each bytecode, make sure non-VRs have refCount of zero
@@ -917,12 +964,12 @@ int codeGenBasicBlock(const Method* method, BasicBlock_O1* bb) {
             offsetNCG = stream - streamMethodStart;
             mapFromBCtoNCG[offsetPC] = offsetNCG;
 #ifdef DEBUG_COMPILE_TABLE
-            ALOGI("this bytecode generates a constant and has no side effect");
+            ALOGI("Bytecode %s generates a constant and has no side effect\n", dexGetOpcodeName(mir->dalvikInsn.opcode));
 #endif
             freeReg(true); //may dump GL VR to memory (this is necessary)
         }
 #ifdef DEBUG_COMPILE_TABLE
-        ALOGI("after one bytecode BB %d (num of VRs %d)", bb->bb_index, bb->num_regs);
+        ALOGI("After one bytecode BB %d (num of VRs %d)", bb->bb_index, bb->num_regs);
 #endif
     }//for each bytecode
 #ifdef DEBUG_COMPILE_TABLE
@@ -930,7 +977,11 @@ int codeGenBasicBlock(const Method* method, BasicBlock_O1* bb) {
 #endif
     if(!lastByteCodeIsJump) constVREndOfBB();
     //at end of a basic block, get spilled GG VR & dump GL VR
-    if(!lastByteCodeIsJump) globalVREndOfBB(method);
+    if(!lastByteCodeIsJump) {
+        retCode = globalVREndOfBB(method);
+        if (retCode < 0)
+            return retCode;
+    }
     //remove entries for temporary registers, L VR and GL VR
     int jj;
     for(k = 0; k < num_compile_entries; ) {
@@ -1010,7 +1061,9 @@ int mergeEntry2(BasicBlock_O1* bb) {
             for(k = 0; k < currentInfo.num_reaching_defs; k++)
                 currentInfo.reachingDefs[k] = bb->infoBasicBlock[jj].reachingDefs[k];
             updateDefUseTable(); //use currentInfo to update defUseTable
-            updateReachingDefA(jj, OVERLAP_B_COVER_A); //update reachingDefs of A
+            int retCode = updateReachingDefA(jj, OVERLAP_B_COVER_A); //update reachingDefs of A
+            if (retCode < 0)
+                return -1;
             isMerged = true;
             hasAlias = true;
             if(typeB == LowOpndRegType_gp) {
@@ -1025,21 +1078,29 @@ int mergeEntry2(BasicBlock_O1* bb) {
             bb->infoBasicBlock[jj].accessType = mergeAccess2(bb->infoBasicBlock[jj].accessType, currentInfo.accessType,
                                                              isBPartiallyOverlapA);
 #ifdef DEBUG_MERGE_ENTRY
-            ALOGI("update accessType in case 2: VR %d %d accessType %d", regA, typeA, bb->infoBasicBlock[jj].accessType);
+            ALOGI("Update accessType in case 2: VR %d %d accessType %d", regA, typeA, bb->infoBasicBlock[jj].accessType);
 #endif
             hasAlias = true;
             if(currentInfo.accessType == REGACCESS_U || currentInfo.accessType == REGACCESS_UD) {
                 /* update currentInfo.reachingDefs */
-                updateReachingDefB1(jj);
-                updateReachingDefB2();
+                int retCode = updateReachingDefB1(jj);
+                if (retCode < 0)
+                    return retCode;
+                retCode = updateReachingDefB2();
+                if (retCode < 0)
+                    return retCode;
             }
-            updateReachingDefA(jj, isBPartiallyOverlapA);
+            int retCode = updateReachingDefA(jj, isBPartiallyOverlapA);
+            if (retCode < 0)
+                return retCode;
         }
         else {
             //even if B does not overlap with A, B can affect the reaching defs of A
             //for example, B is a def of "v0", A is "v1"
             //  B can kill some reaching defs of A or affect the accessType of a reaching def
-            updateReachingDefA(jj, OVERLAP_NO); //update reachingDefs of A
+            int retCode = updateReachingDefA(jj, OVERLAP_NO); //update reachingDefs of A
+            if (retCode < 0)
+                return -1;
         }
     }//for each variable A in infoBasicBlock
     if(!isMerged) {
@@ -1051,7 +1112,7 @@ int mergeEntry2(BasicBlock_O1* bb) {
         else
             bb->infoBasicBlock[bb->num_regs].accessType = currentInfo.accessType;
 #ifdef DEBUG_MERGE_ENTRY
-        ALOGI("update accessType in case 3: VR %d %d accessType %d", regB, typeB, bb->infoBasicBlock[bb->num_regs].accessType);
+        ALOGI("Update accessType in case 3: VR %d %d accessType %d", regB, typeB, bb->infoBasicBlock[bb->num_regs].accessType);
 #endif
         bb->infoBasicBlock[bb->num_regs].regNum = regB;
         for(k = 0; k < 8; k++)
@@ -1067,7 +1128,7 @@ int mergeEntry2(BasicBlock_O1* bb) {
         for(k = 0; k < currentInfo.num_reaching_defs; k++)
             bb->infoBasicBlock[bb->num_regs].reachingDefs[k] = currentInfo.reachingDefs[k];
 #ifdef DEBUG_MERGE_ENTRY
-        ALOGI("try to update reaching defs for VR %d %d", regB, typeB);
+        ALOGI("Try to update reaching defs for VR %d %d", regB, typeB);
         for(k = 0; k < bb->infoBasicBlock[bb->num_regs].num_reaching_defs; k++)
             ALOGI("reaching def %d @ %d for VR %d %d access %d", k, currentInfo.reachingDefs[k].offsetPC,
                   currentInfo.reachingDefs[k].regNum, currentInfo.reachingDefs[k].physicalType,
@@ -1075,23 +1136,25 @@ int mergeEntry2(BasicBlock_O1* bb) {
 #endif
         bb->num_regs++;
         if(bb->num_regs >= MAX_REG_PER_BASICBLOCK) {
-            ALOGE("too many VRs in a basic block");
-            dvmAbort();
+            ALOGE("JIT_ERROR: Number of VRs (%d) in a basic block, exceed maximum (%d)\n", bb->num_regs, MAX_REG_PER_BASICBLOCK);
+            SET_JIT_ERROR(kJitErrorMaxVR);
+            return -1;
         }
-        return -1;
     }
     return 0;
 }
 
-//!update reaching defs for infoBasicBlock[indexToA]
-
-//!use currentInfo.reachingDefs to update reaching defs for variable A
-void updateReachingDefA(int indexToA, OverlapCase isBPartiallyOverlapA) {
-    if(indexToA < 0) return;
+//! \brief update reaching defs for infoBasicBlock[indexToA]
+//! \detail use currentInfo.reachingDefs to update reaching defs for variable A
+//! \param indexToA Index of variable A
+//! \param isBPartiallyOverlapA the type of overlap
+//! \return -1 if error, 0 otherwise
+static int updateReachingDefA(int indexToA, OverlapCase isBPartiallyOverlapA) {
+    if(indexToA < 0) return 0;
     int k, k2;
     OverlapCase isBPartiallyOverlapDef;
     if(currentInfo.accessType == REGACCESS_U) {
-        return; //no update to reachingDefs of the VR
+        return 0; //no update to reachingDefs of the VR
     }
     /* access in currentInfo is DU, D, or UD */
     if(isBPartiallyOverlapA == OVERLAP_B_COVER_A) {
@@ -1102,9 +1165,9 @@ void updateReachingDefA(int indexToA, OverlapCase isBPartiallyOverlapA) {
         currentBB->infoBasicBlock[indexToA].reachingDefs[0].physicalType = currentInfo.physicalType;
         currentBB->infoBasicBlock[indexToA].reachingDefs[0].accessType = REGACCESS_D;
 #ifdef DEBUG_REACHING_DEF
-        ALOGI("single reaching def @ %d for VR %d %d", offsetPC, currentInfo.regNum, currentInfo.physicalType);
+        ALOGI("Single reaching def @ %d for VR %d %d", offsetPC, currentInfo.regNum, currentInfo.physicalType);
 #endif
-        return;
+        return 0;
     }
     /* update reachingDefs for variable A to get rid of dead defs */
     /* Bug fix: it is possible that more than one reaching defs need to be removed
@@ -1173,7 +1236,9 @@ void updateReachingDefA(int indexToA, OverlapCase isBPartiallyOverlapA) {
         //insert the def to variable @ currentInfo
         k = currentBB->infoBasicBlock[indexToA].num_reaching_defs;
         if(k >= 3) {
-          ALOGE("more than 3 reaching defs");
+            ALOGE("JIT_ERROR: more than 3 reaching defs at updateReachingDefA");
+            SET_JIT_ERROR(kJitErrorRegAllocFailed);
+            return -1;
         }
         currentBB->infoBasicBlock[indexToA].reachingDefs[k].offsetPC = offsetPC;
         currentBB->infoBasicBlock[indexToA].reachingDefs[k].regNum = currentInfo.regNum;
@@ -1185,20 +1250,23 @@ void updateReachingDefA(int indexToA, OverlapCase isBPartiallyOverlapA) {
     ALOGI("IN updateReachingDefA for VR %d %d", currentBB->infoBasicBlock[indexToA].regNum,
           currentBB->infoBasicBlock[indexToA].physicalType);
     for(k = 0; k < currentBB->infoBasicBlock[indexToA].num_reaching_defs; k++)
-        ALOGI("reaching def %d @ %d for VR %d %d access %d", k,
+        ALOGI("Reaching def %d @ %d for VR %d %d access %d", k,
               currentBB->infoBasicBlock[indexToA].reachingDefs[k].offsetPC,
               currentBB->infoBasicBlock[indexToA].reachingDefs[k].regNum,
               currentBB->infoBasicBlock[indexToA].reachingDefs[k].physicalType,
               currentBB->infoBasicBlock[indexToA].reachingDefs[k].accessType);
 #endif
+    return 0;
 }
 
-/** Given a variable B @currentInfo,
-    updates its reaching defs by checking reaching defs of variable A @currentBB->infoBasicBlock[indexToA]
-    The result is stored in tmpInfo.reachingDefs
-*/
-void updateReachingDefB1(int indexToA) {
-    if(indexToA < 0) return;
+//! \brief updateReachingDefB1
+//! \detail Given a variable B @currentInfo, updates its reaching defs
+//! by checking reaching defs of variable A @currentBB->infoBasicBlock[indexToA]
+//! The result is stored in tmpInfo.reachingDefs
+//! \param indexToA Index of variable A
+//! \return -1 if error, 0 otherwise
+static int updateReachingDefB1(int indexToA) {
+    if(indexToA < 0) return 0;
     int k;
     tmpInfo.num_reaching_defs = 0;
     for(k = 0; k < currentBB->infoBasicBlock[indexToA].num_reaching_defs; k++) {
@@ -1235,21 +1303,26 @@ void updateReachingDefB1(int indexToA) {
         }
         if(insert1) {
             if(tmpInfo.num_reaching_defs >= 3) {
-                ALOGE("more than 3 reaching defs for tmpInfo");
+                ALOGE("JIT_ERROR: more than 3 reaching defs for tmpInfo at updateReachingDefB1");
+                SET_JIT_ERROR(kJitErrorRegAllocFailed);
+                return -1;
             }
             tmpInfo.reachingDefs[tmpInfo.num_reaching_defs] = currentBB->infoBasicBlock[indexToA].reachingDefs[k];
             tmpInfo.num_reaching_defs++;
 #ifdef DEBUG_REACHING_DEF2
-            ALOGI("insert from entry %d %d: index %d", currentBB->infoBasicBlock[indexToA].regNum,
+            ALOGI("Insert from entry %d %d: index %d", currentBB->infoBasicBlock[indexToA].regNum,
                   currentBB->infoBasicBlock[indexToA].physicalType, k);
 #endif
         }
     }
+    return 0;
 }
 
-/** update currentInfo.reachingDefs by merging currentInfo.reachingDefs with tmpInfo.reachingDefs
-*/
-void updateReachingDefB2() {
+//! \brief updateReachingDefB2
+//! \details update currentInfo.reachingDefs by merging
+//! currentInfo.reachingDefs with tmpInfo.reachingDefs
+//! \return -1 if error, 0 otherwise
+static int updateReachingDefB2(void) {
     int k, k2;
     for(k2 = 0; k2 < tmpInfo.num_reaching_defs; k2++ ) {
         bool merged = false;
@@ -1259,24 +1332,32 @@ void updateReachingDefB2() {
                currentInfo.reachingDefs[k].physicalType == tmpInfo.reachingDefs[k2].physicalType) {
                 merged = true;
                 if(currentInfo.reachingDefs[k].offsetPC != tmpInfo.reachingDefs[k2].offsetPC) {
-                    ALOGE("defs on the same VR %d %d with different offsetPC %d vs %d",
+                    ALOGE("JIT_ERROR: defs on the same VR %d %d with different offsetPC %d vs %d",
                           currentInfo.reachingDefs[k].regNum, currentInfo.reachingDefs[k].physicalType,
                           currentInfo.reachingDefs[k].offsetPC, tmpInfo.reachingDefs[k2].offsetPC);
+                    SET_JIT_ERROR(kJitErrorRegAllocFailed);
+                    return -1;
                 }
-                if(currentInfo.reachingDefs[k].accessType != tmpInfo.reachingDefs[k2].accessType)
-                    ALOGE("defs on the same VR %d %d with different accessType",
+                if(currentInfo.reachingDefs[k].accessType != tmpInfo.reachingDefs[k2].accessType) {
+                    ALOGE("JIT_ERROR: defs on the same VR %d %d with different accessType\n",
                           currentInfo.reachingDefs[k].regNum, currentInfo.reachingDefs[k].physicalType);
+                    SET_JIT_ERROR(kJitErrorRegAllocFailed);
+                    return -1;
+                }
                 break;
             }
         }
         if(!merged) {
             if(currentInfo.num_reaching_defs >= 3) {
-               ALOGE("more than 3 reaching defs for currentInfo");
+                ALOGE("JIT_ERROR: more than 3 reaching defs for currentInfo at updateReachingDefB2\n");
+                SET_JIT_ERROR(kJitErrorRegAllocFailed);
+                return -1;
             }
             currentInfo.reachingDefs[currentInfo.num_reaching_defs] = tmpInfo.reachingDefs[k2];
             currentInfo.num_reaching_defs++;
         }
     }
+    return 0;
 }
 
 //!update currentInfo.reachingDefs with currentInfo if variable is defined in currentInfo
@@ -1337,13 +1418,18 @@ void updateDefUseTable() {
     }
 }
 
-//! insert a use at offsetPC of given variable at end of DefUsePair
-
-//!
+//! \brief insertAUse
+//! \detail Insert a use at offsetPC of given variable at end of DefUsePair
+//! \param ptr The DefUsePair
+//! \param offsetPC
+//! \param regNum
+//! \param physicalType
+//! \return useType
 RegAccessType insertAUse(DefUsePair* ptr, int offsetPC, int regNum, LowOpndRegType physicalType) {
     DefOrUseLink* tLink = (DefOrUseLink*)malloc(sizeof(DefOrUseLink));
     if(tLink == NULL) {
-        ALOGE("Memory allocation failed");
+        ALOGE("JIT_ERROR: Memory allocation failed at insertAUse");
+        SET_JIT_ERROR(kJitErrorMallocFailed);
         return REGACCESS_UNKNOWN;
     }
     tLink->offsetPC = offsetPC;
@@ -1366,13 +1452,19 @@ RegAccessType insertAUse(DefUsePair* ptr, int offsetPC, int regNum, LowOpndRegTy
     return useType;
 }
 
-//! insert a def to currentBB->defUseTable
-
+//! \brief insertADef
+//! \detailsinsert a def to currentBB->defUseTable
 //! update currentBB->defUseTail if necessary
+//! \param offsetPC
+//! \param regNum
+//! \param pType Physical type
+//! \param rType Register access type
+//! \return DefUsePair
 DefUsePair* insertADef(int offsetPC, int regNum, LowOpndRegType pType, RegAccessType rType) {
     DefUsePair* ptr = (DefUsePair*)malloc(sizeof(DefUsePair));
     if(ptr == NULL) {
-        ALOGE("Memory allocation failed");
+        ALOGE("JIT_ERROR: Memory allocation failed at insertADef");
+        SET_JIT_ERROR(kJitErrorMallocFailed);
         return NULL;
     }
     ptr->next = NULL;
@@ -1391,7 +1483,7 @@ DefUsePair* insertADef(int offsetPC, int regNum, LowOpndRegType pType, RegAccess
         currentBB->defUseTable = ptr;
     currentBB->num_defs++;
 #ifdef DEBUG_REACHING_DEF
-    ALOGI("insert a def at %d to defUseTable for VR %d %d", offsetPC,
+    ALOGI("Insert a def at %d to defUseTable for VR %d %d", offsetPC,
           regNum, pType);
 #endif
     return ptr;
@@ -1429,10 +1521,15 @@ RegAccessType insertDefUsePair(int reachingDefIndex) {
     return useType;
 }
 
-//! insert a XFER_MEM_TO_XMM to currentBB->xferPoints
-
-//!
-void insertLoadXfer(int offset, int regNum, LowOpndRegType pType) {
+/* @brief insert a XFER_MEM_TO_XMM to currentBB->xferPoints
+ *
+ * @params offset offsetPC of the transfer location
+ * @params regNum Register number
+ * @params pType Physical type of the reg
+ *
+ * @return -1 if error occurred, 0 otherwise
+ */
+static int insertLoadXfer(int offset, int regNum, LowOpndRegType pType) {
     //check whether it is already in currentBB->xferPoints
     int k;
     for(k = 0; k < currentBB->num_xfer_points; k++) {
@@ -1440,20 +1537,22 @@ void insertLoadXfer(int offset, int regNum, LowOpndRegType pType) {
            currentBB->xferPoints[k].offsetPC == offset &&
            currentBB->xferPoints[k].regNum == regNum &&
            currentBB->xferPoints[k].physicalType == pType)
-            return;
+            return 0;
     }
     currentBB->xferPoints[currentBB->num_xfer_points].xtype = XFER_MEM_TO_XMM;
     currentBB->xferPoints[currentBB->num_xfer_points].regNum = regNum;
     currentBB->xferPoints[currentBB->num_xfer_points].offsetPC = offset;
     currentBB->xferPoints[currentBB->num_xfer_points].physicalType = pType;
 #ifdef DEBUG_XFER_POINTS
-    ALOGI("insert to xferPoints %d: XFER_MEM_TO_XMM of VR %d %d at %d", currentBB->num_xfer_points, regNum, pType, offset);
+    ALOGI("Insert to xferPoints %d: XFER_MEM_TO_XMM of VR %d %d at %d", currentBB->num_xfer_points, regNum, pType, offset);
 #endif
     currentBB->num_xfer_points++;
     if(currentBB->num_xfer_points >= MAX_XFER_PER_BB) {
-        ALOGE("too many xfer points");
-        dvmAbort();
+        ALOGE("JIT_ERROR: Number of transfer points (%d) exceed maximum (%d)", currentBB->num_xfer_points, MAX_XFER_PER_BB);
+        SET_JIT_ERROR(kJitErrorMaxXferPoints);
+        return -1;
     }
+    return 0;
 }
 
 /** update defUseTable by assuming a fake usage at END of a basic block for variable @ currentInfo
@@ -1483,8 +1582,12 @@ int fakeUsageAtEndOfBB(BasicBlock_O1* bb) {
         else if(isBPartiallyOverlapA != OVERLAP_NO) {
             /* B overlaps with A */
             /* update reaching defs of variable B by checking reaching defs of bb->infoBasicBlock[jj] */
-            updateReachingDefB1(jj);
-            updateReachingDefB2(); //merge currentInfo with tmpInfo
+            int retCode = updateReachingDefB1(jj);
+            if (retCode < 0)
+                return retCode;
+            retCode = updateReachingDefB2(); //merge currentInfo with tmpInfo
+            if (retCode < 0)
+                return retCode;
         }
     }
     /* update defUseTable by checking currentInfo */
@@ -1529,8 +1632,10 @@ int updateXferPoints() {
                    ptrUse->physicalType == LowOpndRegType_ss) {
                     /* if a 32-bit definition reaches a xmm usage or a SS usage,
                        insert a XFER_MEM_TO_XMM */
-                    insertLoadXfer(ptrUse->offsetPC,
+                    int retCode = insertLoadXfer(ptrUse->offsetPC,
                                    ptrUse->regNum, LowOpndRegType_xmm);
+                    if (retCode < 0)
+                        return retCode;
                 }
                 ptrUse = ptrUse->next;
             }
@@ -1553,12 +1658,13 @@ int updateXferPoints() {
                 }
                 currentBB->xferPoints[currentBB->num_xfer_points].tableIndex = k;
 #ifdef DEBUG_XFER_POINTS
-                ALOGI("insert XFER %d at def %d: V%d %d", currentBB->num_xfer_points, ptr->def.offsetPC, ptr->def.regNum, defType);
+                ALOGI("Insert XFER %d at def %d: V%d %d", currentBB->num_xfer_points, ptr->def.offsetPC, ptr->def.regNum, defType);
 #endif
                 currentBB->num_xfer_points++;
                 if(currentBB->num_xfer_points >= MAX_XFER_PER_BB) {
-                    ALOGE("too many xfer points");
-                    dvmAbort();
+                    ALOGE("JIT_ERROR: Number of transfer points (%d) exceed maximum (%d)", currentBB->num_xfer_points, MAX_XFER_PER_BB);
+                    SET_JIT_ERROR(kJitErrorMaxXferPoints);
+                    return -1;
                 }
             }
         }
@@ -1589,9 +1695,12 @@ int updateXferPoints() {
                    ptrUse->regNum == ptr->def.regNum) {
                     hasAligned = true;
                     /* if def is on FS and use is on XMM, insert a XFER_MEM_TO_XMM */
-                    if(defType == LowOpndRegType_fs)
-                        insertLoadXfer(ptrUse->offsetPC,
+                    if(defType == LowOpndRegType_fs) {
+                        int retCode = insertLoadXfer(ptrUse->offsetPC,
                                        ptrUse->regNum, LowOpndRegType_xmm);
+                        if (retCode < 0)
+                            return retCode;
+                    }
                 }
                 if(ptrUse->physicalType == LowOpndRegType_fs ||
                    ptrUse->physicalType == LowOpndRegType_fs_s)
@@ -1600,14 +1709,18 @@ int updateXferPoints() {
                    ptrUse->regNum != ptr->def.regNum) {
                     hasMisaligned = true;
                     /* if use is on XMM and use and def are misaligned, insert a XFER_MEM_TO_XMM */
-                    insertLoadXfer(ptrUse->offsetPC,
+                    int retCode = insertLoadXfer(ptrUse->offsetPC,
                                    ptrUse->regNum, LowOpndRegType_xmm);
+                    if (retCode < 0)
+                        return retCode;
                 }
                 if(ptrUse->physicalType == LowOpndRegType_ss) {
                     hasSSUsage = true;
                     /* if use is on SS, insert a XFER_MEM_TO_XMM */
-                    insertLoadXfer(ptrUse->offsetPC,
+                    int retCode = insertLoadXfer(ptrUse->offsetPC,
                                    ptrUse->regNum, LowOpndRegType_ss);
+                    if (retCode < 0)
+                        return retCode;
                 }
                 ptrUse = ptrUse->next;
             }
@@ -1634,12 +1747,13 @@ int updateXferPoints() {
             if(hasAligned) currentBB->xferPoints[currentBB->num_xfer_points].dumpToXmm = true;
             currentBB->xferPoints[currentBB->num_xfer_points].tableIndex = k;
 #ifdef DEBUG_XFER_POINTS
-            ALOGI("insert XFER %d at def %d: V%d %d", currentBB->num_xfer_points, ptr->def.offsetPC, ptr->def.regNum, defType);
+            ALOGI("Insert XFER %d at def %d: V%d %d", currentBB->num_xfer_points, ptr->def.offsetPC, ptr->def.regNum, defType);
 #endif
             currentBB->num_xfer_points++;
             if(currentBB->num_xfer_points >= MAX_XFER_PER_BB) {
-                ALOGE("too many xfer points");
-                dvmAbort();
+                ALOGE("JIT_ERROR: Number of transfer points (%d) exceed maximum (%d)", currentBB->num_xfer_points, MAX_XFER_PER_BB);
+                SET_JIT_ERROR(kJitErrorMaxXferPoints);
+                return -1;
             }
         }
         ptr = ptr->next;
@@ -1654,13 +1768,18 @@ int updateXferPoints() {
               currentBB->xferPoints[k].dumpToMem, currentBB->xferPoints[k].dumpToXmm);
     }
 #endif
-    return -1;
+    return 0;
 }
 
-//! update memVRTable[].ranges by browsing the defUseTable
-
-//! each virtual register has a list of live ranges, and each live range has a list of PCs that access the VR
-void updateLiveTable() {
+/* @brief update memVRTable[].ranges by browsing the defUseTable
+ *
+ * @detail each virtual register has a list of live ranges, and
+ * each live range has a list of PCs that access the VR
+ *
+ * @return -1 if error happened, 0 otherwise
+ */
+static int updateLiveTable(void) {
+    int retCode = 0;
     DefUsePair* ptr = currentBB->defUseTable;
     while(ptr != NULL) {
         bool updateUse = false;
@@ -1668,8 +1787,9 @@ void updateLiveTable() {
             ptr->num_uses = 1;
             ptr->uses = (DefOrUseLink*)malloc(sizeof(DefOrUseLink));
             if(ptr->uses == NULL) {
-                ALOGE("Memory allocation failed");
-                return;
+                ALOGE("JIT_ERROR: Memory allocation failed in updateLiveTable");
+                SET_JIT_ERROR(kJitErrorMallocFailed);
+                return -1;
             }
             ptr->uses->accessType = REGACCESS_D;
             ptr->uses->regNum = ptr->def.regNum;
@@ -1684,16 +1804,22 @@ void updateLiveTable() {
             RegAccessType useType = ptrUse->accessType;
             if(useType == REGACCESS_L || useType == REGACCESS_D) {
                 int indexL = searchMemTable(ptrUse->regNum);
-                if(indexL >= 0)
-                    mergeLiveRange(indexL, ptr->def.offsetPC,
+                if(indexL >= 0) {
+                    retCode = mergeLiveRange(indexL, ptr->def.offsetPC,
                                    ptrUse->offsetPC); //tableIndex, start PC, end PC
+                    if (retCode < 0)
+                        return retCode;
+                }
             }
             if(getRegSize(ptrUse->physicalType) == OpndSize_64 &&
                (useType == REGACCESS_H || useType == REGACCESS_D)) {
                 int indexH = searchMemTable(ptrUse->regNum+1);
-                if(indexH >= 0)
-                    mergeLiveRange(indexH, ptr->def.offsetPC,
+                if(indexH >= 0) {
+                    retCode = mergeLiveRange(indexH, ptr->def.offsetPC,
                                    ptrUse->offsetPC);
+                    if (retCode < 0)
+                        return retCode;
+                }
             }
             ptrUse = ptrUse->next;
         }//while ptrUse
@@ -1720,12 +1846,21 @@ void updateLiveTable() {
         ALOGI("");
     }
 #endif
+    return 0;
 }
 
-//!add a live range [rangeStart, rangeEnd] to ranges of memVRTable, merge to existing live ranges if necessary
-
-//!ranges are in increasing order of startPC
-void mergeLiveRange(int tableIndex, int rangeStart, int rangeEnd) {
+/* @brief Add a live range [rangeStart, rangeEnd] to ranges of memVRTable,
+ * merge to existing live ranges if necessary
+ *
+ * @detail ranges are in increasing order of startPC
+ *
+ * @param tableIndex index into memVRTable
+ * @param rangeStart start of live range
+ * @param rangeEnd end of live range
+ *
+ * @return -1 if error, 0 otherwise
+ */
+static int mergeLiveRange(int tableIndex, int rangeStart, int rangeEnd) {
     if(rangeStart == PC_FOR_START_OF_BB) rangeStart = currentBB->pc_start;
     if(rangeEnd == PC_FOR_END_OF_BB) rangeEnd = currentBB->pc_end;
 #ifdef DEBUG_LIVE_RANGE
@@ -1816,18 +1951,24 @@ void mergeLiveRange(int tableIndex, int rangeStart, int rangeEnd) {
 #ifdef DEBUG_LIVE_RANGE
         ALOGI("LIVERANGE insert one live range [%x %x] to tableIndex %d", rangeStart, rangeEnd, tableIndex);
 #endif
-        return;
+        return 0;
     }
     if(!endBeforeRange) { //here ptrEnd is not NULL
         endIndex++; //next
         ptrEnd_prev = ptrEnd; //ptrEnd_prev is not NULL
         ptrEnd = ptrEnd->next; //ptrEnd can be NULL
     }
-    if(endIndex < startIndex+1) ALOGE("mergeLiveRange endIndex %d startIndex %d", endIndex, startIndex);
+
+    if(endIndex < startIndex+1) {
+        ALOGE("JIT_ERROR: mergeLiveRange endIndex %d is less than startIndex %d\n", endIndex, startIndex);
+        SET_JIT_ERROR(kJitErrorMergeLiveRange);
+        return -1;
+    }
     ///////// use ptrStart & ptrEnd_prev
     if(ptrStart == NULL || ptrEnd_prev == NULL) {
-        ALOGE("mergeLiveRange ptr is NULL");
-        return;
+        ALOGE("JIT_ERROR: mergeLiveRange ptr is NULL\n");
+        SET_JIT_ERROR(kJitErrorMergeLiveRange);
+        return -1;
     }
     //endIndex > startIndex (merge the ranges between startIndex and endIndex-1)
     //update ptrStart
@@ -1839,7 +1980,10 @@ void mergeLiveRange(int tableIndex, int rangeStart, int rangeEnd) {
 #ifdef DEBUG_LIVE_RANGE
     ALOGI("LIVERANGE merge entries for tableIndex %d from %d to %d", tableIndex, startIndex+1, endIndex-1);
 #endif
-    if(ptrStart->num_access <= 0) ALOGE("mergeLiveRange number of access");
+    if(ptrStart->num_access <= 0) {
+        ALOGE("JIT_ERROR: mergeLiveRange number of access");
+        SET_JIT_ERROR(kJitErrorMergeLiveRange);
+    }
 #ifdef DEBUG_LIVE_RANGE
     ALOGI("LIVERANGE tableIndex %d startIndex %d num_access %d (", tableIndex, startIndex, ptrStart->num_access);
     for(k = 0; k < ptrStart->num_access; k++)
@@ -1873,7 +2017,9 @@ void mergeLiveRange(int tableIndex, int rangeStart, int rangeEnd) {
 #ifdef DEBUG_LIVE_RANGE
     ALOGI("num_ranges for VR %d: %d", memVRTable[tableIndex].regNum, memVRTable[tableIndex].num_ranges);
 #endif
+    return 0;
 }
+
 //! insert an access to a given live range, in order
 
 //!
@@ -2255,7 +2401,8 @@ int updateVirtualReg(int reg, LowOpndRegType pType) {
                 //def at xmm: content of misaligned xmm is out-dated
                 //invalidateXmmVR(currentBB->xferPoints[k].tableIndex);
 #ifdef DEBUG_XFER_POINTS
-                if(currentBB->xferPoints[k].dumpToXmm) ALOGI("XFER set_virtual_reg to xmm: xmm VR %d", reg);
+                if(currentBB->xferPoints[k].dumpToXmm)
+                    ALOGI("XFER set_virtual_reg to xmm: xmm VR %d", reg);
 #endif
                 if(pType == LowOpndRegType_xmm)  {
 #ifdef DEBUG_XFER_POINTS
@@ -2323,7 +2470,8 @@ int registerAlloc(int type, int reg, bool isPhysical, bool updateRefCount) {
     if(newType & LowOpndRegType_scratch) reg = reg - PhysicalReg_SCRATCH_1 + 1;
     int tIndex = searchCompileTable(newType, reg);
     if(tIndex < 0) {
-      ALOGE("reg %d type %d not found in registerAlloc", reg, newType);
+      ALOGE("JIT_ERROR: reg %d type %d not found in registerAlloc\n", reg, newType);
+      SET_JIT_ERROR(kJitErrorRegAllocFailed);
       return PhysicalReg_Null;
     }
 
@@ -2385,8 +2533,11 @@ int registerAlloc(int type, int reg, bool isPhysical, bool updateRefCount) {
 
 //!This is used when MOVE_OPT is on, it tries to alias a virtual register with a temporary to remove a move
 int registerAllocMove(int reg, int type, bool isPhysical, int srcReg) {
-    if(srcReg == PhysicalReg_EDI || srcReg == PhysicalReg_ESP || srcReg == PhysicalReg_EBP)
-        ALOGE("can't move from srcReg EDI or ESP or EBP");
+    if(srcReg == PhysicalReg_EDI || srcReg == PhysicalReg_ESP || srcReg == PhysicalReg_EBP) {
+        ALOGE("JIT_ERROR: Cannot move from srcReg EDI or ESP or EBP");
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
+        return -1;
+    }
 #ifdef DEBUG_REGALLOC
     ALOGI("in registerAllocMove: reg %d type %d srcReg %d", reg, type, srcReg);
 #endif
@@ -2394,7 +2545,8 @@ int registerAllocMove(int reg, int type, bool isPhysical, int srcReg) {
     if(newType & LowOpndRegType_scratch) reg = reg - PhysicalReg_SCRATCH_1 + 1;
     int index = searchCompileTable(newType, reg);
     if(index < 0) {
-        ALOGE("reg %d type %d not found in registerAllocMove", reg, newType);
+        ALOGE("JIT_ERROR: reg %d type %d not found in registerAllocMove", reg, newType);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return -1;
     }
 
@@ -2446,9 +2598,11 @@ int getFreeReg(int type, int reg, int indexToCompileTable) {
 
         int index = searchVirtualInfoOfBB((LowOpndRegType)(type&MASK_FOR_TYPE), reg, currentBB);
         if(index < 0) {
-            ALOGE("VR %d %d not found in infoBasicBlock of currentBB %d (num of VRs %d)",
+            ALOGE("JIT_ERROR: VR %d %d not found in infoBasicBlock of currentBB %d (num of VRs %d)",
                   reg, type, currentBB->bb_index, currentBB->num_regs);
-            dvmAbort();
+            SET_JIT_ERROR(kJitErrorRegAllocFailed);
+            //Error trickles down to dvmCompilerMIR2LIR, trace is rejected
+            return -1;
         }
 
         /* check allocConstraints for this VR,
@@ -2496,18 +2650,22 @@ int getFreeReg(int type, int reg, int indexToCompileTable) {
         if(vr_num >= 0) {
             int index3 = searchCompileTable(LowOpndRegType_gp | LowOpndRegType_virtual, vr_num);
             if(index3 < 0) {
-                ALOGE("2 in tracing linkage to VR %d", vr_num);
-                dvmAbort();
+                ALOGE("JIT_ERROR: Inavlid linkage VR for temporary register %d", vr_num);
+                SET_JIT_ERROR(kJitErrorRegAllocFailed);
+                //Error trickles down to dvmCompilerMIR2LIR, trace is rejected
+                return -1;
             }
 
             if(compileTable[index3].physicalReg == PhysicalReg_Null) {
                 int index2 = searchVirtualInfoOfBB(LowOpndRegType_gp, vr_num, currentBB);
                 if(index2 < 0) {
-                    ALOGE("1 in tracing linkage to VR %d", vr_num);
-                    dvmAbort();
+                    ALOGE("JIT_ERROR: In tracing linkage to VR %d", vr_num);
+                    SET_JIT_ERROR(kJitErrorRegAllocFailed);
+                    //Error trickles down to dvmCompilerMIR2LIR, trace is rejected
+                    return -1;
                 }
 #ifdef DEBUG_REGALLOC
-                ALOGI("in getFreeReg for temporary reg %d, trace the linkage to VR %d",
+                ALOGI("In getFreeReg for temporary reg %d, trace the linkage to VR %d",
                      reg, vr_num);
 #endif
 
@@ -2701,8 +2859,10 @@ PhysicalReg spillForLogicalReg(int type, int reg, int indexToCompileTable) {
     }
     if(index < 0) {
         dumpCompileTable();
-        ALOGE("no register to spill for logical %d %d", reg, type);
-        dvmAbort();
+        ALOGE("JIT_ERROR: no register to spill for logical %d %d\n", reg, type);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
+        //Error trickles down to dvmCompilerMIR2LIR, trace is rejected
+        return PhysicalReg_Null;
     }
     allocR = (PhysicalReg)spillLogicalReg(index, true);
 #ifdef DEBUG_REGALLOC
@@ -2718,8 +2878,10 @@ PhysicalReg spillForLogicalReg(int type, int reg, int indexToCompileTable) {
 //!Return the physical register that was allocated to the variable
 int spillLogicalReg(int spill_index, bool updateTable) {
     if((compileTable[spill_index].physicalType & LowOpndRegType_hard) != 0) {
-        ALOGE("can't spill a hard-coded register");
-        dvmAbort();
+        ALOGE("JIT_ERROR: can't spill a hard-coded register");
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
+        //Error trickles down to dvmCompilerMIR2LIR, trace is rejected
+        return -1;
     }
     int physicalReg = compileTable[spill_index].physicalReg;
     if(!canSpillReg[physicalReg]) {
@@ -2789,7 +2951,8 @@ int unspillLogicalReg(int spill_index, int physicalReg) {
 int spillVirtualReg(int vrNum, LowOpndRegType type, bool updateTable) {
     int index = searchCompileTable(type | LowOpndRegType_virtual, vrNum);
     if(index < 0) {
-        ALOGE("can't find VR %d %d in spillVirtualReg", vrNum, type);
+        ALOGE("JIT_ERROR: Cannot find VR %d %d in spillVirtualReg", vrNum, type);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return -1;
     }
     //check whether it is const
@@ -2841,7 +3004,9 @@ int spillForHardReg(int regNum, int type) {
 //! allocConstraints specify how many times a hardcoded register is used in this basic block
 void updateCurrentBBWithConstraints(PhysicalReg reg) {
     if(reg > PhysicalReg_EBP) {
-        ALOGE("register %d out of range in updateCurrentBBWithConstraints", reg);
+        ALOGE("JIT_ERROR: Register %d out of range in updateCurrentBBWithConstraints\n", reg);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
+        return;
     }
     currentBB->allocConstraints[reg].count++;
 }
@@ -2899,14 +3064,18 @@ int sortAllocConstraint(RegAllocConstraint* allocConstraints,
 #endif
     return 0;
 }
-//! find the entry for a given virtual register in compileTable
 
-//!
-int findVirtualRegInTable(u2 vA, LowOpndRegType type, bool printError) {
+//! \brief find the entry for a given virtual register in compileTable
+//! \param vA The VR to search for
+//! \param type Register type
+//! \return the virtual reg if found, else -1 as error.
+int findVirtualRegInTable(u2 vA, LowOpndRegType type) {
     int k = searchCompileTable(type | LowOpndRegType_virtual, vA);
-    if(k < 0 && printError) {
-        ALOGE("findVirtualRegInTable virtual register %d type %d", vA, type);
-        dvmAbort();
+    if(k < 0) {
+        ALOGE("JIT_ERROR: Couldn't find virtual register %d type %d in compiler table\n", vA, type);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
+        //Error trickles down to dvmCompilerMIR2LIR, trace is rejected
+        return -1;
     }
     return k;
 }
@@ -2951,7 +3120,11 @@ int isVirtualRegConstant(int regNum, LowOpndRegType type, int* valuePtr, bool up
     if((isConstL && size == OpndSize_32) || (isConstL && isConstH)) {
         if(updateRefCount) {
             int indexOrig = searchCompileTable(type | LowOpndRegType_virtual, regNum);
-            if(indexOrig < 0) ALOGE("can't find VR in isVirtualRegConstant num %d type %d", regNum, type);
+            if(indexOrig < 0) {
+                ALOGE("JIT_ERROR: Cannot find VR in isVirtualRegConstant num %d type %d\n", regNum, type);
+                SET_JIT_ERROR(kJitErrorRegAllocFailed);
+                return -1;
+            }
             decreaseRefCount(indexOrig);
         }
 #ifdef DEBUG_CONST
@@ -3165,10 +3338,12 @@ int updateVRAtUse(int reg, LowOpndRegType pType, int regAll) {
 #define MAX_NUM_DEAD_PC_IN_BB 40
 int deadPCs[MAX_NUM_DEAD_PC_IN_BB];
 int num_dead_pc = 0;
-//! collect all PCs that can be removed
 
-//! traverse each byte code in the current basic block and check whether it can be removed, if yes, update deadPCs
-void getDeadStmts() {
+//! \brief collect all PCs that can be removed
+//!
+//! \details traverse each byte code in the current basic block and check whether it can be removed, if yes, update deadPCs
+//! \return -1 if error happened, 0 otherwise
+static int getDeadStmts() {
     BasicBlock_O1* bb = currentBB;
     int k;
     num_dead_pc = 0;
@@ -3183,7 +3358,7 @@ void getDeadStmts() {
         bool isDeadStmt = true;
         getVirtualRegInfo(infoByteCode, mir);
         u2 inst_op = mir->dalvikInsn.opcode;
-	//skip bytecodes with side effect
+        //skip bytecodes with side effect
         if(inst_op != OP_CONST_STRING && inst_op != OP_CONST_STRING_JUMBO &&
            inst_op != OP_MOVE && inst_op != OP_MOVE_OBJECT &&
            inst_op != OP_MOVE_FROM16 && inst_op != OP_MOVE_OBJECT_FROM16 &&
@@ -3202,9 +3377,10 @@ void getDeadStmts() {
                 num_defs++;
                 DefUsePair* indexT = searchDefUseTable(offsetPC, infoByteCode[k].regNum, infoByteCode[k].physicalType);
                 if(indexT == NULL) {
-                    ALOGE("def at %x of VR %d %d not in table",
-                           offsetPC, infoByteCode[k].regNum, infoByteCode[k].physicalType);
-                    return;
+                    ALOGE("JIT_ERROR: Def at %x of VR %d %d not in table\n",
+                        offsetPC, infoByteCode[k].regNum, infoByteCode[k].physicalType);
+                    SET_JIT_ERROR(kJitErrorRegAllocFailed);
+                    return -1;
                 }
                 if(indexT->num_uses > 0) {
                     isDeadStmt = false;
@@ -3227,20 +3403,26 @@ void getDeadStmts() {
     } //for offsetPC
 #ifdef DEBUG_DSE
     ALOGI("Dead Stmts: ");
-    for(k = 0; k < num_dead_pc; k++) ALOGI("%x ", deadPCs[k]);
-    ALOGI("");
+    for(k = 0; k < num_dead_pc; k++)
+        ALOGI("%x ", deadPCs[k]);
 #endif
+    return 0;
 }
-//! entry point to remove dead statements
-
-//! recursively call getDeadStmts and remove uses in defUseTable that are from a dead PC
+//! \brief entry point to remove dead statements
+//!
+//! \details recursively call getDeadStmts and remove uses in defUseTable that are from a dead PC
 //! until there is no change to number of dead PCs
-void removeDeadDefs() {
+//! \return -1 if error happened, 0 otherwise
+static int removeDeadDefs() {
     int k;
     int deadPCs_2[MAX_NUM_DEAD_PC_IN_BB];
     int num_dead_pc_2 = 0;
-    getDeadStmts();
-    if(num_dead_pc == 0) return;
+    int retCode = 0;
+    retCode = getDeadStmts();
+    if (retCode < 0)
+        return retCode;
+    if(num_dead_pc == 0)
+        return 0;
     DefUsePair* ptr = NULL;
     DefOrUseLink* ptrUse = NULL;
     DefOrUseLink* ptrUse_prev = NULL;
@@ -3283,13 +3465,15 @@ void removeDeadDefs() {
             }//while ptrUse
             ptr = ptr->next;
         }//while ptr
-	//save deadPCs in deadPCs_2
+        //save deadPCs in deadPCs_2
         num_dead_pc_2 = num_dead_pc;
         for(k = 0; k < num_dead_pc_2; k++)
             deadPCs_2[k] = deadPCs[k];
-	//update deadPCs
-        getDeadStmts();
-	//if no change to number of dead PCs, break out of the while loop
+        //update deadPCs
+        retCode = getDeadStmts();
+        if (retCode < 0)
+            return retCode;
+        //if no change to number of dead PCs, break out of the while loop
         if(num_dead_pc_2 == num_dead_pc) break;
     }//while
 #ifdef DEBUG_DSE
@@ -3297,8 +3481,8 @@ void removeDeadDefs() {
     for(k = 0; k < num_dead_pc; k++) {
         ALOGI("%d ", deadPCs[k]);
     }
-    ALOGI("");
 #endif
+    return 0;
 }
 /////////////////////////////////////////////////////////////
 //!search memVRTable for a given virtual register
@@ -3337,13 +3521,15 @@ void setVRToMemory(int regNum, OpndSize size) {
     int indexH = -1;
     if(size == OpndSize_64) indexH = searchMemTable(regNum+1);
     if(indexL < 0) {
-        ALOGE("VR %d not in memVRTable", regNum);
+        ALOGE("JIT_ERROR: VR %d not in memVRTable at setVRToMemory", regNum);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return;
     }
     memVRTable[indexL].inMemory = true;
     if(size == OpndSize_64) {
         if(indexH < 0) {
-            ALOGE("VR %d not in memVRTable", regNum+1);
+            ALOGE("JIT_ERROR: VR %d not in memVRTabl at setVRToMemory for upper 64-bits", regNum+1);
+            SET_JIT_ERROR(kJitErrorRegAllocFailed);
             return;
         }
         memVRTable[indexH].inMemory = true;
@@ -3354,12 +3540,14 @@ void setVRToMemory(int regNum, OpndSize size) {
 //!
 bool isVRNullCheck(int regNum, OpndSize size) {
     if(size != OpndSize_32) {
-        ALOGE("isVRNullCheck size should be 32");
-        dvmAbort();
+        ALOGE("JIT_ERROR: isVRNullCheck size is not 32 for register %d", regNum);
+        SET_JIT_ERROR(kJitErrorNullBoundCheckFailed);
+        return false;
     }
     int indexL = searchMemTable(regNum);
     if(indexL < 0) {
-        ALOGE("VR %d not in memVRTable", regNum);
+        ALOGE("JIT_ERROR: VR %d not in memVRTable at isVRNullCheck", regNum);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return false;
     }
     return memVRTable[indexL].nullCheckDone;
@@ -3367,32 +3555,40 @@ bool isVRNullCheck(int regNum, OpndSize size) {
 bool isVRBoundCheck(int vr_array, int vr_index) {
     int indexL = searchMemTable(vr_array);
     if(indexL < 0) {
-        ALOGE("isVRBoundCheck: VR %d not in memVRTable", vr_array);
+        ALOGE("JIT_ERROR: VR %d not in memVRTable at isVRBoundCheck", vr_array);
+        SET_JIT_ERROR(kJitErrorNullBoundCheckFailed);
         return false;
     }
     if(memVRTable[indexL].boundCheck.indexVR == vr_index)
         return memVRTable[indexL].boundCheck.checkDone;
     return false;
 }
-//! set nullCheckDone in memVRTable to true
-
+//! \brief set nullCheckDone in memVRTable to true
+//!
+//! \param regNum the register number
+//! \param size the register size
 //!
-void setVRNullCheck(int regNum, OpndSize size) {
+//! \return -1 if error happened, 0 otherwise
+int setVRNullCheck(int regNum, OpndSize size) {
     if(size != OpndSize_32) {
-        ALOGE("setVRNullCheck size should be 32");
-        dvmAbort();
+        ALOGE("JIT_ERROR: setVRNullCheck size should be 32\n");
+        SET_JIT_ERROR(kJitErrorNullBoundCheckFailed);
+        return -1;
     }
     int indexL = searchMemTable(regNum);
     if(indexL < 0) {
-        ALOGE("VR %d not in memVRTable", regNum);
-        return;
+        ALOGE("JIT_ERROR: VR %d not in memVRTable at setVRNullCheck", regNum);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
+        return -1;
     }
     memVRTable[indexL].nullCheckDone = true;
+    return 0;
 }
 void setVRBoundCheck(int vr_array, int vr_index) {
     int indexL = searchMemTable(vr_array);
     if(indexL < 0) {
-        ALOGE("setVRBoundCheck: VR %d not in memVRTable", vr_array);
+        ALOGE("JIT_ERROR: VR %d not in memVRTable at setVRBoundCheck", vr_array);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return;
     }
     memVRTable[indexL].boundCheck.indexVR = vr_index;
@@ -3459,7 +3655,9 @@ int requestVRFreeDelay(int regNum, u4 reason) {
     if(indexL >= 0) {
         memVRTable[indexL].delayFreeFlags |= reason;
     } else {
-        ALOGE("requestVRFreeDelay: VR %d not in memVRTable", regNum);
+        ALOGE("JIT_ERROR: At requestVRFreeDelay: VR %d not in memVRTable", regNum);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
+        return -1;
     }
     return indexL;
 }
@@ -3622,7 +3820,8 @@ int getSpillIndex(bool isGLUE, OpndSize size) {
             return k;
         }
     }
-    ALOGE("can't find spill position in spillLogicalReg");
+    ALOGE("JIT_ERROR: Cannot find spill position in spillLogicalReg\n");
+    SET_JIT_ERROR(kJitErrorRegAllocFailed);
     return -1;
 }
 //!this is called before generating a native code, it sets entries in array canSpillReg to true
@@ -3926,7 +4125,8 @@ bool isTemp8Bit(int type, int reg) {
             return infoByteCodeTemp[k].is8Bit;
         }
     }
-    ALOGE("isTemp8Bit %d %d", type, reg);
+    ALOGE("JIT_ERROR: Could not find reg %d type %d at isTemp8Bit", reg, type);
+    SET_JIT_ERROR(kJitErrorRegAllocFailed);
     return false;
 }
 
@@ -3939,7 +4139,8 @@ bool isTemp8Bit(int type, int reg) {
 bool isVRLive(int vA) {
     int index = searchMemTable(vA);
     if(index < 0) {
-        ALOGE("couldn't find VR %d in memTable", vA);
+        ALOGE("JIT_ERROR: Could not find VR %d in memTable at isVRLive", vA);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return false;
     }
     LiveRange* ptr = memVRTable[index].ranges;
@@ -3962,7 +4163,8 @@ bool isLastByteCodeOfLiveRange(int compileIndex) {
         /* check live ranges for the VR */
         index = searchMemTable(compileTable[k].regNum);
         if(index < 0) {
-            ALOGE("couldn't find VR %d in memTable", compileTable[k].regNum);
+            ALOGE("JIT_ERROR: Could not find 32-bit VR %d in memTable at isLastByteCodeOfLiveRange", compileTable[k].regNum);
+            SET_JIT_ERROR(kJitErrorRegAllocFailed);
             return false;
         }
         ptr = memVRTable[index].ranges;
@@ -3977,7 +4179,8 @@ bool isLastByteCodeOfLiveRange(int compileIndex) {
     index = searchMemTable(compileTable[k].regNum);
     bool tmpB = false;
     if(index < 0) {
-        ALOGE("couldn't find VR %d in memTable", compileTable[k].regNum);
+        ALOGE("JIT_ERROR: Could not find 64-bit VR %d (lower 32) in memTable at isLastByteCodeOfLiveRange", compileTable[k].regNum);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return false;
     }
     ptr = memVRTable[index].ranges;
@@ -3992,7 +4195,8 @@ bool isLastByteCodeOfLiveRange(int compileIndex) {
     /* check live ranges of the high half */
     index = searchMemTable(compileTable[k].regNum+1);
     if(index < 0) {
-        ALOGE("couldn't find VR %d in memTable", compileTable[k].regNum+1);
+        ALOGE("JIT_ERROR: Could not find 64-bit VR %d (upper 32) in memTable at isLastByteCodeOfLiveRange", compileTable[k].regNum+1);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return false;
     }
     ptr = memVRTable[index].ranges;
@@ -4015,7 +4219,8 @@ bool loopIndepUse(int compileIndex) {
     /* check live ranges of the low half */
     index = searchMemTable(compileTable[k].regNum);
     if(index < 0) {
-        LOGE("ERROR in finding VR %d in memTable\n", compileTable[k].regNum);
+        ALOGE("JIT_ERROR: Could not find 32-bit VR %d in memTable at loopIndepUse", compileTable[k].regNum);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return false;
     }
     LiveRange* ptr = memVRTable[index].ranges;
@@ -4027,7 +4232,8 @@ bool loopIndepUse(int compileIndex) {
     /* check for the high half */
     index = searchMemTable(compileTable[k].regNum+1);
     if(index < 0) {
-        LOGE("ERROR in finding VR %d in memTable\n", compileTable[k].regNum+1);
+        ALOGE("JIT_ERROR: Could not find 64-bit VR %d in memTable at loopIndepUse", compileTable[k].regNum+1);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return false;
     }
     ptr = memVRTable[index].ranges;
@@ -4048,7 +4254,8 @@ bool reachEndOfBB(int compileIndex) {
     /* check live ranges of the low half */
     index = searchMemTable(compileTable[k].regNum);
     if(index < 0) {
-        ALOGE("couldn't find VR %d in memTable", compileTable[k].regNum);
+        ALOGE("JIT_ERROR: Could not find 32-bit VR %d in memTable at reachEndOfBB", compileTable[k].regNum);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return false;
     }
     LiveRange* ptr = memVRTable[index].ranges;
@@ -4067,7 +4274,8 @@ bool reachEndOfBB(int compileIndex) {
     /* check live ranges of the high half */
     index = searchMemTable(compileTable[k].regNum+1);
     if(index < 0) {
-        ALOGE("couldn't find VR %d in memTable", compileTable[k].regNum+1);
+        ALOGE("JIT_ERROR: Could not find 64-bit VR %d in memTable at reachEndOfBB", compileTable[k].regNum+1);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return false;
     }
     ptr = memVRTable[index].ranges;
@@ -4096,7 +4304,8 @@ bool isNextToLastAccess(int compileIndex) {
     bool retCode = false;
     index = searchMemTable(compileTable[k].regNum);
     if(index < 0) {
-        ALOGE("couldn't find VR %d in memTable", compileTable[k].regNum);
+        ALOGE("JIT_ERROR: Could not find 32-bit VR %d in memTable at isNextToLastAccess", compileTable[k].regNum);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return false;
     }
     LiveRange* ptr = memVRTable[index].ranges;
@@ -4119,7 +4328,8 @@ bool isNextToLastAccess(int compileIndex) {
     /* check live ranges for the high half */
     index = searchMemTable(compileTable[k].regNum+1);
     if(index < 0) {
-        ALOGE("couldn't find VR %d in memTable", compileTable[k].regNum+1);
+        ALOGE("JIT_ERROR: Could not find 64-bit VR %d in memTable at isNextToLastAccess", compileTable[k].regNum+1);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return false;
     }
     ptr = memVRTable[index].ranges;
@@ -4149,7 +4359,8 @@ int getNextLiveRange(int compileIndex) {
     int index;
     index = searchMemTable(compileTable[k].regNum);
     if(index < 0) {
-        ALOGE("couldn't find VR %d in memTable", compileTable[k].regNum);
+        ALOGE("JIT_ERROR: Could not find 32-bit VR %d in memTable at getNextLiveRange", compileTable[k].regNum);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return offsetPC;
     }
     bool found = false;
@@ -4170,7 +4381,8 @@ int getNextLiveRange(int compileIndex) {
     found = false;
     index = searchMemTable(compileTable[k].regNum+1);
     if(index < 0) {
-        ALOGE("couldn't find VR %d in memTable", compileTable[k].regNum+1);
+        ALOGE("JIT_ERROR: Could not find 64-bit VR %d in memTable at getNextLiveRange", compileTable[k].regNum+1);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return offsetPC;
     }
     int nextUse2 = offsetPC;
@@ -4199,7 +4411,8 @@ int getNextAccess(int compileIndex) {
     /* check live ranges of the low half */
     index = searchMemTable(compileTable[k].regNum);
     if(index < 0) {
-        ALOGE("couldn't find VR %d in memTable", compileTable[k].regNum);
+        ALOGE("JIT_ERROR: Could not find 32-bit VR %d in memTable at getNextAccess", compileTable[k].regNum);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return offsetPC;
     }
     bool found = false;
@@ -4230,7 +4443,8 @@ int getNextAccess(int compileIndex) {
     found = false;
     index = searchMemTable(compileTable[k].regNum+1);
     if(index < 0) {
-        ALOGE("couldn't find VR %d in memTable", compileTable[k].regNum+1);
+        ALOGE("JIT_ERROR: Could not find 64-bit VR %d in memTable at getNextAccess", compileTable[k].regNum+1);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return offsetPC;
     }
     int nextUse2 = offsetPC;
@@ -4354,7 +4568,9 @@ int freeReg(bool spillGL) {
                     /* update spill info for temporaries */
                     spillIndexUsed[compileTable[k].spill_loc_index >> 2] = 0;
                     compileTable[k].spill_loc_index = -1;
-                    ALOGE("free a temporary register with TRSTATE_SPILLED");
+                    ALOGE("JIT_ERROR: free a temporary register with TRSTATE_SPILLED\n");
+                    SET_JIT_ERROR(kJitErrorRegAllocFailed);
+                    return -1;
                 }
             }
         }
@@ -4373,8 +4589,10 @@ void decreaseRefCount(int index) {
 #endif
     compileTable[index].refCount--;
     if(compileTable[index].refCount < 0) {
-        ALOGE("refCount is negative for REG %d %d", compileTable[index].regNum, compileTable[index].physicalType);
-        dvmAbort();
+        ALOGE("JIT_ERROR: refCount is negative for REG %d %d at decreaseRefCount",
+                compileTable[index].regNum, compileTable[index].physicalType);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
+        return;
     }
 }
 //! reduce the reference count of a VR by 1
@@ -4384,7 +4602,8 @@ int updateRefCount(int reg, LowOpndRegType type) {
     if(currentBB == NULL) return 0;
     int index = searchCompileTable(LowOpndRegType_virtual | type, reg);
     if(index < 0) {
-        ALOGE("virtual reg %d type %d not found in updateRefCount", reg, type);
+        ALOGE("JIT_ERROR: virtual reg %d type %d not found in updateRefCount\n", reg, type);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return -1;
     }
     decreaseRefCount(index);
@@ -4399,7 +4618,8 @@ int updateRefCount2(int reg, int type, bool isPhysical) {
     if(newType & LowOpndRegType_scratch) reg = reg - PhysicalReg_SCRATCH_1 + 1;
     int index = searchCompileTable(newType, reg);
     if(index < 0) {
-        ALOGE("reg %d type %d not found in updateRefCount", reg, newType);
+        ALOGE("JIT_ERROR: reg %d type %d not found in updateRefCount\n", reg, newType);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return -1;
     }
     decreaseRefCount(index);
@@ -4412,7 +4632,8 @@ bool isGlueHandled(int glue_reg) {
     if(currentBB == NULL) return false;
     int index = searchCompileTable(LowOpndRegType_gp, glue_reg);
     if(index < 0) {
-        ALOGE("glue reg %d not found in isGlueHandled", glue_reg);
+        ALOGE("JIT_ERROR: glue reg %d not found in isGlueHandled\n", glue_reg);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return -1;
     }
     if(compileTable[index].spill_loc_index >= 0 ||
@@ -4427,15 +4648,22 @@ bool isGlueHandled(int glue_reg) {
 #endif
     return false;
 }
-//! reset the state of a glue variable to not existant (not in physical register nor spilled)
 
+//! \brief reset the state of a glue variable to not existent
+//!
+//! \details reset the state of a glue variable to not existent
+//!  (not in physical register nor spilled)
+//! \param reg
 //!
-void resetGlue(int glue_reg) {
-    if(currentBB == NULL) return;
+//! \return -1 if error happened, 0 otherwise
+int resetGlue(int glue_reg) {
+    if(currentBB == NULL)
+        return 0;
     int index = searchCompileTable(LowOpndRegType_gp, glue_reg);
     if(index < 0) {
-        ALOGE("glue reg %d not found in resetGlue", glue_reg);
-        return;
+        ALOGE("JIT_ERROR: glue reg %d not found in resetGlue\n", glue_reg);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
+        return -1;
     }
 #ifdef DEBUG_GLUE
     ALOGI("GLUE reset for %d", glue_reg);
@@ -4444,30 +4672,41 @@ void resetGlue(int glue_reg) {
     if(compileTable[index].spill_loc_index >= 0)
         spillIndexUsed[compileTable[index].spill_loc_index >> 2] = 0;
     compileTable[index].spill_loc_index = -1;
+    return 0;
 }
-//! set a glue variable in a physical register allocated for a variable
 
-//! Variable is using lowering module's naming convention
-void updateGlue(int reg, bool isPhysical, int glue_reg) {
-    if(currentBB == NULL) return;
+//! \brief set a glue variable in a physical register allocated for a variable
+//!
+//! \details Variable is using lowering module's naming convention
+//! \param reg
+//! \param isPhysical whether reg is physical
+//! \param glue_reg
+//!
+//! \return -1 if error happened, 0 otherwise
+int updateGlue(int reg, bool isPhysical, int glue_reg) {
+    if(currentBB == NULL)
+        return 0;
     int index = searchCompileTable(LowOpndRegType_gp, glue_reg);
     if(index < 0) {
-        ALOGE("glue reg %d not found in updateGlue", glue_reg);
-        return;
+        ALOGE("JIT_ERROR: updateGlue reg %d type %d\n", reg, glue_reg);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
+        return -1;
     }
     /* find the compileTable entry for variable <reg, isPhysical> */
     int newType = convertType(LowOpndRegType_gp, reg, isPhysical);
     if(newType & LowOpndRegType_scratch) reg = reg - PhysicalReg_SCRATCH_1 + 1;
     int index2 = searchCompileTable(newType, reg);
     if(index2 < 0 || compileTable[index2].physicalReg == PhysicalReg_Null) {
-        ALOGE("updateGlue reg %d type %d", reg, newType);
-        return;
+        ALOGE("JIT_ERROR: updateGlue reg %d type %d for index2", reg, newType);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
+        return -1;
     }
 #ifdef DEBUG_GLUE
     ALOGI("physical register for GLUE %d set to %d", glue_reg, compileTable[index2].physicalReg);
 #endif
     compileTable[index].physicalReg = compileTable[index2].physicalReg;
     compileTable[index].spill_loc_index = -1;
+    return 0;
 }
 
 //! check whether a virtual register is in a physical register
@@ -4479,7 +4718,8 @@ int checkVirtualReg(int reg, LowOpndRegType type, int updateRefCount) {
     if(currentBB == NULL) return PhysicalReg_Null;
     int index = searchCompileTable(LowOpndRegType_virtual | type, reg);
     if(index < 0) {
-        ALOGE("virtual reg %d type %d not found in checkVirtualReg", reg, type);
+        ALOGE("JIT_ERROR: virtual reg %d type %d not found in checkVirtualReg\n", reg, type);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return PhysicalReg_Null;
     }
     //reduce reference count
@@ -4525,7 +4765,8 @@ bool checkTempReg2(int reg, int type, bool isPhysical, int physicalRegForVR, u2
                 return false;
         }
     }
-    ALOGE("checkTempReg2 %d %d", reg, newType);
+    ALOGE("JIT_ERROR: in checkTempReg2 %d %d\n", reg, newType);
+    SET_JIT_ERROR(kJitErrorRegAllocFailed);
     return false;
 }
 //!check whether a temporary can share the same physical register with a VR
@@ -4538,7 +4779,8 @@ int checkTempReg(int reg, int type, bool isPhysical, int vrNum) {
     if(newType & LowOpndRegType_scratch) reg = reg - PhysicalReg_SCRATCH_1 + 1;
     int index = searchCompileTable(newType, reg);
     if(index < 0) {
-        ALOGE("temp reg %d type %d not found in checkTempReg", reg, newType);
+        ALOGE("JIT_ERROR: temp reg %d type %d not found in checkTempReg\n", reg, newType);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return PhysicalReg_Null;
     }
 
@@ -4662,7 +4904,7 @@ void storeVRExitOfLoop() {
           compileTable[k].gType != GLOBALTYPE_GG &&
           loopIndepUse(k)) {
 #ifdef DEBUG_ENDOFBB
-           LOGI("EXITOFLOOP SPILL VR %d %d\n", compileTable[k].regNum, compileTable[k].physicalType);
+           ALOGI("EXITOFLOOP SPILL VR %d %d\n", compileTable[k].regNum, compileTable[k].physicalType);
 #endif
            spillLogicalReg(k, true);
        }
@@ -4670,10 +4912,14 @@ void storeVRExitOfLoop() {
     syncAllRegs();
 }
 
-//!handles GG VRs at end of a basic block
-
-//!make sure all GG VRs are in pre-defined physical registers
-void globalVREndOfBB(const Method* method) {
+//! \brief handles GG VRs at end of a basic block
+//!
+//! \details make sure all GG VRs are in pre-defined physical registers
+//!
+//! \param method The enclosing method
+//!
+//! \return -1 on error, 0 otherwise
+int globalVREndOfBB(const Method* method) {
     //fix: freeReg first to write LL VR back to memory to avoid it gets overwritten by GG VRs
     freeReg(true);
     int k;
@@ -4708,7 +4954,9 @@ void globalVREndOfBB(const Method* method) {
 #endif
                 compileTable[k].physicalReg = compileTable[k].physicalReg_prev;
                 if(allRegs[compileTable[k].physicalReg_prev].isUsed) {
-                    ALOGE("physical register for GG VR is still used");
+                    ALOGE("JIT_ERROR: Physical register for GG VR is still used\n");
+                    SET_JIT_ERROR(kJitErrorRegAllocFailed);
+                    return -1;
                 }
                 get_virtual_reg_noalloc(compileTable[k].regNum,
                                         getRegSize(compileTable[k].physicalType),
@@ -4721,6 +4969,7 @@ void globalVREndOfBB(const Method* method) {
         compileTable[indexForGlue].physicalReg == PhysicalReg_Null) {
         unspillLogicalReg(indexForGlue, PhysicalReg_EBP); //load %ebp
     }
+    return 0;
 }
 
 //! get ready for the next version of a hard-coded register
@@ -4728,8 +4977,11 @@ void globalVREndOfBB(const Method* method) {
 //!set its physicalReg to Null and update its reference count
 int nextVersionOfHardReg(PhysicalReg pReg, int refCount) {
     int indexT = searchCompileTable(LowOpndRegType_gp | LowOpndRegType_hard, pReg);
-    if(indexT < 0)
+    if(indexT < 0) {
+        ALOGE("JIT_ERROR: Physical reg not found at nextVersionOfHardReg");
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
         return -1;
+    }
     compileTable[indexT].physicalReg = PhysicalReg_Null;
 #ifdef DEBUG_REFCOUNT
     ALOGI("REFCOUNT: to %d in nextVersionOfHardReg %d", refCount, pReg);
@@ -4738,9 +4990,13 @@ int nextVersionOfHardReg(PhysicalReg pReg, int refCount) {
     return 0;
 }
 
-/** update compileTable with bb->infoBasicBlock[k]
-*/
-void insertFromVirtualInfo(BasicBlock_O1* bb, int k) {
+//! \brief update compileTable with bb->infoBasicBlock[k]
+//!
+//! \param bb basic block
+//! \param k index
+//!
+//! \return -1 on error, 0 otherwise
+int insertFromVirtualInfo(BasicBlock_O1* bb, int k) {
     int index = searchCompileTable(LowOpndRegType_virtual | bb->infoBasicBlock[k].physicalType, bb->infoBasicBlock[k].regNum);
     if(index < 0) {
         /* the virtual register is not in compileTable, insert it */
@@ -4754,8 +5010,9 @@ void insertFromVirtualInfo(BasicBlock_O1* bb, int k) {
         compileTable[num_compile_entries].gType = bb->infoBasicBlock[k].gType;
         num_compile_entries++;
         if(num_compile_entries >= COMPILE_TABLE_SIZE) {
-            ALOGE("compileTable overflow");
-            dvmAbort();
+            ALOGE("JIT_ERROR: compileTable overflow at insertFromVirtualInfo");
+            SET_JIT_ERROR(kJitErrorRegAllocFailed);
+            return -1;
         }
     }
     /* re-set reference count of all VRs */
@@ -4763,11 +5020,15 @@ void insertFromVirtualInfo(BasicBlock_O1* bb, int k) {
     compileTable[index].accessType = bb->infoBasicBlock[k].accessType;
     if(compileTable[index].gType == GLOBALTYPE_GG)
         compileTable[index].physicalReg_prev = bb->infoBasicBlock[k].physicalReg_GG;
+    return 0;
 }
 
-/** update compileTable with infoByteCodeTemp[k]
-*/
-void insertFromTempInfo(int k) {
+//! \brief update compileTable with infoByteCodeTemp[k]
+//!
+//! \param k index
+//!
+//! \return -1 on error, 0 otherwise
+int insertFromTempInfo(int k) {
     int index = searchCompileTable(infoByteCodeTemp[k].physicalType, infoByteCodeTemp[k].regNum);
     if(index < 0) {
         /* the temporary is not in compileTable, insert it */
@@ -4776,8 +5037,9 @@ void insertFromTempInfo(int k) {
         compileTable[num_compile_entries].regNum = infoByteCodeTemp[k].regNum;
         num_compile_entries++;
         if(num_compile_entries >= COMPILE_TABLE_SIZE) {
-            ALOGE("compileTable overflow");
-            dvmAbort();
+            ALOGE("JIT_ERROR: compileTable overflow at insertFromTempInfo");
+            SET_JIT_ERROR(kJitErrorRegAllocFailed);
+            return -1;
         }
     }
     compileTable[index].physicalReg = PhysicalReg_Null;
@@ -4785,6 +5047,7 @@ void insertFromTempInfo(int k) {
     compileTable[index].linkageToVR = infoByteCodeTemp[k].linkageToVR;
     compileTable[index].gType = GLOBALTYPE_L;
     compileTable[index].spill_loc_index = -1;
+    return 0;
 }
 
 /* insert a glue-related register GLUE_DVMDEX to compileTable */
@@ -4801,8 +5064,9 @@ void insertGlueReg() {
 
     num_compile_entries++;
     if(num_compile_entries >= COMPILE_TABLE_SIZE) {
-        ALOGE("compileTable overflow");
-        dvmAbort();
+        ALOGE("JIT_ERROR: compileTable overflow at insertGlueReg");
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
+        return;
     }
 }
 
@@ -4821,7 +5085,6 @@ void dumpVirtualInfoOfBasicBlock(BasicBlock_O1* bb) {
                    bb->infoBasicBlock[jj].reachingDefs[k].regNum,
                    bb->infoBasicBlock[jj].reachingDefs[k].physicalType,
                    bb->infoBasicBlock[jj].reachingDefs[k].accessType);
-        ALOGI("");
     }
 }
 
@@ -4854,7 +5117,8 @@ bool isFirstOfHandler(BasicBlock_O1* bb) {
 BasicBlock_O1* createBasicBlock(int src_pc, int end_pc) {
     BasicBlock_O1* bb = (BasicBlock_O1*)malloc(sizeof(BasicBlock_O1));
     if(bb == NULL) {
-        ALOGE("out of memory");
+        ALOGE("JIT_ERROR: Out of memory when trying to alloc basic block for pc %d\n", src_pc);
+        SET_JIT_ERROR(kJitErrorMallocFailed);
         return NULL;
     }
     bb->pc_start = src_pc;
@@ -4879,8 +5143,9 @@ BasicBlock_O1* createBasicBlock(int src_pc, int end_pc) {
     }
     num_bbs_for_method++;
     if(num_bbs_for_method >= MAX_NUM_BBS_PER_METHOD) {
-        ALOGE("too many basic blocks");
-        dvmAbort();
+        ALOGE("JIT_ERROR: Exceeded maximum number of basic blocks\n");
+        SET_JIT_ERROR(kJitErrorTraceFormation);
+        return NULL;
     }
     return bb;
 }
@@ -4911,7 +5176,11 @@ void rememberState(int stateNum) {
             stateTable1_4[k].physicalReg = compileTable[k].physicalReg;
             stateTable1_4[k].spill_loc_index = compileTable[k].spill_loc_index;
         }
-        else ALOGE("state table overflow");
+        else {
+            ALOGE("JIT_ERROR: state table overflow at rememberState for compileTable");
+            SET_JIT_ERROR(kJitErrorRegAllocFailed);
+            return;
+        }
 #ifdef DEBUG_STATE
         ALOGI("logical reg %d %d mapped to physical reg %d with spill index %d refCount %d",
                compileTable[k].regNum, compileTable[k].physicalType, compileTable[k].physicalReg,
@@ -4935,7 +5204,11 @@ void rememberState(int stateNum) {
             stateTable2_4[k].regNum = memVRTable[k].regNum;
             stateTable2_4[k].inMemory = memVRTable[k].inMemory;
         }
-        else ALOGE("state table overflow");
+        else {
+            ALOGE("JIT_ERROR: state table overflow at goToState for compileTable\n");
+            SET_JIT_ERROR(kJitErrorRegAllocFailed);
+            return;
+        }
 #ifdef DEBUG_STATE
         ALOGI("virtual reg %d in memory %d", memVRTable[k].regNum, memVRTable[k].inMemory);
 #endif
@@ -4967,9 +5240,15 @@ void goToState(int stateNum) {
             compileTable[k].physicalReg = stateTable1_4[k].physicalReg;
             compileTable[k].spill_loc_index = stateTable1_4[k].spill_loc_index;
         }
-        else ALOGE("state table overflow");
+        else {
+            ALOGE("JIT_ERROR: State table overflow at goToState");
+            SET_JIT_ERROR(kJitErrorStateTransfer);
+            return;
+        }
     }
-    updateSpillIndexUsed();
+    int retCode = updateSpillIndexUsed();
+    if (retCode < 0)
+        return;
     syncAllRegs(); //to sync up allRegs CAN'T call freeReg here
     //since it will change the state!!!
     for(k = 0; k < num_memory_vr; k++) {
@@ -4989,7 +5268,11 @@ void goToState(int stateNum) {
             memVRTable[k].regNum = stateTable2_4[k].regNum;
             memVRTable[k].inMemory = stateTable2_4[k].inMemory;
         }
-        else ALOGE("state table overflow");
+        else {
+            ALOGE("JIT_ERROR: state table overflow at goToState for memVRTable\n");
+            SET_JIT_ERROR(kJitErrorRegAllocFailed);
+            return;
+        }
     }
 }
 typedef struct TransferOrder {
@@ -5013,27 +5296,35 @@ SourceReg srcRegs[MAX_NUM_DEST];
 bool handledSrc[MAX_NUM_DEST];
 //! in what order should the source registers be handled
 int handledOrder[MAX_NUM_DEST];
-//! insert a source register with a single destination
 
+//! \brief insert a source register with a single destination
+//!
+//! \param srcPhysical
+//! \param targetReg
+//! \param targetSpill
+//! \param index
 //!
-void insertSrcReg(int srcPhysical, int targetReg, int targetSpill, int index) {
+//! \return -1 on error, 0 otherwise
+int insertSrcReg(int srcPhysical, int targetReg, int targetSpill, int index) {
     int k = 0;
     for(k = 0; k < num_src_regs; k++) {
         if(srcRegs[k].physicalReg == srcPhysical) { //increase num_dests
             if(srcRegs[k].num_dests >= MAX_NUM_DEST) {
-                ALOGE("exceed number dst regs for a source reg");
-                dvmAbort();
+                ALOGE("JIT_ERROR: Exceed number dst regs for a source reg\n");
+                SET_JIT_ERROR(kJitErrorMaxDestRegPerSource);
+                return -1;
             }
             srcRegs[k].dsts[srcRegs[k].num_dests].targetReg = targetReg;
             srcRegs[k].dsts[srcRegs[k].num_dests].targetSpill = targetSpill;
             srcRegs[k].dsts[srcRegs[k].num_dests].compileIndex = index;
             srcRegs[k].num_dests++;
-            return;
+            return 0;
         }
     }
     if(num_src_regs >= MAX_NUM_DEST) {
-        ALOGE("exceed number of source regs");
-        dvmAbort();
+        ALOGE("JIT_ERROR: Exceed number of source regs\n");
+        SET_JIT_ERROR(kJitErrorMaxDestRegPerSource);
+        return -1;
     }
     srcRegs[num_src_regs].physicalReg = srcPhysical;
     srcRegs[num_src_regs].num_dests = 1;
@@ -5041,7 +5332,9 @@ void insertSrcReg(int srcPhysical, int targetReg, int targetSpill, int index) {
     srcRegs[num_src_regs].dsts[0].targetSpill = targetSpill;
     srcRegs[num_src_regs].dsts[0].compileIndex = index;
     num_src_regs++;
+    return 0;
 }
+
 //! check whether a register is a source and the source is not yet handled
 
 //!
@@ -5160,7 +5453,8 @@ void constructSrcRegs(int stateNum) {
             if(compileTable[k].physicalReg == PhysicalReg_Null && targetReg != PhysicalReg_Null) {
                 /* handles VR for case I:
                    insert a xfer order from PhysicalReg_Null to targetReg */
-                insertSrcReg(PhysicalReg_Null, targetReg, targetSpill, k);
+                 if (insertSrcReg(PhysicalReg_Null, targetReg, targetSpill, k) == -1)
+                     return;
 #ifdef DEBUG_STATE
                 ALOGI("insert for VR Null %d %d %d", targetReg, targetSpill, k);
 #endif
@@ -5169,13 +5463,15 @@ void constructSrcRegs(int stateNum) {
             if(compileTable[k].physicalReg != PhysicalReg_Null && targetReg != PhysicalReg_Null) {
                 /* handles VR for case III
                    insert a xfer order from srcReg to targetReg */
-                insertSrcReg(compileTable[k].physicalReg, targetReg, targetSpill, k);
+                if (insertSrcReg(compileTable[k].physicalReg, targetReg, targetSpill, k) == -1)
+                    return;
             }
 
             if(compileTable[k].physicalReg != PhysicalReg_Null && targetReg == PhysicalReg_Null) {
                 /* handles VR for case II
                    insert a xfer order from srcReg to memory */
-                insertSrcReg(compileTable[k].physicalReg, targetReg, targetSpill, k);
+                if (insertSrcReg(compileTable[k].physicalReg, targetReg, targetSpill, k) == -1)
+                    return;
             }
         }
 
@@ -5195,14 +5491,16 @@ void constructSrcRegs(int stateNum) {
 #ifdef DEBUG_STATE
                     ALOGI("insert Null %d %d %d", targetReg, targetSpill, k);
 #endif
-                    insertSrcReg(PhysicalReg_Null, targetReg, targetSpill, k);
+                    if (insertSrcReg(PhysicalReg_Null, targetReg, targetSpill, k) == -1)
+                        return;
                 }
             }
 
             if(compileTable[k].physicalReg != PhysicalReg_Null && targetReg != PhysicalReg_Null) {
                 /* handles non-VR for case III
                    insert a xfer order from srcReg to targetReg */
-                insertSrcReg(compileTable[k].physicalReg, targetReg, targetSpill, k);
+                if (insertSrcReg(compileTable[k].physicalReg, targetReg, targetSpill, k) == -1)
+                    return;
             }
 
             if(compileTable[k].physicalReg != PhysicalReg_Null && targetReg == PhysicalReg_Null) {
@@ -5214,7 +5512,8 @@ void constructSrcRegs(int stateNum) {
 #endif
                 } else {
                     /* insert a xfer order from srcReg to memory */
-                    insertSrcReg(compileTable[k].physicalReg, targetReg, targetSpill, k);
+                    if (insertSrcReg(compileTable[k].physicalReg, targetReg, targetSpill, k) == -1)
+                        return;
                 }
             }
 
@@ -5266,8 +5565,9 @@ void constructSrcRegs(int stateNum) {
             }
         } //for k
         if(num_handled == prev_handled) {
-            ALOGE("no progress in selecting order");
-            dvmAbort();
+            ALOGE("JIT_ERROR: No progress in selecting order while in constructSrcReg");
+            SET_JIT_ERROR(kJitErrorStateTransfer);
+            return;
         }
     } //while
     for(k = 0; k < num_src_regs; k++) {
@@ -5277,15 +5577,15 @@ void constructSrcRegs(int stateNum) {
         }
     }
     if(num_in_order != num_src_regs) {
-        ALOGE("num_in_order != num_src_regs");
-        dvmAbort();
+        ALOGE("JIT_ERROR: num_in_order != num_src_regs while in constructSrcReg");
+        SET_JIT_ERROR(kJitErrorStateTransfer);
+        return;
     }
 #ifdef DEBUG_STATE
     ALOGI("ORDER: ");
     for(k = 0; k < num_src_regs; k++) {
         ALOGI("%d ", handledOrder[k]);
     }
-    ALOGI("");
 #endif
 }
 //! transfer the state of register allocator to a state specified in a state table
@@ -5297,7 +5597,11 @@ void transferToState(int stateNum) {
 #ifdef DEBUG_STATE
     ALOGI("STATE: transfer to state %d", stateNum);
 #endif
-    if(stateNum > 4 || stateNum < 1) ALOGE("state table overflow");
+    if(stateNum > 4 || stateNum < 1) {
+        ALOGE("JIT_ERROR: State table overflow at transferToState");
+        SET_JIT_ERROR(kJitErrorStateTransfer);
+        return;
+    }
     constructSrcRegs(stateNum);
     int k4, k3;
     for(k4 = 0; k4 < num_src_regs; k4++) {
@@ -5368,8 +5672,11 @@ void transferToState(int stateNum) {
             targetReg = stateTable2_4[k].regNum;
             targetBool = stateTable2_4[k].inMemory;
         }
-        if(targetReg != memVRTable[k].regNum)
-            ALOGE("regNum mismatch in transferToState");
+        if(targetReg != memVRTable[k].regNum) {
+            ALOGE("JIT_ERROR: regNum mismatch in transferToState");
+            SET_JIT_ERROR(kJitErrorStateTransfer);
+            return;
+        }
         if(targetBool && (!memVRTable[k].inMemory)) {
             //dump to memory, check entries in compileTable: vA gp vA xmm vA ss
 #ifdef DEBUG_STATE
diff --git a/vm/compiler/codegen/x86/AnalysisO1.h b/vm/compiler/codegen/x86/AnalysisO1.h
index c40067c..f1cd80d 100644
--- a/vm/compiler/codegen/x86/AnalysisO1.h
+++ b/vm/compiler/codegen/x86/AnalysisO1.h
@@ -363,13 +363,12 @@ typedef enum GlueVarType {
 void forwardAnalysis(int type);
 
 //functions in bc_visitor.c
-//int getByteCodeSize();
-bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR);
+int getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR);
 int getVirtualRegInfo(VirtualRegInfo* infoArray, const MIR * currentMIR);
 int getTempRegInfo(TempRegInfo* infoArray, const MIR * currentMIR);
 int createCFGHandler(Method* method);
 
-int findVirtualRegInTable(u2 vA, LowOpndRegType type, bool printError);
+int findVirtualRegInTable(u2 vA, LowOpndRegType type);
 int searchCompileTable(int type, int regNum);
 BasicBlock_O1* createBasicBlock(int src_pc, int end_pc);
 void handleJump(BasicBlock_O1* bb_prev, int relOff);
diff --git a/vm/compiler/codegen/x86/BytecodeVisitor.cpp b/vm/compiler/codegen/x86/BytecodeVisitor.cpp
index 853fefb..9db5cb3 100644
--- a/vm/compiler/codegen/x86/BytecodeVisitor.cpp
+++ b/vm/compiler/codegen/x86/BytecodeVisitor.cpp
@@ -412,8 +412,9 @@ int getByteCodeSize() { //uses inst, unit in u2
     }
 #endif
     default:
-        ALOGE("ERROR: JIT does not support getting size of bytecode 0x%hx\n",
+        ALOGE("JIT_ERROR: JIT does not support getting size of bytecode 0x%hx\n",
                 currentMIR->dalvikInsn.opcode);
+        SET_JIT_ERROR(kJitErrorUnsupportedBytecode);
         assert(false && "All opcodes should be supported.");
         break;
     }
@@ -421,33 +422,46 @@ int getByteCodeSize() { //uses inst, unit in u2
 }
 #endif
 
-//! reduces refCount of a virtual register
-
+//! \brief reduces refCount of a virtual register
+//!
+//! \param vA
+//! \param type
 //!
-void touchOneVR(u2 vA, LowOpndRegType type) {
+//! \return -1 on error, 0 otherwise
+static int touchOneVR(u2 vA, LowOpndRegType type) {
     int index = searchCompileTable(LowOpndRegType_virtual | type, vA);
     if(index < 0) {
-        ALOGE("virtual reg %d type %d not found in touchOneVR", vA, type);
-        return;
+        ALOGE("JIT_ERROR: virtual reg %d type %d not found in touchOneVR\n", vA, type);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
+        return -1;
     }
     compileTable[index].refCount--;
+    return 0;
 }
-//! reduces refCount of two virtual registers
 
+//! \brief reduces refCount of two virtual registers
 //!
-void touchTwoVRs(u2 vA, u2 vB, LowOpndRegType type) {
+//! \param vA
+//! \param vB
+//! \param type
+//!
+//! \return -1 if error, 0 otherwise
+static int touchTwoVRs(u2 vA, u2 vB, LowOpndRegType type) {
     int index = searchCompileTable(LowOpndRegType_virtual | type, vA);
     if(index < 0) {
-        ALOGE("virtual reg vA %d type %d not found in touchTwoVRs", vA, type);
-        return;
+        ALOGE("JIT_ERROR: virtual reg %d type %d not found in touchTwoVRs\n", vA, type);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
+        return -1;
     }
     compileTable[index].refCount--;
     index = searchCompileTable(LowOpndRegType_virtual | type, vB);
     if(index < 0) {
-        ALOGE("virtual reg vB %d type %d not found in touchTwoVRs", vB, type);
-        return;
+        ALOGE("JIT_ERROR: virtual reg %d type %d not found in touchTwoVRs\n", vB, type);
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
+        return -1;
     }
     compileTable[index].refCount--;
+    return 0;
 }
 int num_const_worklist;
 //! worklist to update constVRTable later
@@ -514,7 +528,11 @@ void setVRToConst(int regNum, OpndSize size, int* tmpValue) {
         constVRTable[indexH].isConst = true;
         constVRTable[indexH].value = tmpValue[1];
     }
-    if(num_const_vr > MAX_CONST_REG) ALOGE("constVRTable overflows");
+    if(num_const_vr > MAX_CONST_REG) {
+        ALOGE("JIT_ERROR: constVRTable overflows at setVRToConst");
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
+        return;
+    }
     invalidateVRDueToConst(regNum, size);
 }
 
@@ -532,11 +550,21 @@ void updateConstInfo(BasicBlock_O1* bb) {
         setVRToNonConst(constWorklist[k], OpndSize_32);
     }
 }
-//! check whether the current bytecode generates a const
 
-//! if yes, update constVRTable; otherwise, update constWorklist
-//! if a bytecode uses vA (const), and updates vA to non const, getConstInfo will return false and update constWorklist to make sure when lowering the bytecode, vA is treated as constant
-bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
+//! \brief check whether the current bytecode generates a const
+//!
+//! \details if yes, update constVRTable; otherwise, update constWorklist
+//! if a bytecode uses vA (const), and updates vA to non const, getConstInfo
+//! will return 0 and update constWorklist to make sure when lowering the
+//! bytecode, vA is treated as constant
+//!
+//! \param bb the BasicBlock_O1 to analyze
+//! \param currentMIR
+//!
+//! \return 1 if the bytecode generates a const, 0 otherwise, and -1 if an
+//! error occured.
+int getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
+    int retCode = 0;
     compileTableEntry* infoArray = compileTable;
     Opcode inst_op = currentMIR->dalvikInsn.opcode;
     u2 vA = 0, vB = 0, v1, v2;
@@ -551,7 +579,7 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
     /* A bytecode with the MIR_INLINED op will be treated as
      * no-op during codegen */
     if (currentMIR->OptimizationFlags & MIR_INLINED)
-        return false; // does NOT generate a constant
+        return 0; // does NOT generate a constant
 #endif
 
     switch(inst_op) {
@@ -565,36 +593,44 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
         vA = currentMIR->dalvikInsn.vA;
         vB = currentMIR->dalvikInsn.vB;
         if(isVirtualRegConstant(vB, LowOpndRegType_gp, tmpValue, false) == 3) {
-            entry = findVirtualRegInTable(vA, LowOpndRegType_gp, true);
+            entry = findVirtualRegInTable(vA, LowOpndRegType_gp);
+            if (entry < 0)
+                return -1;
             setVRToConst(vA, OpndSize_32, tmpValue);
             infoArray[entry].isConst = true;
             infoArray[entry].value[0] = tmpValue[0];
             compileTable[entry].refCount--;
-            touchOneVR(vB, LowOpndRegType_gp);
-            return true;
+            retCode = touchOneVR(vB, LowOpndRegType_gp);
+            if (retCode < 0)
+                return retCode;
+            return 1;
         } else {
             constWorklist[num_const_worklist] = vA;
             num_const_worklist++;
         }
-        return false;
+        return 0;
     case OP_MOVE_WIDE:
     case OP_MOVE_WIDE_FROM16:
     case OP_MOVE_WIDE_16:
         vA = currentMIR->dalvikInsn.vA;
         vB = currentMIR->dalvikInsn.vB;
         if(isVirtualRegConstant(vB, LowOpndRegType_xmm, tmpValue, false) == 3) {
-            entry = findVirtualRegInTable(vA, LowOpndRegType_xmm, true);
+            entry = findVirtualRegInTable(vA, LowOpndRegType_xmm);
+            if (entry < 0)
+                return -1;
             setVRToConst(vA, OpndSize_64, tmpValue);
             compileTable[entry].refCount--;
-            touchOneVR(vB, LowOpndRegType_xmm);
-            return true;
+            retCode = touchOneVR(vB, LowOpndRegType_xmm);
+            if (retCode < 0)
+                return retCode;
+            return 1;
         } else {
             constWorklist[num_const_worklist] = vA;
             num_const_worklist++;
             constWorklist[num_const_worklist] = vA+1;
             num_const_worklist++;
         }
-        return false;
+        return 0;
     case OP_MOVE_RESULT:
     case OP_MOVE_RESULT_OBJECT:
     case OP_MOVE_EXCEPTION:
@@ -623,7 +659,7 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
         vA = currentMIR->dalvikInsn.vA;
         constWorklist[num_const_worklist] = vA;
         num_const_worklist++;
-        return false;
+        return 0;
     case OP_MOVE_RESULT_WIDE:
     case OP_AGET_WIDE:
     case OP_SGET_WIDE:
@@ -633,7 +669,7 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
         num_const_worklist++;
         constWorklist[num_const_worklist] = vA+1;
         num_const_worklist++;
-        return false;
+        return 0;
     case OP_INSTANCE_OF:
     case OP_ARRAY_LENGTH:
     case OP_NEW_ARRAY:
@@ -650,7 +686,7 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
         vA = currentMIR->dalvikInsn.vA;
         constWorklist[num_const_worklist] = vA;
         num_const_worklist++;
-        return false;
+        return 0;
     case OP_IGET_WIDE:
     case OP_IGET_WIDE_VOLATILE:
     case OP_IGET_WIDE_QUICK:
@@ -659,7 +695,7 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
         num_const_worklist++;
         constWorklist[num_const_worklist] = vA+1;
         num_const_worklist++;
-        return false;
+        return 0;
         //TODO: constant folding for float/double/long ALU
     case OP_ADD_FLOAT:
     case OP_SUB_FLOAT:
@@ -669,7 +705,7 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
         vA = currentMIR->dalvikInsn.vA;
         constWorklist[num_const_worklist] = vA;
         num_const_worklist++;
-        return false;
+        return 0;
     case OP_ADD_DOUBLE:
     case OP_SUB_DOUBLE:
     case OP_MUL_DOUBLE:
@@ -680,7 +716,7 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
         num_const_worklist++;
         constWorklist[num_const_worklist] = vA+1;
         num_const_worklist++;
-        return false;
+        return 0;
     case OP_NEG_FLOAT:
     case OP_INT_TO_FLOAT:
     case OP_LONG_TO_FLOAT:
@@ -695,7 +731,7 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
         vA = currentMIR->dalvikInsn.vA;
         constWorklist[num_const_worklist] = vA; //change constWorklist to point to vA TODO
         num_const_worklist++;
-        return false;
+        return 0;
     case OP_FLOAT_TO_LONG:
     case OP_DOUBLE_TO_LONG:
     case OP_FLOAT_TO_DOUBLE:
@@ -704,7 +740,7 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
         num_const_worklist++;
         constWorklist[num_const_worklist] = vA+1;
         num_const_worklist++;
-        return false;
+        return 0;
     case OP_NEG_DOUBLE:
     case OP_INT_TO_DOUBLE: //fp stack
     case OP_LONG_TO_DOUBLE:
@@ -719,7 +755,7 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
         num_const_worklist++;
         constWorklist[num_const_worklist] = vA+1;
         num_const_worklist++;
-        return false;
+        return 0;
     case OP_NEG_INT:
     case OP_NOT_INT:
     case OP_LONG_TO_INT:
@@ -729,7 +765,9 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
         vA = currentMIR->dalvikInsn.vA;
         vB = currentMIR->dalvikInsn.vB;
         if(isVirtualRegConstant(vB, LowOpndRegType_gp, tmpValue, false) == 3) {
-            entry = findVirtualRegInTable(vA, LowOpndRegType_gp, true);
+            entry = findVirtualRegInTable(vA, LowOpndRegType_gp);
+            if (entry < 0)
+                return -1;
             infoArray[entry].isConst = true;
             if(inst_op == OP_NEG_INT)
                 infoArray[entry].value[0] = -tmpValue[0];
@@ -746,16 +784,18 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
             tmpValue[0] = infoArray[entry].value[0];
             setVRToConst(vA, OpndSize_32, tmpValue);
             compileTable[entry].refCount--;
-            touchOneVR(vB, LowOpndRegType_gp);
+            retCode = touchOneVR(vB, LowOpndRegType_gp);
+            if (retCode < 0)
+                return retCode;
 #ifdef DEBUG_CONST
-            LOGD("getConstInfo: set VR %d to %d", vA, infoArray[entry].value[0]);
+            ALOGD("getConstInfo: set VR %d to %d", vA, infoArray[entry].value[0]);
 #endif
-            return true;
+            return 1;
         }
         else {
             constWorklist[num_const_worklist] = vA;
             num_const_worklist++;
-            return false;
+            return 0;
         }
     case OP_NEG_LONG:
     case OP_NOT_LONG:
@@ -765,7 +805,7 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
         num_const_worklist++;
         constWorklist[num_const_worklist] = vA+1; //fixed on 10/15/2009
         num_const_worklist++;
-        return false;
+        return 0;
     case OP_DIV_INT_2ADDR:
     case OP_REM_INT_2ADDR:
     case OP_REM_INT_LIT16:
@@ -777,7 +817,7 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
         vA = currentMIR->dalvikInsn.vA;
         constWorklist[num_const_worklist] = vA;
         num_const_worklist++;
-        return false;
+        return 0;
     case OP_ADD_INT_2ADDR:
     case OP_SUB_INT_2ADDR:
     case OP_MUL_INT_2ADDR:
@@ -791,7 +831,9 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
         v2 = currentMIR->dalvikInsn.vB;
         if(isVirtualRegConstant(vA, LowOpndRegType_gp, tmpValue, false) == 3 &&
            isVirtualRegConstant(v2, LowOpndRegType_gp, tmpValue2, false) == 3) {
-            entry = findVirtualRegInTable(vA, LowOpndRegType_gp, true);
+            entry = findVirtualRegInTable(vA, LowOpndRegType_gp);
+            if (entry < 0)
+                return -1;
             infoArray[entry].isConst = true;
             if(inst_op == OP_ADD_INT_2ADDR)
                 infoArray[entry].value[0] = tmpValue[0] + tmpValue2[0];
@@ -818,16 +860,18 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
             tmpValue[0] = infoArray[entry].value[0];
             setVRToConst(vA, OpndSize_32, tmpValue);
             compileTable[entry].refCount--;
-            touchOneVR(v2, LowOpndRegType_gp);
+            retCode = touchOneVR(v2, LowOpndRegType_gp);
+            if (retCode < 0)
+                return retCode;
 #ifdef DEBUG_CONST
-            LOGD("getConstInfo: set VR %d to %d", vA, infoArray[entry].value[0]);
+            ALOGD("getConstInfo: set VR %d to %d", vA, infoArray[entry].value[0]);
 #endif
-            return true;
+            return 1;
         }
         else {
             constWorklist[num_const_worklist] = vA;
             num_const_worklist++;
-            return false;
+            return 0;
         }
     case OP_ADD_INT_LIT16:
     case OP_RSUB_INT:
@@ -839,7 +883,9 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
         vB = currentMIR->dalvikInsn.vB;
         tmp_s4 = currentMIR->dalvikInsn.vC;
         if(isVirtualRegConstant(vB, LowOpndRegType_gp, tmpValue, false) == 3) {
-            entry = findVirtualRegInTable(vA, LowOpndRegType_gp, true);
+            entry = findVirtualRegInTable(vA, LowOpndRegType_gp);
+            if (entry < 0)
+                return -1;
             infoArray[entry].isConst = true;
             if(inst_op == OP_ADD_INT_LIT16)
                 infoArray[entry].value[0] = tmpValue[0] + tmp_s4;
@@ -860,16 +906,18 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
             tmpValue[0] = infoArray[entry].value[0];
             setVRToConst(vA, OpndSize_32, tmpValue);
             compileTable[entry].refCount--;
-            touchOneVR(vB, LowOpndRegType_gp);
+            retCode = touchOneVR(vB, LowOpndRegType_gp);
+            if (retCode < 0)
+                return retCode;
 #ifdef DEBUG_CONST
-            LOGD("getConstInfo: set VR %d to %d", vA, infoArray[entry].value[0]);
+            ALOGD("getConstInfo: set VR %d to %d", vA, infoArray[entry].value[0]);
 #endif
-            return true;
+            return 1;
         }
         else {
             constWorklist[num_const_worklist] = vA;
             num_const_worklist++;
-            return false;
+            return 0;
         }
     case OP_ADD_INT:
     case OP_SUB_INT:
@@ -885,7 +933,9 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
         v2 = currentMIR->dalvikInsn.vC;
         if(isVirtualRegConstant(v1, LowOpndRegType_gp, tmpValue, false) == 3 &&
            isVirtualRegConstant(v2, LowOpndRegType_gp, tmpValue2, false) == 3) {
-            entry = findVirtualRegInTable(vA, LowOpndRegType_gp, true);
+            entry = findVirtualRegInTable(vA, LowOpndRegType_gp);
+            if (entry < 0)
+                return -1;
             infoArray[entry].isConst = true;
             if(inst_op == OP_ADD_INT)
                 infoArray[entry].value[0] = tmpValue[0] + tmpValue2[0];
@@ -912,17 +962,21 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
             tmpValue[0] = infoArray[entry].value[0];
             setVRToConst(vA, OpndSize_32, tmpValue);
             compileTable[entry].refCount--;
-            touchOneVR(v1, LowOpndRegType_gp);
-            touchOneVR(v2, LowOpndRegType_gp);
+            retCode = touchOneVR(v1, LowOpndRegType_gp);
+            if (retCode < 0)
+                return retCode;
+            retCode = touchOneVR(v2, LowOpndRegType_gp);
+            if (retCode < 0)
+                return retCode;
 #ifdef DEBUG_CONST
-            LOGD("getConstInfo: set VR %d to %d", vA, infoArray[entry].value[0]);
+            ALOGD("getConstInfo: set VR %d to %d", vA, infoArray[entry].value[0]);
 #endif
-            return true;
+            return 1;
         }
         else {
             constWorklist[num_const_worklist] = vA;
             num_const_worklist++;
-            return false;
+            return 0;
         }
     case OP_ADD_INT_LIT8: //INST_AA
     case OP_RSUB_INT_LIT8:
@@ -937,7 +991,9 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
         vB = currentMIR->dalvikInsn.vB;
         tmp_s4 = currentMIR->dalvikInsn.vC;
         if(isVirtualRegConstant(vB, LowOpndRegType_gp, tmpValue, false) == 3) {
-            entry = findVirtualRegInTable(vA, LowOpndRegType_gp, true);
+            entry = findVirtualRegInTable(vA, LowOpndRegType_gp);
+            if (entry < 0)
+                return -1;
             infoArray[entry].isConst = true;
             if(inst_op == OP_ADD_INT_LIT8)
                 infoArray[entry].value[0] = tmpValue[0] + tmp_s4;
@@ -964,16 +1020,18 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
             tmpValue[0] = infoArray[entry].value[0];
             setVRToConst(vA, OpndSize_32, tmpValue);
             compileTable[entry].refCount--;
-            touchOneVR(vB, LowOpndRegType_gp);
+            retCode = touchOneVR(vB, LowOpndRegType_gp);
+            if (retCode < 0)
+                return retCode;
 #ifdef DEBUG_CONST
-            LOGD("getConstInfo: set VR %d to %d", vA, infoArray[entry].value[0]);
+            ALOGD("getConstInfo: set VR %d to %d", vA, infoArray[entry].value[0]);
 #endif
-            return true;
+            return 1;
         }
         else {
             constWorklist[num_const_worklist] = vA;
             num_const_worklist++;
-            return false;
+            return 0;
         }
     case OP_ADD_LONG:
     case OP_SUB_LONG:
@@ -993,12 +1051,12 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
         num_const_worklist++;
         constWorklist[num_const_worklist] = vA+1;
         num_const_worklist++;
-        return false;
+        return 0;
     case OP_CMP_LONG:
         vA = currentMIR->dalvikInsn.vA;
         constWorklist[num_const_worklist] = vA;
         num_const_worklist++;
-        return false;
+        return 0;
     case OP_ADD_LONG_2ADDR:
     case OP_SUB_LONG_2ADDR:
     case OP_AND_LONG_2ADDR:
@@ -1015,148 +1073,172 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
         num_const_worklist++;
         constWorklist[num_const_worklist] = vA+1;
         num_const_worklist++;
-        return false;
+        return 0;
     case OP_CONST_4:
         vA = currentMIR->dalvikInsn.vA;
         tmp_s4 = currentMIR->dalvikInsn.vB;
-        entry = findVirtualRegInTable(vA, LowOpndRegType_gp, true);
+        entry = findVirtualRegInTable(vA, LowOpndRegType_gp);
+        if (entry < 0)
+            return -1;
         infoArray[entry].isConst = true;
         infoArray[entry].value[0] = tmp_s4;
         tmpValue[0] = infoArray[entry].value[0];
         setVRToConst(vA, OpndSize_32, tmpValue);
         compileTable[entry].refCount--;
 #ifdef DEBUG_CONST
-        LOGD("getConstInfo: set VR %d to %d", vA, tmp_s4);
+        ALOGD("getConstInfo: set VR %d to %d", vA, tmp_s4);
 #endif
-        return true;
+        return 1;
     case OP_CONST_16:
         BBBB = currentMIR->dalvikInsn.vB;
         vA = currentMIR->dalvikInsn.vA;
-        entry = findVirtualRegInTable(vA, LowOpndRegType_gp, true);
+        entry = findVirtualRegInTable(vA, LowOpndRegType_gp);
+        if (entry < 0)
+            return -1;
         infoArray[entry].isConst = true;
         infoArray[entry].value[0] = (s2)BBBB;
         tmpValue[0] = infoArray[entry].value[0];
         setVRToConst(vA, OpndSize_32, tmpValue);
         compileTable[entry].refCount--;
 #ifdef DEBUG_CONST
-        LOGD("getConstInfo: set VR %d to %d", vA, infoArray[entry].value[0]);
+        ALOGD("getConstInfo: set VR %d to %d", vA, infoArray[entry].value[0]);
 #endif
-        return true;
+        return 1;
     case OP_CONST:
         vA = currentMIR->dalvikInsn.vA;
         tmp_u4 = currentMIR->dalvikInsn.vB;
-        entry = findVirtualRegInTable(vA, LowOpndRegType_gp, true);
+        entry = findVirtualRegInTable(vA, LowOpndRegType_gp);
+        if (entry < 0)
+            return -1;
         infoArray[entry].isConst = true;
         infoArray[entry].value[0] = (s4)tmp_u4;
         tmpValue[0] = infoArray[entry].value[0];
         setVRToConst(vA, OpndSize_32, tmpValue);
         compileTable[entry].refCount--;
 #ifdef DEBUG_CONST
-        LOGD("getConstInfo: set VR %d to %d", vA, infoArray[entry].value[0]);
+        ALOGD("getConstInfo: set VR %d to %d", vA, infoArray[entry].value[0]);
 #endif
-        return true;
+        return 1;
     case OP_CONST_HIGH16:
         vA = currentMIR->dalvikInsn.vA;
         tmp_u2 = currentMIR->dalvikInsn.vB;
-        entry = findVirtualRegInTable(vA, LowOpndRegType_gp, true);
+        entry = findVirtualRegInTable(vA, LowOpndRegType_gp);
+        if (entry < 0)
+            return -1;
         infoArray[entry].isConst = true;
         infoArray[entry].value[0] = ((s4)tmp_u2)<<16;
         tmpValue[0] = infoArray[entry].value[0];
         setVRToConst(vA, OpndSize_32, tmpValue);
         compileTable[entry].refCount--;
 #ifdef DEBUG_CONST
-        LOGD("getConstInfo: set VR %d to %d", vA, infoArray[entry].value[0]);
+        ALOGD("getConstInfo: set VR %d to %d", vA, infoArray[entry].value[0]);
 #endif
-        return true;
+        return 1;
     case OP_CONST_WIDE_16:
         vA = currentMIR->dalvikInsn.vA;
         tmp_u2 = currentMIR->dalvikInsn.vB;
-        entry = findVirtualRegInTable(vA, LowOpndRegType_gp, true);
+        entry = findVirtualRegInTable(vA, LowOpndRegType_gp);
+        if (entry < 0)
+            return -1;
         infoArray[entry].isConst = true;
         infoArray[entry].value[0] = (s2)tmp_u2;
         tmpValue[0] = infoArray[entry].value[0];
         compileTable[entry].refCount--;
 #ifdef DEBUG_CONST
-        LOGD("getConstInfo: set VR %d to %x", vA, infoArray[entry].value[0]);
+        ALOGD("getConstInfo: set VR %d to %x", vA, infoArray[entry].value[0]);
 #endif
 
-        entry = findVirtualRegInTable(vA+1, LowOpndRegType_gp, true);
+        entry = findVirtualRegInTable(vA+1, LowOpndRegType_gp);
+        if (entry < 0)
+            return -1;
         infoArray[entry].isConst = true;
         infoArray[entry].value[0] = ((s2)tmp_u2)>>31;
         tmpValue[1] = infoArray[entry].value[0];
         setVRToConst(vA, OpndSize_64, tmpValue);
         compileTable[entry].refCount--;
 #ifdef DEBUG_CONST
-        LOGD("getConstInfo: set VR %d to %x", vA+1, infoArray[entry].value[0]);
+        ALOGD("getConstInfo: set VR %d to %x", vA+1, infoArray[entry].value[0]);
 #endif
-        return true;
+        return 1;
     case OP_CONST_WIDE_32:
         vA = currentMIR->dalvikInsn.vA;
         tmp_u4 = currentMIR->dalvikInsn.vB;
-        entry = findVirtualRegInTable(vA, LowOpndRegType_gp, true);
+        entry = findVirtualRegInTable(vA, LowOpndRegType_gp);
+        if (entry < 0)
+            return -1;
         infoArray[entry].isConst = true;
         infoArray[entry].value[0] = (s4)tmp_u4;
         tmpValue[0] = infoArray[entry].value[0];
         compileTable[entry].refCount--;
 #ifdef DEBUG_CONST
-        LOGD("getConstInfo: set VR %d to %x", vA, infoArray[entry].value[0]);
+        ALOGD("getConstInfo: set VR %d to %x", vA, infoArray[entry].value[0]);
 #endif
 
-        entry = findVirtualRegInTable(vA+1, LowOpndRegType_gp, true);
+        entry = findVirtualRegInTable(vA+1, LowOpndRegType_gp);
+        if (entry < 0)
+            return -1;
         infoArray[entry].isConst = true;
         infoArray[entry].value[0] = ((s4)tmp_u4)>>31;
         tmpValue[1] = infoArray[entry].value[0];
         setVRToConst(vA, OpndSize_64, tmpValue);
         compileTable[entry].refCount--;
 #ifdef DEBUG_CONST
-        LOGD("getConstInfo: set VR %d to %x", vA+1, infoArray[entry].value[0]);
+        ALOGD("getConstInfo: set VR %d to %x", vA+1, infoArray[entry].value[0]);
 #endif
-        return true;
+        return 1;
     case OP_CONST_WIDE:
         vA = currentMIR->dalvikInsn.vA;
         tmp_u4 = (s4)currentMIR->dalvikInsn.vB_wide;
-        entry = findVirtualRegInTable(vA, LowOpndRegType_gp, true);
+        entry = findVirtualRegInTable(vA, LowOpndRegType_gp);
+        if (entry < 0)
+            return -1;
         infoArray[entry].isConst = true;
         infoArray[entry].value[0] = (s4)tmp_u4;
         tmpValue[0] = infoArray[entry].value[0];
         compileTable[entry].refCount--;
 #ifdef DEBUG_CONST
-        LOGD("getConstInfo: set VR %d to %x", vA, infoArray[entry].value[0]);
+        ALOGD("getConstInfo: set VR %d to %x", vA, infoArray[entry].value[0]);
 #endif
 
         tmp_u4 = (s4)(currentMIR->dalvikInsn.vB_wide >> 32);
-        entry = findVirtualRegInTable(vA+1, LowOpndRegType_gp, true);
+        entry = findVirtualRegInTable(vA+1, LowOpndRegType_gp);
+        if (entry < 0)
+            return -1;
         infoArray[entry].isConst = true;
         infoArray[entry].value[0] = (s4)tmp_u4;
         tmpValue[1] = infoArray[entry].value[0];
         setVRToConst(vA, OpndSize_64, tmpValue);
         compileTable[entry].refCount--;
 #ifdef DEBUG_CONST
-        LOGD("getConstInfo: set VR %d to %x", vA+1, infoArray[entry].value[0]);
+        ALOGD("getConstInfo: set VR %d to %x", vA+1, infoArray[entry].value[0]);
 #endif
-        return true;
+        return 1;
     case OP_CONST_WIDE_HIGH16:
         vA = currentMIR->dalvikInsn.vA;
         tmp_u2 = currentMIR->dalvikInsn.vB;
-        entry = findVirtualRegInTable(vA, LowOpndRegType_gp, true);
+        entry = findVirtualRegInTable(vA, LowOpndRegType_gp);
+        if (entry < 0)
+            return -1;
         infoArray[entry].isConst = true;
         infoArray[entry].value[0] = 0;
         tmpValue[0] = infoArray[entry].value[0];
         compileTable[entry].refCount--;
 #ifdef DEBUG_CONST
-        LOGD("getConstInfo: set VR %d to %x", vA, infoArray[entry].value[0]);
+        ALOGD("getConstInfo: set VR %d to %x", vA, infoArray[entry].value[0]);
 #endif
 
-        entry = findVirtualRegInTable(vA+1, LowOpndRegType_gp, true);
+        entry = findVirtualRegInTable(vA+1, LowOpndRegType_gp);
+        if (entry < 0)
+            return -1;
         infoArray[entry].isConst = true;
         infoArray[entry].value[0] = ((s4)tmp_u2)<<16;
         tmpValue[1] = infoArray[entry].value[0];
         setVRToConst(vA, OpndSize_64, tmpValue);
         compileTable[entry].refCount--;
 #ifdef DEBUG_CONST
-        LOGD("getConstInfo: set VR %d to %x", vA+1, infoArray[entry].value[0]);
+        ALOGD("getConstInfo: set VR %d to %x", vA+1, infoArray[entry].value[0]);
 #endif
-        return true;
+        return 1;
 #ifdef SUPPORT_HLO
     case OP_X_AGET_QUICK:
     case OP_X_AGET_OBJECT_QUICK:
@@ -1167,14 +1249,14 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
         vA = FETCH(1) & 0xff;
         constWorklist[num_const_worklist] = vA;
         num_const_worklist++;
-        return false;
+        return 0;
     case OP_X_AGET_WIDE_QUICK:
         vA = FETCH(1) & 0xff;
         constWorklist[num_const_worklist] = vA;
         num_const_worklist++;
         constWorklist[num_const_worklist] = vA+1;
         num_const_worklist++;
-        return false;
+        return 0;
     case OP_X_DEREF_GET:
     case OP_X_DEREF_GET_OBJECT:
     case OP_X_DEREF_GET_BOOLEAN:
@@ -1184,20 +1266,20 @@ bool getConstInfo(BasicBlock_O1* bb, const MIR * currentMIR) {
         vA = FETCH(1) & 0xff;
         constWorklist[num_const_worklist] = vA;
         num_const_worklist++;
-        return false;
+        return 0;
     case OP_X_DEREF_GET_WIDE:
         vA = FETCH(1) & 0xff;
         constWorklist[num_const_worklist] = vA;
         num_const_worklist++;
         constWorklist[num_const_worklist] = vA+1;
         num_const_worklist++;
-        return false;
+        return 0;
 #endif
     default:
         // Bytecode does not generate a const
         break;
     }
-    return false;
+    return 0;
 }
 
 //! This function updates infoArray with virtual registers accessed when lowering the bytecode, and returns size of the bytecode in unit of u2
@@ -2993,8 +3075,9 @@ int getVirtualRegInfo(VirtualRegInfo* infoArray, const MIR * currentMIR) {
         break;
 #endif
     default:
-        ALOGE("ERROR: JIT does not support bytecode 0x%hx when updating\n"
+        ALOGE("JIT_ERROR: JIT does not support bytecode 0x%hx when updating\n"
                 "VR accesses\n", currentMIR->dalvikInsn.opcode);
+        SET_JIT_ERROR(kJitErrorUnsupportedBytecode);
         assert(false && "All opcodes should be supported.");
         break;
     }
@@ -4063,7 +4146,7 @@ int getTempRegInfo(TempRegInfo* infoArray, const MIR * currentMIR) { //returns a
         {
 #if 0
           if(iget_obj_inst == 12) {
-            LOGD("increase count for instance %d of %s %s", iget_obj_inst, currentMethod->clazz->descriptor, currentMethod->name);
+            ALOGD("increase count for instance %d of %s %s", iget_obj_inst, currentMethod->clazz->descriptor, currentMethod->name);
             infoArray[5].refCount = 4; //DU
           }
           else
@@ -5618,8 +5701,9 @@ int getTempRegInfo(TempRegInfo* infoArray, const MIR * currentMIR) { //returns a
     }
 #endif
     default:
-        ALOGE("ERROR: JIT does not support bytecode 0x%hx when updating\n"
+        ALOGE("JIT_ERROR: JIT does not support bytecode 0x%hx when updating\n"
                 "temp accesses\n", currentMIR->dalvikInsn.opcode);
+        SET_JIT_ERROR(kJitErrorUnsupportedBytecode);
         assert(false && "All opcodes should be supported.");
         break;
     }
diff --git a/vm/compiler/codegen/x86/CodegenErrors.cpp b/vm/compiler/codegen/x86/CodegenErrors.cpp
new file mode 100644
index 0000000..e12b826
--- /dev/null
+++ b/vm/compiler/codegen/x86/CodegenErrors.cpp
@@ -0,0 +1,144 @@
+/*
+ * Copyright (C) 2012-2013 Intel Corporation
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "CodegenErrors.h"
+
+/**
+ * @brief Error messages corresponding to JitCompilationErrors
+ * IMPORTANT: This needs to get updated when JitCompilationErrors
+ * is changed
+ */
+static const char* jitErrorMessages[kJitErrorMaxDefined] = {
+    "Exceeded maximum allowed VRs in a basic block",
+    "Jump offset greater than 8-bits",
+    "Trace contains bytecode with no implementation",
+    "Trace contains SGET / SPUT bytecode with unresolved field",
+    "Cannot find BasicBlock_O1 corresponding to a BasicBlock",
+    "Jit code cache is full while trace compilation",
+    "Failure in register allocator or register tables",
+    "Malloc failure while trace compilation",
+    "Exceeded maximum number of transfer points per BB",
+    "Exceeded number of destination regs for a source reg",
+    "Problem with state transfer in JIT",
+    "Problem with trace formation",
+    "Problem while performing null or bound check",
+    "Problem while merging live ranges (mergeLiveRange)",
+    "Global data not defined",
+    "Error while scheduling instructions"
+    //Add error messages here when adding error codes
+};
+
+/**
+ * @brief Contains a list of errors which are considered fatal
+ * Putting an error in this list will cause a dvmAbort if the
+ * error happens
+ * @param jitError The error to check for
+ * @return whether it is fatal
+ */
+bool isErrorFatal(JitCompilationErrors jitError) {
+
+    switch(jitError) {
+        case kJitErrorMallocFailed:
+        case kJitErrorInsScheduling:
+            return true;
+        default:
+            return false;
+    }
+
+}
+
+/**
+ * @brief Checks whether a compilation should be re-attempted
+ * Fixes anything which can be fixed. At the end we
+ * either don't have an error, have fixed the error, or
+ * cannot recover from the error. For the second case, we
+ * retry the compilation.
+ * @return whether we can retry the trace.
+ */
+bool dvmCanFixErrorsAndRetry(CompilationUnit *cUnit){
+
+    //Check if no error happened. No need to retry
+    if (!IS_ANY_JIT_ERROR_SET())
+        return false;
+
+    bool isError = false;
+    int lenErrorCodeBitVector = kJitErrorMaxDefined;
+
+    //Check all the errors which have been raised:
+    for (int i = 0; i < lenErrorCodeBitVector; i++) {
+        if (IS_JIT_ERROR_SET(i)) {
+            //This is the first error we are seeing. Print some information
+            //to be noticeable in the logs
+            if (!isError) {
+                ALOGE("++++++++++++++++++++++++++++++++++++++++++++");
+                ALOGE("Error while compiling trace  %s%s, offset %d", cUnit->method->clazz->descriptor,
+                     cUnit->method->name, cUnit->traceDesc->trace[0].info.frag.startOffset);
+
+                //If kJitErrorCodegen is the first error we encounter,
+                //somebody forgot to raise an error flag somewhere.
+                //Print a message and reject the trace:
+                if (i == kJitErrorCodegen) {
+                    ALOGE("Unknown error. Error flag not set at error location");
+                    ALOGE("++++++++++++++++++++++++++++++++++++++++++++");
+                    return false;
+                }
+
+                //Some other error happened with a proper flag. Remove the guard
+                CLEAR_JIT_ERROR(kJitErrorCodegen);
+
+                isError = true;
+                ALOGE("The following errors occurred:");
+            }
+
+            if (jitErrorMessages[i] == '\0')
+                ALOGE("\tError: (message not defined for JIT error)");
+            else
+                ALOGE("\tError: %s", jitErrorMessages[i]);
+
+            if (isErrorFatal((JitCompilationErrors) i)) {
+                ALOGE("\t\t(FATAL ERROR)");
+                ALOGE("FATAL_ERRORS in JIT. Aborting");
+                dvmAbort();
+            }
+        }
+    }
+
+    /* Handle any errors which can be handled */
+
+    //Handle error due to large jump offset
+    if ( IS_JIT_ERROR_SET(kJitErrorShortJumpOffset)) {
+        gDvmJit.disableOpt |= (1 << kShortJumpOffset);
+        ALOGE("Resolved error due to short jump offset");
+        //Clear the error:
+        CLEAR_JIT_ERROR(kJitErrorShortJumpOffset);
+    }
+
+    /* If at this point, we again have no errors set
+     * we have successfully resolved the errors. We can
+     * retry the trace now.
+     */
+    if (!IS_ANY_JIT_ERROR_SET()){
+        ALOGE("Retrying trace %s%s, offset %d", cUnit->method->clazz->descriptor,
+                cUnit->method->name, cUnit->traceDesc->trace[0].info.frag.startOffset);
+        ALOGE("++++++++++++++++++++++++++++++++++++++++++++");
+        return true;
+    }
+
+    //Otherwise, error cannot be handled:
+    ALOGE("Terminating trace due to unresolved errors");
+    ALOGE("++++++++++++++++++++++++++++++++++++++++++++");
+    return false;
+}
diff --git a/vm/compiler/codegen/x86/CodegenErrors.h b/vm/compiler/codegen/x86/CodegenErrors.h
new file mode 100644
index 0000000..d01148e
--- /dev/null
+++ b/vm/compiler/codegen/x86/CodegenErrors.h
@@ -0,0 +1,116 @@
+/*
+ * Copyright (C) 2012-2013 Intel Corporation
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ * @enum JitCompilationErrors
+ * @brief Possible errors which can happen during compilation
+ * Values indicate bit position in DvmJitGlobals.jitErrorFlags + 1
+ * IMPORTANT: Update jitErrorMessages when making changes to this list
+ */
+
+#ifndef CODEGEN_X86_CODEGEN_ERRORS_H_
+#define CODEGEN_X86_CODEGEN_ERRORS_H_
+
+#include "Dalvik.h"
+#include "../../CompilerIR.h"
+
+enum JitCompilationErrors {
+    /** @brief Exceeded maximum allowed VRs in a basic block */
+    kJitErrorMaxVR = 0,
+    /** @brief 8-bit jump offset not enough to reach label */
+    kJitErrorShortJumpOffset,
+    /** @brief Trace contains a bytecode with no JIT implementation */
+    kJitErrorUnsupportedBytecode,
+    /** @brief Field ptr unresolved for SGET/SPUT bytecodes */
+    kJitErrorUnresolvedField,
+    /** @brief Cannot find BasicBlock_O1 corresponding to a BasicBlock */
+    kJitErrorInvalidBBId,
+    /** @brief JIT code cache is full */
+    kJitErrorCodeCacheFull,
+    /** @brief Failures while allocating registers or error
+     *  in locating / putting registers in register tables
+     */
+    kJitErrorRegAllocFailed,
+    /** @brief Malloc failed. */
+    kJitErrorMallocFailed,
+    /** @brief Exceeded maximum number of transfer points per BB */
+    kJitErrorMaxXferPoints,
+    /** @brief Exceeded number of destination regs for a source reg */
+    kJitErrorMaxDestRegPerSource,
+    /** @brief Problem with state transfer in JIT */
+    kJitErrorStateTransfer,
+    /** @brief General trace formation issues */
+    kJitErrorTraceFormation,
+    /** @brief Errors while performing Null and Bound checks */
+    kJitErrorNullBoundCheckFailed,
+    /** @brief Errors while merging LiveRanges */
+    kJitErrorMergeLiveRange,
+    /** @brief Errors while accessing global data */
+    kJitErrorGlobalData,
+    /** @brief Errors while scheduling instructions */
+    kJitErrorInsScheduling,
+
+    /* ----- Add more errors above ---------------------------*/
+    /* ----- Don't add new errors beyond this point ----------*/
+
+    /** @brief Indicates "some" error happened
+     * Specifically, the purpose is that if someone forgets
+     * to use SET_JIT_ERROR at the specific error location,
+     * but does throw a return, the function handling that
+     * return can set this generic error. Also useful if a
+     * function can set multiple errors, the calling function
+     * won't have to worry about which one to set. Hopefully
+     * all of the errors have been individually set too.
+     * THIS NEEDS TO BE THE SECOND LAST VALUE
+     */
+    kJitErrorCodegen,
+    /** @brief Guarding value
+     * THIS NEEDS TO BE THE LAST VALUE
+     */
+    kJitErrorMaxDefined
+};
+
+/*
+ * Getter / Setter for  JitCompilationErrors
+ */
+/* Sets a particular error */
+#define SET_JIT_ERROR(jit_error)  gDvmJit.jitErrorFlags |= (1 << (int) jit_error);
+
+/* Clears only a particular error */
+#define CLEAR_JIT_ERROR(jit_error) gDvmJit.jitErrorFlags &= ~(1 << (int) jit_error);                                                                                    \
+
+/* Checks if a particular error is set */
+#define IS_JIT_ERROR_SET(jit_error) ( (gDvmJit.jitErrorFlags & (1 << (int) jit_error)) != 0 )
+
+/* Clears all errors */
+#define CLEAR_ALL_JIT_ERRORS() gDvmJit.jitErrorFlags = 0;                                                                                  \
+
+/* Checks if ANY error is set */
+#define IS_ANY_JIT_ERROR_SET() (gDvmJit.jitErrorFlags != 0)
+
+#define MAX_RETRIES 1
+
+/**
+ * @brief Checks whether a compilation should be re-attempted
+ * Fixes anything which can be fixed. At the end we
+ * either don't have an error, have fixed the error, or
+ * cannot recover from the error. For the second case, we
+ * retry the compilation.
+ * @return whether we can retry the trace.
+ */
+bool dvmCanFixErrorsAndRetry(CompilationUnit *cUnit);
+
+#endif
diff --git a/vm/compiler/codegen/x86/CodegenInterface.cpp b/vm/compiler/codegen/x86/CodegenInterface.cpp
index ccefd97..6349d7b 100644
--- a/vm/compiler/codegen/x86/CodegenInterface.cpp
+++ b/vm/compiler/codegen/x86/CodegenInterface.cpp
@@ -79,7 +79,7 @@ void dvmInitJitOpcodeTable() {
     }
     for (i = 0; i < sizeof(jitOpcodeTable)/sizeof(bool); i++) {
         if (jitOpcodeTable[i] == false)
-            LOGV("opcode 0x%x not supported by JIT", i);
+            ALOGV("opcode 0x%x not supported by JIT", i);
     }
 }
 
@@ -189,9 +189,9 @@ bool dvmCompilerArchInit() {
     }
 
     // Print out values used
-    LOGV("JIT threshold set to %hu",gDvmJit.threshold);
-    LOGV("JIT table size set to %u",gDvmJit.jitTableSize);
-    LOGV("JIT code cache size set to %u",gDvmJit.codeCacheSize);
+    ALOGV("JIT threshold set to %hu",gDvmJit.threshold);
+    ALOGV("JIT table size set to %u",gDvmJit.jitTableSize);
+    ALOGV("JIT code cache size set to %u",gDvmJit.codeCacheSize);
 
     //Disable Method-JIT
     gDvmJit.disableOpt |= (1 << kMethodJit);
@@ -723,7 +723,9 @@ u4* dvmJitUnchain(void* codeAddr)
                     predChainCell->clazz = PREDICTED_CHAIN_CLAZZ_INIT;
                     break;
                 default:
-                    ALOGE("Unexpected chaining type: %d", i);
+                    ALOGE("JIT_ERROR: Unexpected chaining type: %d", i);
+                    //Error is beyond the scope of the x86 JIT back-end
+                    ALOGE("\t FATAL ERROR. ABORTING!");
                     dvmAbort();  // dvmAbort OK here - can't safely recover
             }
             COMPILER_TRACE_CHAINING(
@@ -786,7 +788,7 @@ static int insertJumpHelp()
 static int handleNormalChainingCell(CompilationUnit *cUnit,
                                      unsigned int offset, int blockId, LowOpBlockLabel* labelList)
 {
-    ALOGV("in handleNormalChainingCell for method %s block %d BC offset %x NCG offset %x",
+    ALOGV("In handleNormalChainingCell for method %s block %d BC offset %x NCG offset %x",
           cUnit->method->name, blockId, offset, stream - streamMethodStart);
     if(dump_x86_inst)
         ALOGI("LOWER NormalChainingCell at offsetPC %x offsetNCG %x @%p",
@@ -809,7 +811,7 @@ static int handleNormalChainingCell(CompilationUnit *cUnit,
 static int handleHotChainingCell(CompilationUnit *cUnit,
                                   unsigned int offset, int blockId, LowOpBlockLabel* labelList)
 {
-    ALOGV("in handleHotChainingCell for method %s block %d BC offset %x NCG offset %x",
+    ALOGV("In handleHotChainingCell for method %s block %d BC offset %x NCG offset %x",
           cUnit->method->name, blockId, offset, stream - streamMethodStart);
     if(dump_x86_inst)
         ALOGI("LOWER HotChainingCell at offsetPC %x offsetNCG %x @%p",
@@ -829,7 +831,7 @@ static int handleHotChainingCell(CompilationUnit *cUnit,
 static int handleBackwardBranchChainingCell(CompilationUnit *cUnit,
                                      unsigned int offset, int blockId, LowOpBlockLabel* labelList)
 {
-    ALOGV("in handleBackwardBranchChainingCell for method %s block %d BC offset %x NCG offset %x",
+    ALOGV("In handleBackwardBranchChainingCell for method %s block %d BC offset %x NCG offset %x",
           cUnit->method->name, blockId, offset, stream - streamMethodStart);
     if(dump_x86_inst)
         ALOGI("LOWER BackwardBranchChainingCell at offsetPC %x offsetNCG %x @%p",
@@ -849,7 +851,7 @@ static int handleBackwardBranchChainingCell(CompilationUnit *cUnit,
 static int handleInvokeSingletonChainingCell(CompilationUnit *cUnit,
                                               const Method *callee, int blockId, LowOpBlockLabel* labelList)
 {
-    ALOGV("in handleInvokeSingletonChainingCell for method %s block %d callee %s NCG offset %x",
+    ALOGV("In handleInvokeSingletonChainingCell for method %s block %d callee %s NCG offset %x",
           cUnit->method->name, blockId, callee->name, stream - streamMethodStart);
     if(dump_x86_inst)
         ALOGI("LOWER InvokeSingletonChainingCell at block %d offsetNCG %x @%p",
@@ -992,13 +994,11 @@ static void setupLoopEntryBlock(CompilationUnit *cUnit, BasicBlock *entry,
 /* check whether we can merge the block at index i with its target block */
 bool mergeBlock(BasicBlock *bb, CompilationUnit *cUnit) {
     if(bb->blockType == kDalvikByteCode &&
-       bb->firstMIRInsn != NULL &&
-       (bb->lastMIRInsn->dalvikInsn.opcode == OP_GOTO_16 ||
-        bb->lastMIRInsn->dalvikInsn.opcode == OP_GOTO ||
-        bb->lastMIRInsn->dalvikInsn.opcode == OP_GOTO_32) &&
-       bb->fallThrough == NULL) {// &&
-       //cUnit->hasLoop) {
-        //ALOGI("merge blocks ending with goto at index %d", i);
+        bb->firstMIRInsn != NULL &&
+        (bb->lastMIRInsn->dalvikInsn.opcode == OP_GOTO_16 ||
+         bb->lastMIRInsn->dalvikInsn.opcode == OP_GOTO ||
+         bb->lastMIRInsn->dalvikInsn.opcode == OP_GOTO_32) &&
+         bb->fallThrough == NULL) {
         MIR* prevInsn = bb->lastMIRInsn->prev;
         if(bb->taken == NULL) return false;
         if(cUnit->jitMode == kJitLoop && bb->taken == cUnit->entryBlock->fallThrough)
@@ -1096,14 +1096,21 @@ bool hasBranchInLoop(CompilationUnit *cUnit)
     return true;
 }
 
-
 /* 4 is the number of additional bytes needed for chaining information for trace:
  * 2 bytes for chaining cell count offset and 2 bytes for chaining cell offset */
 #define EXTRA_BYTES_FOR_CHAINING 4
 
-/* Entry function to invoke the backend of the JIT compiler */
-void dvmCompilerMIR2LIR(CompilationUnit *cUnit, JitTranslationInfo *info)
+//! \brief Lower middle-level IR ro low-level IR
+//!
+//! \details Entry function to invoke the backend of the JIT compiler
+//!
+//! \param cUnit: The current compilation unit
+//! \param info: JitTranslationInfo. Holds generated code address on success
+static void compilerMIR2LIRJit(CompilationUnit *cUnit, JitTranslationInfo *info)
 {
+    const u2* startCodePtr;
+    const DexCode* dexCode;
+
     dump_x86_inst = cUnit->printMe;
     /* Used to hold the labels of each block */
     LowOpBlockLabel *labelList =
@@ -1168,10 +1175,21 @@ void dvmCompilerMIR2LIR(CompilationUnit *cUnit, JitTranslationInfo *info)
             bb = (BasicBlock *) blockList->elemList[i];
             if(bb->blockType == kDalvikByteCode &&
                bb->firstMIRInsn != NULL) {
-                preprocessingBB(bb);
+                int retCode = preprocessingBB(bb);
+                if (retCode < 0) {
+                    endOfTrace(true/*freeOnly*/);
+                    cUnit->baseAddr = NULL;
+                    SET_JIT_ERROR(kJitErrorCodegen);
+                    return;
+                }
             }
         }
-        preprocessingTrace();
+        if (preprocessingTrace() == -1) {
+            endOfTrace(true/*freeOnly*/);
+            cUnit->baseAddr = NULL;
+            SET_JIT_ERROR(kJitErrorCodegen);
+            return;
+        }
     }
 
     branchInLoop = cUnit->jitMode == kJitLoop && hasBranchInLoop(cUnit);
@@ -1198,8 +1216,7 @@ void dvmCompilerMIR2LIR(CompilationUnit *cUnit, JitTranslationInfo *info)
             if (bb->firstMIRInsn == NULL) {
                 continue;
             } else {
-              setupLoopEntryBlock(cUnit, bb, bb->fallThrough->id);
-                                  //&labelList[blockList[i]->fallThrough->id]);
+                setupLoopEntryBlock(cUnit, bb, bb->fallThrough->id);
             }
         } else if (bb->blockType == kExitBlock) {
             labelList[i].lop.opCode2 = ATOM_PSEUDO_EXIT_BLOCK;
@@ -1282,93 +1299,98 @@ void dvmCompilerMIR2LIR(CompilationUnit *cUnit, JitTranslationInfo *info)
             }
             continue;
         }
-        {
+
         //LowOp *headLIR = NULL;
-        const DexCode *dexCode = dvmGetMethodCode(cUnit->method);
-        const u2 *startCodePtr = dexCode->insns;
+        dexCode = dvmGetMethodCode(cUnit->method);
+        startCodePtr = dexCode->insns;
         labelList[i].lop.generic.offset = (stream - streamMethodStart);
         ALOGV("get ready to handle JIT bb %d type %d hidden %d",
               bb->id, bb->blockType, bb->hidden);
         for (BasicBlock *nextBB = bb; nextBB != NULL; nextBB = cUnit->nextCodegenBlock) {
-            bb = nextBB;
-            bb->visited = true;
-            cUnit->nextCodegenBlock = NULL;
-
-        if(gDvm.executionMode == kExecutionModeNcgO1 &&
-           bb->blockType != kEntryBlock &&
-           bb->firstMIRInsn != NULL) {
-            startOfBasicBlock(bb);
-            int cg_ret = codeGenBasicBlockJit(cUnit->method, bb);
-            endOfBasicBlock(bb);
-            if(cg_ret < 0) {
-                endOfTrace(true/*freeOnly*/);
-                cUnit->baseAddr = NULL;
-                PROTECT_CODE_CACHE(stream, unprotected_code_cache_bytes);
-                return;
-            }
-        } else {
-        for (mir = bb->firstMIRInsn; mir; mir = mir->next) {
-            // Global variable rPC that's holding the Dalvik PC
-            // needs to be updated here because we are iterating
-            // through the MIRs of this BB.
-            rPC = const_cast<u2 *>(cUnit->method->insns) + mir->offset;
-            startOfBasicBlock(bb); //why here for O0
-            Opcode dalvikOpCode = mir->dalvikInsn.opcode;
-            if((int)dalvikOpCode >= (int)kMirOpFirst) {
-                handleExtendedMIR(cUnit, mir);
-                continue;
-            }
-            InstructionFormat dalvikFormat =
-                dexGetFormatFromOpcode(dalvikOpCode);
-            ALOGV("ready to handle bytecode at offset %x: opcode %d format %d",
-                  mir->offset, dalvikOpCode, dalvikFormat);
-
-            // Before: A boundary LIR with Atom pseudo-mnemonic named
-            //      ATOM_PSEUDO_DALVIK_BYTECODE_BOUNDARY was being created
-            //      at this point. The allocation of the Atom LIR used to
-            //      update the global variable named lowOpTimeStamp.
-            // After: LIRs are now only allocated through the Instruction
-            //      scheduling interface and LIRs with only pseudo-mnemonics
-            //      are not supported. In order to keep semantics, the
-            //      timestamp will be updated here manually since it affects
-            //      register allocation.
-            lowOpTimeStamp++;
-
-            bool notHandled = true;
-            /*
-             * Debugging: screen the opcode first to see if it is in the
-             * do[-not]-compile list
-             */
-            bool singleStepMe =
-                gDvmJit.includeSelectedOp !=
-                ((gDvmJit.opList[dalvikOpCode >> 3] &
-                  (1 << (dalvikOpCode & 0x7))) !=
-                 0);
-            if (singleStepMe || cUnit->allSingleStep) {
-            } else {
-                //lower each byte code, update LIR
-                notHandled = lowerByteCodeJit(cUnit->method, mir, rPC);
-                if(gDvmJit.codeCacheByteUsed + (stream - streamStart) +
-                   CODE_CACHE_PADDING > gDvmJit.codeCacheSize) {
-                    ALOGI("JIT code cache full after lowerByteCodeJit (trace uses %uB)", (stream - streamStart));
-                    gDvmJit.codeCacheFull = true;
-                    cUnit->baseAddr = NULL;
+                bb = nextBB;
+                bb->visited = true;
+                cUnit->nextCodegenBlock = NULL;
+
+            if(gDvm.executionMode == kExecutionModeNcgO1 &&
+               bb->blockType != kEntryBlock &&
+               bb->firstMIRInsn != NULL) {
+                startOfBasicBlock(bb);
+                int cg_ret = codeGenBasicBlockJit(cUnit->method, bb);
+                endOfBasicBlock(bb);
+                if(cg_ret < 0) {
+                    ALOGI("Could not compile trace for %s%s, offset %d",
+                            cUnit->method->clazz->descriptor, cUnit->method->name,
+                            cUnit->traceDesc->trace[0].info.frag.startOffset);
+                    SET_JIT_ERROR(kJitErrorCodegen);
                     endOfTrace(true/*freeOnly*/);
+                    cUnit->baseAddr = NULL;
                     PROTECT_CODE_CACHE(stream, unprotected_code_cache_bytes);
                     return;
                 }
             }
-            if (notHandled) {
-                ALOGE("%#06x: Opcode 0x%x (%s) / Fmt %d not handled",
-                     mir->offset,
-                     dalvikOpCode, dexGetOpcodeName(dalvikOpCode),
-                     dalvikFormat);
-                dvmAbort();
-                break;
-            }
-        } // end for
-        } // end else //JIT + O0 code generator
-        }
+            else {
+                for (mir = bb->firstMIRInsn; mir; mir = mir->next) {
+                    // Global variable rPC that's holding the Dalvik PC
+                    // needs to be updated here because we are iterating
+                    // through the MIRs of this BB.
+                    rPC = const_cast<u2 *>(cUnit->method->insns) + mir->offset;
+                    startOfBasicBlock(bb); //why here for O0
+                    Opcode dalvikOpCode = mir->dalvikInsn.opcode;
+                    if((int)dalvikOpCode >= (int)kMirOpFirst) {
+                        handleExtendedMIR(cUnit, mir);
+                        continue;
+                    }
+                    InstructionFormat dalvikFormat =
+                        dexGetFormatFromOpcode(dalvikOpCode);
+                    ALOGV("ready to handle bytecode at offset %x: opcode %d format %d",
+                          mir->offset, dalvikOpCode, dalvikFormat);
+
+                    // Before: A boundary LIR with Atom pseudo-mnemonic named
+                    //      ATOM_PSEUDO_DALVIK_BYTECODE_BOUNDARY was being created
+                    //      at this point. The allocation of the Atom LIR used to
+                    //      update the global variable named lowOpTimeStamp.
+                    // After: LIRs are now only allocated through the Instruction
+                    //      scheduling interface and LIRs with only pseudo-mnemonics
+                    //      are not supported. In order to keep semantics, the
+                    //      timestamp will be updated here manually since it affects
+                    //      register allocation.
+                    lowOpTimeStamp++;
+
+                    bool notHandled = true;
+                    /*
+                     * Debugging: screen the opcode first to see if it is in the
+                     * do[-not]-compile list
+                     */
+                    bool singleStepMe =
+                        gDvmJit.includeSelectedOp !=
+                        ((gDvmJit.opList[dalvikOpCode >> 3] &
+                          (1 << (dalvikOpCode & 0x7))) !=
+                         0);
+                    if (singleStepMe || cUnit->allSingleStep) {
+                    } else {
+                        //lower each byte code, update LIR
+                        notHandled = lowerByteCodeJit(cUnit->method, mir, rPC);
+                        if(gDvmJit.codeCacheByteUsed + (stream - streamStart) +
+                           CODE_CACHE_PADDING > gDvmJit.codeCacheSize) {
+                            ALOGE("JIT_ERROR: Code cache full after lowerByteCodeJit (trace uses %uB)", (stream - streamStart));
+                            SET_JIT_ERROR(kJitErrorCodeCacheFull);
+                            gDvmJit.codeCacheFull = true;
+                            cUnit->baseAddr = NULL;
+                            endOfTrace(true/*freeOnly*/);
+                            PROTECT_CODE_CACHE(stream, unprotected_code_cache_bytes);
+                            return;
+                        }
+                    }
+                    if (notHandled) {
+                        ALOGE("JIT_ERROR: Opcode 0x%x (%s) / Fmt %d at offset %#06x not handled\n",
+                            dalvikOpCode, dexGetOpcodeName(dalvikOpCode), dalvikFormat, mir->offset);
+                        SET_JIT_ERROR(kJitErrorUnsupportedBytecode);
+                        cUnit->baseAddr = NULL;
+                        endOfTrace(true); /* need to free structures */
+                        break;
+                    }
+                } // end for
+            } // end else //JIT + O0 code generator
         } // end for
         /* Eliminate redundant loads/stores and delay stores into later slots */
 #if 0
@@ -1442,13 +1464,16 @@ gen_fallthrough:
                     labelList[blockId].lop.generic.offset += nop_size; //skip over nop
                     break;
                 default:
-                    ALOGE("Bad blocktype %d", chainingBlock->blockType);
-                    dvmAbort();
-                    break;
+                    ALOGE("JIT_ERROR: Bad blocktype %d", chainingBlock->blockType);
+                    SET_JIT_ERROR(kJitErrorTraceFormation);
+                    cUnit->baseAddr = NULL;
+                    endOfTrace(true); /* need to free structures */
+                    return;
             }
 
             if (gDvmJit.codeCacheByteUsed + (stream - streamStart) + CODE_CACHE_PADDING > gDvmJit.codeCacheSize) {
-                ALOGI("JIT code cache full after ChainingCell (trace uses %uB)", (stream - streamStart));
+                ALOGE("JIT_ERROR: Code cache full after ChainingCell (trace uses %uB)", (stream - streamStart));
+                SET_JIT_ERROR(kJitErrorCodeCacheFull);
                 gDvmJit.codeCacheFull = true;
                 cUnit->baseAddr = NULL;
                 endOfTrace(true); /* need to free structures */
@@ -1470,7 +1495,8 @@ gen_fallthrough:
     if (gDvmJit.codeCacheFull) {
         // We hit code cache size limit either after dumping exception handling
         // state or after calling endOfTrace. Bail out for this trace!
-        ALOGI("JIT code cache full after endOfTrace (trace uses %uB)", (stream - streamStart));
+        ALOGE("JIT_ERROR: Code cache full after endOfTrace (trace uses %uB)", (stream - streamStart));
+        SET_JIT_ERROR(kJitErrorCodeCacheFull);
         cUnit->baseAddr = NULL;
         PROTECT_CODE_CACHE(stream, unprotected_code_cache_bytes);
         return;
@@ -1491,7 +1517,8 @@ gen_fallthrough:
     cUnit->baseAddr = streamMethodStart;
     cUnit->totalSize = (stream - streamStart);
     if(gDvmJit.codeCacheByteUsed + cUnit->totalSize + CODE_CACHE_PADDING > gDvmJit.codeCacheSize) {
-        ALOGI("JIT code cache full after ChainingCellCounts (trace uses %uB)", (stream - streamStart));
+        ALOGE("JIT_ERROR: Code cache full after ChainingCellCounts (trace uses %uB)", (stream - streamStart));
+        SET_JIT_ERROR(kJitErrorCodeCacheFull);
         gDvmJit.codeCacheFull = true;
         cUnit->baseAddr = NULL;
         PROTECT_CODE_CACHE(stream, unprotected_code_cache_bytes);
@@ -1525,6 +1552,40 @@ gen_fallthrough:
     info->codeAddress = (char*)cUnit->baseAddr;// + cUnit->headerSize;
 }
 
+//! \brief Helper function to call compilerMIR2LIRJit
+//!
+//! \details Calls dvmCompilerMIR2LIRJit, checks for errors
+//! and retries if possible.
+//!
+//! \param cUnit: The current compilation unit
+//! \param info: JitTranslationInfo.
+void dvmCompilerMIR2LIR(CompilationUnit *cUnit, JitTranslationInfo *info) {
+   //Start the counter
+   int numTries = 0;
+
+   //Try to lower MIR
+    do {
+        //See if we have been here too many times:
+        if (numTries > MAX_RETRIES) {
+            ALOGI("Too many retries while compiling trace  %s%s, offset %d", cUnit->method->clazz->descriptor,
+                cUnit->method->name, cUnit->traceDesc->trace[0].info.frag.startOffset);
+            ALOGI("Rejecting Trace");
+            return;
+        }
+
+        //Ignore errors in previous compilations
+        CLEAR_ALL_JIT_ERRORS();
+
+        //Do the trace compilation
+        numTries++;
+        compilerMIR2LIRJit(cUnit, info);
+
+        //Once done, see if errors happened, and if so
+        //see if we can retry and come back
+    } while (IS_ANY_JIT_ERROR_SET() && dvmCanFixErrorsAndRetry(cUnit));
+}
+
+
 /*
  * Perform translation chain operation.
  */
@@ -1600,8 +1661,9 @@ bool dvmCompilerDoWork(CompilerWorkOrder *work)
             break;
         default:
             isCompile = false;
-            ALOGE("Jit: unknown work order type");
+            ALOGE("JIT_ERROR: Unknown work order type");
             assert(0);  // Bail if debug build, discard otherwise
+            ALOGE("\tError ignored");
     }
     if (!success)
         work->result.codeAddress = NULL;
diff --git a/vm/compiler/codegen/x86/ExceptionHandling.cpp b/vm/compiler/codegen/x86/ExceptionHandling.cpp
index 2169611..18092b5 100644
--- a/vm/compiler/codegen/x86/ExceptionHandling.cpp
+++ b/vm/compiler/codegen/x86/ExceptionHandling.cpp
@@ -115,6 +115,8 @@ void ExceptionHandlingRestoreState::dumpAllExceptionHandlingRestoreState(void) {
                 + sizeOfExceptionRestore + CODE_CACHE_PADDING
                 > gDvmJit.codeCacheSize) {
             gDvmJit.codeCacheFull = true;
+            ALOGE("JIT_ERROR: Code cache full while dumping exception handling restore state");
+            SET_JIT_ERROR(kJitErrorCodeCacheFull);
             this->reset();
             return;
         }
@@ -124,10 +126,13 @@ void ExceptionHandlingRestoreState::dumpAllExceptionHandlingRestoreState(void) {
 
         // JIT verbosity
         if (dump_x86_inst)
-            LOGD("LOWER %s @%p", label, stream);
+            ALOGD("LOWER %s @%p", label, stream);
 
         // Insert label exception_restore_state_# where # is the unique identifier
-        insertLabel(label, true);
+        if (insertLabel(label, true) == -1) {
+            this->reset();
+            return;
+        }
 
         // Copy to instruction stream
         memcpy(stream, this->streams[i].first, sizeOfExceptionRestore);
diff --git a/vm/compiler/codegen/x86/Lower.cpp b/vm/compiler/codegen/x86/Lower.cpp
index f90b34a..9edafeb 100644
--- a/vm/compiler/codegen/x86/Lower.cpp
+++ b/vm/compiler/codegen/x86/Lower.cpp
@@ -215,6 +215,7 @@ int common_returnFromMethod();
 
 */
 int performCGWorklist() {
+    int retCode = 0;
     filled_new_array_notimpl();
     freeShortMap();
     const_string_resolve();
@@ -236,9 +237,9 @@ int performCGWorklist() {
     freeShortMap();
     throw_exception(PhysicalReg_ECX, PhysicalReg_EAX, PhysicalReg_Null, true);
     freeShortMap();
-    new_instance_needinit();
+    retCode = new_instance_needinit();
     freeShortMap();
-    return 0;
+    return retCode;
 }
 
 int aput_object_count;
@@ -263,7 +264,8 @@ int ncgMethodFake(Method* method) {
     unsigned int i;
     u2* rStart = (u2*)malloc(5*sizeof(u2));
     if(rStart == NULL) {
-        ALOGE("Memory allocation failed");
+        ALOGE("JIT_ERROR: Memory allocation failed at ncgMethodFake");
+        SET_JIT_ERROR(kJitErrorMallocFailed);
         return -1;
     }
     rPC = rStart;
@@ -374,7 +376,8 @@ void initGlobalMethods() {
     gDvmJit.scheduling = false;
 
     // generate native code for function ncgGetEIP
-    insertLabel("ncgGetEIP", false);
+    if (insertLabel("ncgGetEIP", false) == -1)
+        return;
     move_mem_to_reg(OpndSize_32, 0, PhysicalReg_ESP, true, PhysicalReg_EDX, true);
     x86_return();
 
@@ -388,15 +391,19 @@ void initGlobalMethods() {
     //common_invokeMethodNoRange();
     //common_invokeMethodRange();
 
-    if(dump_x86_inst) ALOGI("ArgsDone_Normal start");
+    if(dump_x86_inst)
+        ALOGI("ArgsDone_Normal start");
     common_invokeArgsDone(ArgsDone_Normal, false);
     freeShortMap();
-    if(dump_x86_inst) ALOGI("ArgsDone_Native start");
+    if(dump_x86_inst)
+        ALOGI("ArgsDone_Native start");
     common_invokeArgsDone(ArgsDone_Native, false);
     freeShortMap();
-    if(dump_x86_inst) ALOGI("ArgsDone_Full start");
+    if(dump_x86_inst)
+        ALOGI("ArgsDone_Full start");
     common_invokeArgsDone(ArgsDone_Full, true/*isJitFull*/);
-    if(dump_x86_inst) ALOGI("ArgsDone_Full end");
+    if(dump_x86_inst)
+        ALOGI("ArgsDone_Full end");
     freeShortMap();
 
     common_backwardBranch();
@@ -547,14 +554,18 @@ int lowerByteCode(const Method* method, const MIR * mir, const u2 * dalvikPC) {
             }
         }
 
-        LOGI("LOWER %s%s%s with offsetPC %x offsetNCG %x @%p\n",
+        ALOGI("LOWER %s%s%s with offsetPC %x offsetNCG %x @%p\n",
                 decodedString, note, extraNote, offsetPC, stream - streamMethodStart,
                 stream);
     }
 
     //update mapFromBCtoNCG
     offsetNCG = stream - streamMethodStart;
-    if(offsetPC >= BYTECODE_SIZE_PER_METHOD) ALOGE("offsetPC %d exceeds BYTECODE_SIZE_PER_METHOD", offsetPC);
+    if(offsetPC >= BYTECODE_SIZE_PER_METHOD) {
+        ALOGE("JIT_ERROR: offsetPC %d exceeds BYTECODE_SIZE_PER_METHOD", offsetPC);
+        SET_JIT_ERROR(kJitErrorTraceFormation);
+        return -1;
+    }
     mapFromBCtoNCG[offsetPC] = offsetNCG;
 #if defined(ENABLE_TRACING) && defined(TRACING_OPTION2)
     insertMapWorklist(offsetPC, mapFromBCtoNCG[offsetPC], 1);
@@ -1015,9 +1026,6 @@ int lowerByteCode(const Method* method, const MIR * mir, const u2 * dalvikPC) {
         return op_execute_inline(mir, false /*isRange*/);
     case OP_EXECUTE_INLINE_RANGE:
         return op_execute_inline(mir, true /*isRange*/);
-    case OP_BREAKPOINT:
-        ALOGE("found bytecode OP_BREAKPOINT");
-        exit(-1);
 //  case OP_INVOKE_OBJECT_INIT_RANGE:
 //      return op_invoke_object_init_range();
     case OP_IGET_QUICK:
@@ -1041,8 +1049,9 @@ int lowerByteCode(const Method* method, const MIR * mir, const u2 * dalvikPC) {
     case OP_INVOKE_SUPER_QUICK_RANGE:
         return op_invoke_super_quick_range(mir);
     default:
-        ALOGE("ERROR: JIT does not support bytecode 0x%hx\n",
-                mir->dalvikInsn.opcode);
+        ALOGE("JIT_ERROR: JIT does not support bytecode %s\n",
+                dexGetOpcodeName(mir->dalvikInsn.opcode));
+        SET_JIT_ERROR(kJitErrorUnsupportedBytecode);
         assert(false && "All opcodes should be supported.");
         break;
     }
@@ -1067,9 +1076,9 @@ void sendLabelInfoToVTune(int startStreamPtr, int endStreamPtr, const char* labe
     jitMethod.method_size = endStreamPtr-startStreamPtr;
     int res = iJIT_NotifyEvent(iJVM_EVENT_TYPE_METHOD_LOAD_FINISHED, (void*)&jitMethod);
     if (res) {
-        LOGI("JIT API: a trace of %s method was written successfully.\n", labelName);
+        ALOGI("JIT API: a trace of %s method was written successfully.\n", labelName);
     } else {
-        LOGI("JIT API: failed to write a trace of %s method.\n", labelName);
+        ALOGI("JIT API: failed to write a trace of %s method.\n", labelName);
     }
 }
 #endif
diff --git a/vm/compiler/codegen/x86/Lower.h b/vm/compiler/codegen/x86/Lower.h
index 429750c..9c07180 100644
--- a/vm/compiler/codegen/x86/Lower.h
+++ b/vm/compiler/codegen/x86/Lower.h
@@ -52,6 +52,7 @@
 #define INVOKE_FIX //optimization
 #define GETVR_FIX //optimization
 
+#include "CodegenErrors.h"
 #include "Dalvik.h"
 #include "enc_wrapper.h"
 #include "AnalysisO1.h"
@@ -706,7 +707,7 @@ bool checkTempReg2(int reg, int type, bool isPhysical, int physicalRegForVR, u2
 int freeReg(bool spillGL);
 int nextVersionOfHardReg(PhysicalReg pReg, int refCount);
 int updateVirtualReg(int reg, LowOpndRegType type);
-void setVRNullCheck(int regNum, OpndSize size);
+int setVRNullCheck(int regNum, OpndSize size);
 bool isVRNullCheck(int regNum, OpndSize size);
 void setVRBoundCheck(int vr_array, int vr_index);
 bool isVRBoundCheck(int vr_array, int vr_index);
@@ -714,8 +715,8 @@ int requestVRFreeDelay(int regNum, u4 reason);
 void cancelVRFreeDelayRequest(int regNum, u4 reason);
 bool getVRFreeDelayRequested(int regNum);
 bool isGlueHandled(int glue_reg);
-void resetGlue(int glue_reg);
-void updateGlue(int reg, bool isPhysical, int glue_reg);
+int resetGlue(int glue_reg);
+int updateGlue(int reg, bool isPhysical, int glue_reg);
 int updateVRAtUse(int reg, LowOpndRegType pType, int regAll);
 int touchEcx();
 int touchEax();
@@ -727,7 +728,7 @@ void endBranch();
 void rememberState(int);
 void goToState(int);
 void transferToState(int);
-void globalVREndOfBB(const Method*);
+int globalVREndOfBB(const Method*);
 void constVREndOfBB();
 bool hasVRStoreExitOfLoop();
 void storeVRExitOfLoop();
@@ -1048,8 +1049,8 @@ int common_errNoSuchMethod();
 int common_errDivideByZero();
 int common_periodicChecks_entry();
 int common_periodicChecks4();
-int common_gotoBail();
-int common_gotoBail_0();
+int common_gotoBail(void);
+int common_gotoBail_0(void);
 int common_errStringIndexOutOfBounds();
 void goto_invokeArgsDone();
 
@@ -1389,7 +1390,7 @@ int getRelativeNCG(s4 tmp, JmpCall_type type, bool* unknown, OpndSize* size);
 void freeAtomMem();
 OpndSize estOpndSizeFromImm(int target);
 
-void preprocessingBB(BasicBlock* bb);
-void preprocessingTrace();
+int preprocessingBB(BasicBlock* bb);
+int preprocessingTrace();
 void dump_nop(int size);
 #endif
diff --git a/vm/compiler/codegen/x86/LowerAlu.cpp b/vm/compiler/codegen/x86/LowerAlu.cpp
index 1d9d9f2..2dbf89c 100644
--- a/vm/compiler/codegen/x86/LowerAlu.cpp
+++ b/vm/compiler/codegen/x86/LowerAlu.cpp
@@ -286,7 +286,8 @@ int common_fp_to_int(bool isDouble, u2 vA, u2 vB) {
     load_effective_addr(2, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
     rememberState(3);
     unconditional_jump(".float_to_int_okay", true);
-    insertLabel(".float_to_int_nanInf", true);
+    if (insertLabel(".float_to_int_nanInf", true) == -1)
+        return -1;
     conditional_jump(Condition_NP, ".float_to_int_posInf", true);
     //fstps CHECK
     goToState(2);
@@ -294,21 +295,24 @@ int common_fp_to_int(bool isDouble, u2 vA, u2 vB) {
     set_VR_to_imm(vA, OpndSize_32, 0);
     transferToState(3);
     unconditional_jump(".float_to_int_okay", true);
-    insertLabel(".float_to_int_posInf", true);
+    if (insertLabel(".float_to_int_posInf", true) == -1)
+        return -1;
     //fstps CHECK
     goToState(2);
     store_fp_stack_VR(true, OpndSize_32, vA);
     set_VR_to_imm(vA, OpndSize_32, 0x7fffffff);
     transferToState(3);
     unconditional_jump(".float_to_int_okay", true);
-    insertLabel(".float_to_int_negInf", true);
+    if (insertLabel(".float_to_int_negInf", true) == -1)
+        return -1;
     goToState(1);
     //fstps CHECK
     store_fp_stack_VR(true, OpndSize_32, vA);
     store_fp_stack_VR(true, OpndSize_32, vA);
     set_VR_to_imm(vA, OpndSize_32, 0x80000000);
     transferToState(3);
-    insertLabel(".float_to_int_okay", true);
+    if (insertLabel(".float_to_int_okay", true) == -1)
+        return -1;
     return 0;
 }
 
@@ -386,7 +390,8 @@ int common_fp_to_long(bool isDouble, u2 vA, u2 vB) {
     unconditional_jump(".float_to_long_okay", true);
 
     //We can be here for positive infinity or NaN. Check parity bit
-    insertLabel(".float_to_long_nanInf", true);
+    if (insertLabel(".float_to_long_nanInf", true) == -1)
+        return -1;
     conditional_jump(Condition_NP, ".float_to_long_posInf", true);
     goToState(2);
     //Save corresponding Long NaN value
@@ -397,7 +402,8 @@ int common_fp_to_long(bool isDouble, u2 vA, u2 vB) {
     compare_fp_stack(true, 0, false/*isDouble*/); //ST(0)
     unconditional_jump(".float_to_long_okay", true);
 
-    insertLabel(".float_to_long_posInf", true);
+    if (insertLabel(".float_to_long_posInf", true) == -1)
+        return -1;
     goToState(2);
     //Save corresponding Long Positive Infinity value
     load_global_data_API("valuePosInfLong", OpndSize_64, 2, false);
@@ -407,7 +413,8 @@ int common_fp_to_long(bool isDouble, u2 vA, u2 vB) {
     compare_fp_stack(true, 0, false/*isDouble*/); //ST(0)
     unconditional_jump(".float_to_long_okay", true);
 
-    insertLabel(".float_to_long_negInf", true);
+    if (insertLabel(".float_to_long_negInf", true) == -1)
+        return -1;
     //fstpl
     goToState(1);
     //Load corresponding Long Negative Infinity value
@@ -417,7 +424,8 @@ int common_fp_to_long(bool isDouble, u2 vA, u2 vB) {
     //Pop out the original value we pushed
     compare_fp_stack(true, 0, false/*isDouble*/); //ST(0)
 
-    insertLabel(".float_to_long_okay", true);
+    if (insertLabel(".float_to_long_okay", true) == -1)
+        return -1;
     return 0;
 }
 
@@ -837,7 +845,8 @@ int common_div_rem_int(bool isRem, u2 vA, u2 v1, u2 v2) {
     transferToState(2);
     conditional_jump(Condition_E, ".common_div_rem_int_special", true);
 
-    insertLabel(".common_div_rem_int_32", true);
+    if (insertLabel(".common_div_rem_int_32", true) == -1) //merge point
+        return -1;
     convert_integer(OpndSize_32, OpndSize_64); //cdq
     //idiv: dividend in edx:eax; quotient in eax; remainder in edx
     alu_unary_reg(OpndSize_32, idiv_opc, 2, false);
@@ -850,7 +859,8 @@ int common_div_rem_int(bool isRem, u2 vA, u2 v1, u2 v2) {
     //can allocate a register not capable of 8-bit operation, like ESI,
     //which will cause undefined behaviour.
     goToState(1);
-    insertLabel(".common_div_rem_int_8", true);
+    if (insertLabel(".common_div_rem_int_8", true) == -1)
+        return -1;
     move_reg_to_reg(OpndSize_32, 2, false, PhysicalReg_EBX, true);
     alu_unary_reg(OpndSize_8, div_opc, PhysicalReg_EBX, true);
     if (isRem) {
@@ -864,13 +874,15 @@ int common_div_rem_int(bool isRem, u2 vA, u2 v1, u2 v2) {
     //Do 16-bit divide:
     //div: dividend in dx:ax; quotient in ax; remainder in dx
     goToState(1);
-    insertLabel(".common_div_rem_int_16", true);
+    if (insertLabel(".common_div_rem_int_16", true) == -1)
+        return -1;
     move_imm_to_reg(OpndSize_32, 0, PhysicalReg_EDX, true);  //clearing out.
     alu_unary_reg(OpndSize_16, div_opc, 2, false);
 
 
     transferToState(3);
-    insertLabel(".common_div_rem_int_divdone", true);
+    if (insertLabel(".common_div_rem_int_divdone", true) == -1)
+        return -1;
     if(isRem)
         set_virtual_reg(vA, OpndSize_32, PhysicalReg_EDX, true);
     else //divide: quotient in %eax
@@ -879,14 +891,18 @@ int common_div_rem_int(bool isRem, u2 vA, u2 v1, u2 v2) {
     unconditional_jump(".common_div_rem_int_okay", true);
 
     goToState(2);
-    insertLabel(".common_div_rem_int_special", true);
+    if (insertLabel(".common_div_rem_int_special", true) == -1)
+        return -1;
+
     if(isRem)
         set_VR_to_imm(vA, OpndSize_32, 0);
     else
         set_VR_to_imm(vA, OpndSize_32, 0x80000000);
 
     transferToState(4);
-    insertLabel(".common_div_rem_int_okay", true);
+    if (insertLabel(".common_div_rem_int_okay", true) == -1) //merge point 2
+        return -1;
+
     return 0;
 }
 #undef P_GPR_1
@@ -1241,7 +1257,7 @@ int common_div_rem_int_lit(bool isRem, u2 vA, u2 vB, s2 imm) {
     if(imm == 0) {
         export_pc(); //use %edx
 #ifdef DEBUG_EXCEPTION
-        LOGI("EXTRA code to handle exception");
+        ALOGI("EXTRA code to handle exception");
 #endif
         constVREndOfBB();
         beforeCall("exception"); //dump GG, GL VRs
@@ -1269,7 +1285,9 @@ int common_div_rem_int_lit(bool isRem, u2 vA, u2 vB, s2 imm) {
     if(imm == -1) {
         unconditional_jump(".div_rem_int_lit_okay", true);
         rememberState(2);
-        insertLabel(".div_rem_int_lit_special", true);
+
+        if (insertLabel(".div_rem_int_lit_special", true) == -1)
+            return -1;
         goToState(1);
         if(isRem)
             set_VR_to_imm(vA, OpndSize_32, 0);
@@ -1278,7 +1296,8 @@ int common_div_rem_int_lit(bool isRem, u2 vA, u2 vB, s2 imm) {
         transferToState(2);
     }
 
-    insertLabel(".div_rem_int_lit_okay", true); //merge point 2
+    if (insertLabel(".div_rem_int_lit_okay", true) == -1)
+        return -1; //merge point 2
     return 0;
 }
 #undef P_GPR_1
@@ -1686,10 +1705,12 @@ int common_shr_long(u2 vA, u2 v1, u2 v2) {
     //check whether the target is next instruction TODO
     unconditional_jump(".common_shr_long_done", true);
 
-    insertLabel(".common_shr_long_special", true);
+    if (insertLabel(".common_shr_long_special", true) == -1)
+        return -1;
     goToState(1);
     transferToState(2);
-    insertLabel(".common_shr_long_done", true);
+    if (insertLabel(".common_shr_long_done", true) == -1)
+        return -1;
     set_virtual_reg(vA, OpndSize_64, 1, false);
     return 0;
 }
@@ -2306,7 +2327,8 @@ int op_cmp_long(const MIR * mir) {
     set_virtual_reg(vA, OpndSize_32, 6, false);
     rememberState(2);
     unconditional_jump(".cmp_long_okay", true);
-    insertLabel(".cmp_long_equal", true);
+    if (insertLabel(".cmp_long_equal", true) == -1)
+        return -1;
     goToState(1);
 #endif
 
@@ -2328,14 +2350,17 @@ int op_cmp_long(const MIR * mir) {
     set_VR_to_imm(vA, OpndSize_32, 0);
     unconditional_jump(".cmp_long_okay", true);
 
-    insertLabel(".cmp_long_less", true);
+    if (insertLabel(".cmp_long_less", true) == -1)
+        return -1;
     set_VR_to_imm(vA, OpndSize_32, 0xffffffff);
     unconditional_jump(".cmp_long_okay", true);
 
-    insertLabel(".cmp_long_greater", true);
+    if (insertLabel(".cmp_long_greater", true) == -1)
+        return -1;
     set_VR_to_imm(vA, OpndSize_32, 1);
 #endif
-    insertLabel(".cmp_long_okay", true);
+    if (insertLabel(".cmp_long_okay", true) == -1)
+        return -1;
     return 0;
 }
 #undef P_GPR_1
diff --git a/vm/compiler/codegen/x86/LowerConst.cpp b/vm/compiler/codegen/x86/LowerConst.cpp
index ef8f207..1f77537 100644
--- a/vm/compiler/codegen/x86/LowerConst.cpp
+++ b/vm/compiler/codegen/x86/LowerConst.cpp
@@ -222,7 +222,8 @@ int op_const_class(const MIR * mir) {
     move_imm_to_reg(OpndSize_32, tmp, PhysicalReg_EAX, true);
     call_helper_API(".class_resolve");
     transferToState(1);
-    insertLabel(".const_class_resolved", true);
+    if (insertLabel(".const_class_resolved", true) == -1)
+        return -1;
     set_virtual_reg(vA, OpndSize_32, PhysicalReg_EAX, true);
 #else
     /* for trace-based JIT, the class is already resolved since this code has been executed */
diff --git a/vm/compiler/codegen/x86/LowerGetPut.cpp b/vm/compiler/codegen/x86/LowerGetPut.cpp
index fb2184b..4dd70b6 100644
--- a/vm/compiler/codegen/x86/LowerGetPut.cpp
+++ b/vm/compiler/codegen/x86/LowerGetPut.cpp
@@ -473,13 +473,15 @@ int op_aput_object(const MIR * mir) { //type checking
     ////TODO NCG O1 + code cache
     unconditional_jump(".aput_object_after_check", true);
 
-    insertLabel(".aput_object_skip_check", true);
+    if (insertLabel(".aput_object_skip_check", true) == -1)
+        return -1;
     goToState(1);
     //NOTE: "2, false" is live through function call
     move_reg_to_mem_disp_scale(OpndSize_32, 4, false, 1, false, offArrayObject_contents, 2, false, 4);
 
     transferToState(2);
-    insertLabel(".aput_object_after_check", true);
+    if (insertLabel(".aput_object_after_check", true) == -1)
+        return -1;
     ///////////////////////////////
   }
   return 0;
@@ -514,7 +516,9 @@ void markCard(int valReg, int tgtAddrReg, bool targetPhysical, int scratchReg, b
    conditional_jump(Condition_E, ".markCard_skip", true);
    alu_binary_imm_reg(OpndSize_32, shr_opc, GC_CARD_SHIFT, tgtAddrReg, targetPhysical);
    move_reg_to_mem_disp_scale(OpndSize_8, scratchReg, isPhysical, scratchReg, isPhysical, 0, tgtAddrReg, targetPhysical, 1);
-   insertLabel(".markCard_skip", true);
+   if (insertLabel(".markCard_skip", true) == -1) {
+       return;
+   }
 }
 
 void markCard_notNull(int tgtAddrReg, int scratchReg, bool isPhysical) {
@@ -562,7 +566,8 @@ int iget_iput_common_nohelper(u2 referenceIndex, InstanceAccess flag, u2 vA,
     move_imm_to_reg(OpndSize_32, referenceIndex, PhysicalReg_EAX, true);
     call_helper_API(".inst_field_resolve");
     transferToState(1);
-    insertLabel(".iget_iput_resolved", true);
+    if (insertLabel(".iget_iput_resolved", true) == -1)
+        return -1;
 #else
 #ifdef WITH_JIT_INLINING
     const Method *method =
@@ -905,7 +910,8 @@ int sget_sput_common(StaticAccess flag, u2 vA, u2 referenceIndex, bool isObj,
         export_pc(); //use %edx
         call_helper_API(".static_field_resolve");
         transferToState(1);
-        insertLabel(".sget_sput_resolved", true);
+        if (insertLabel(".sget_sput_resolved", true) == -1)
+            return -1;
 #else
 #ifdef WITH_JIT_INLINING
         const Method *method =
@@ -918,15 +924,17 @@ int sget_sput_common(StaticAccess flag, u2 vA, u2 referenceIndex, bool isObj,
               (currentMethod->clazz->pDvmDex->pResFields[referenceIndex]);
 #endif
 
-    /* Usually, fieldPtr should not be null. The interpreter should resolve
-     * it before we come here, or not allow this opcode in a trace. However,
-     * we can be in a loop trace and this opcode might have been picked up
-     * by exhaustTrace. Sending a -1 here will terminate the loop formation
-     * and fall back to normal trace, which will not have this opcode.
-     */
-    if (!fieldPtr) {
-        return -1;
-    }
+        /* Usually, fieldPtr should not be null. The interpreter should resolve
+         * it before we come here, or not allow this opcode in a trace. However,
+         * we can be in a loop trace and this opcode might have been picked up
+         * by exhaustTrace. Sending a -1 here will terminate the loop formation
+         * and fall back to normal trace, which will not have this opcode.
+         */
+        if (!fieldPtr) {
+            ALOGE("JIT_ERROR: Unresolved fieldPtr at sget_sput_common");
+            SET_JIT_ERROR(kJitErrorUnresolvedField);
+            return -1;
+        }
 
     move_imm_to_reg(OpndSize_32, (int)fieldPtr, PhysicalReg_EAX, true);
 #endif
diff --git a/vm/compiler/codegen/x86/LowerHelper.cpp b/vm/compiler/codegen/x86/LowerHelper.cpp
index bb07d4a..3438390 100644
--- a/vm/compiler/codegen/x86/LowerHelper.cpp
+++ b/vm/compiler/codegen/x86/LowerHelper.cpp
@@ -255,9 +255,14 @@ LowOpMem* lower_mem(Mnemonic m, AtomOpCode m2, OpndSize size, int disp,
         stream = encoder_mem(m, size, disp, base_reg, isBasePhysical, stream);
         return NULL;
     }
-    if (!isBasePhysical)
-        dvmAbort();
+
+    if (!isBasePhysical) {
+        ALOGE("JIT_ERROR: Base register not physical in lower_mem");
+        SET_JIT_ERROR(kJitErrorInsScheduling);
+        return NULL;
+    }
     LowOpMem* op = singletonPtr<Scheduler>()->allocateNewEmptyLIR<LowOpMem>();
+
     op->opCode = m;
     op->opCode2 = m2;
     op->opndSrc.size = size;
@@ -294,9 +299,14 @@ LowOpReg* lower_reg(Mnemonic m, AtomOpCode m2, OpndSize size, int reg,
         stream = encoder_reg(m, size, reg, isPhysical, type, stream);
         return NULL;
     }
-    if (!isPhysical)
-        dvmAbort();
+
+    if (!isPhysical) {
+        ALOGE("JIT_ERROR: Register not physical at lower_reg");
+        SET_JIT_ERROR(kJitErrorInsScheduling);
+        return NULL;
+    }
     LowOpReg* op = singletonPtr<Scheduler>()->allocateNewEmptyLIR<LowOpReg>();
+
     op->opCode = m;
     op->opCode2 = m2;
     op->opndSrc.size = size;
@@ -366,10 +376,14 @@ LowOpRegReg* lower_reg_to_reg(Mnemonic m, AtomOpCode m2, OpndSize size, int regS
         return NULL;
     }
 
-    if (!isPhysical && !isPhysical2)
-        dvmAbort();
+    if (!isPhysical && !isPhysical2) {
+        ALOGE("JIT_ERROR: Registers not physical at lower_reg_to_reg");
+        SET_JIT_ERROR(kJitErrorInsScheduling);
+        return NULL;
+    }
 
     LowOpRegReg* op = singletonPtr<Scheduler>()->allocateNewEmptyLIR<LowOpRegReg>();
+
     op->opCode = m;
     op->opCode2 = m2;
     op->opndDest.size = overridden_size;
@@ -494,9 +508,14 @@ LowOpMemReg* lower_mem_to_reg(Mnemonic m, AtomOpCode m2, OpndSize size, int disp
                 overridden_size, reg, isPhysical, overridden_type, stream);
         return NULL;
     }
-    if (!isBasePhysical && !isPhysical)
-        dvmAbort();
+
+    if (!isBasePhysical && !isPhysical) {
+        ALOGE("JIT_ERROR: Base register or operand register not physical in lower_mem_to_reg");
+        SET_JIT_ERROR(kJitErrorInsScheduling);
+        return NULL;
+    }
     LowOpMemReg* op = singletonPtr<Scheduler>()->allocateNewEmptyLIR<LowOpMemReg>();
+
     op->opCode = m;
     op->opCode2 = m2;
     op->opndDest.size = overridden_size;
@@ -670,9 +689,14 @@ LowOpMemReg* lower_mem_scale_to_reg(Mnemonic m, OpndSize size, int base_reg,
                 isPhysical, overridden_type, stream);
         return NULL;
     }
-    if (!isBasePhysical && !isIndexPhysical && !isPhysical)
-        dvmAbort();
+
+    if (!isBasePhysical && !isIndexPhysical && !isPhysical) {
+        ALOGE("JIT_ERROR: Base, index or operand register not physical at lower_mem_scale_to_reg");
+        SET_JIT_ERROR(kJitErrorInsScheduling);
+        return NULL;
+    }
     LowOpMemReg* op = singletonPtr<Scheduler>()->allocateNewEmptyLIR<LowOpMemReg>();
+
     op->opCode = m;
     op->opCode2 = ATOM_NORMAL;
     op->opndDest.size = overridden_size;
@@ -732,9 +756,14 @@ LowOpRegMem* lower_reg_to_mem_scale(Mnemonic m, OpndSize size, int reg,
                 stream);
         return NULL;
     }
-    if (!isBasePhysical && !isIndexPhysical && !isPhysical)
-        dvmAbort();
+
+    if (!isBasePhysical && !isIndexPhysical && !isPhysical) {
+        ALOGE("JIT_ERROR: Base, index or operand register not physical in lower_reg_to_mem_scale");
+        SET_JIT_ERROR(kJitErrorInsScheduling);
+        return NULL;
+    }
     LowOpRegMem* op = singletonPtr<Scheduler>()->allocateNewEmptyLIR<LowOpRegMem>();
+
     op->opCode = m;
     op->opCode2 = ATOM_NORMAL;
     op->opndDest.size = size;
@@ -786,9 +815,14 @@ LowOpRegMem* lower_reg_to_mem(Mnemonic m, AtomOpCode m2, OpndSize size, int reg,
                 isBasePhysical, type, stream);
         return NULL;
     }
-    if (!isBasePhysical && !isPhysical)
-        dvmAbort();
+
+    if (!isBasePhysical && !isPhysical) {
+        ALOGE("JIT_ERROR: Base or operand register not physical in lower_reg_to_mem");
+        SET_JIT_ERROR(kJitErrorInsScheduling);
+        return NULL;
+    }
     LowOpRegMem* op = singletonPtr<Scheduler>()->allocateNewEmptyLIR<LowOpRegMem>();
+
     op->opCode = m;
     op->opCode2 = m2;
     op->opndDest.size = size;
@@ -850,9 +884,14 @@ LowOpImmReg* lower_imm_to_reg(Mnemonic m, AtomOpCode m2, OpndSize size, int imm,
         stream = encoder_imm_reg(m, size, imm, reg, isPhysical, type, stream);
         return NULL;
     }
-    if (!isPhysical)
-        dvmAbort();
+
+    if (!isPhysical) {
+        ALOGE("JIT_ERROR: Operand register not physical in lower_imm_to_reg");
+        SET_JIT_ERROR(kJitErrorInsScheduling);
+        return NULL;
+    }
     LowOpImmReg* op = singletonPtr<Scheduler>()->allocateNewEmptyLIR<LowOpImmReg>();
+
     op->opCode = m;
     op->opCode2 = m2;
     op->opndDest.size = size;
@@ -899,9 +938,14 @@ LowOpImmMem* lower_imm_to_mem(Mnemonic m, AtomOpCode m2, OpndSize size, int imm,
                 stream);
         return NULL;
     }
-    if (!isBasePhysical)
-        dvmAbort();
+
+    if (!isBasePhysical) {
+        ALOGE("JIT_ERROR: Base register not physical in lower_imm_to_mem");
+        SET_JIT_ERROR(kJitErrorInsScheduling);
+        return NULL;
+    }
     LowOpImmMem* op = singletonPtr<Scheduler>()->allocateNewEmptyLIR<LowOpImmMem>();
+
     op->opCode = m;
     op->opCode2 = m2;
     op->opndDest.size = size;
@@ -959,9 +1003,14 @@ LowOpRegMem* lower_fp_to_mem(Mnemonic m, AtomOpCode m2, OpndSize size, int reg,
                 stream);
         return NULL;
     }
-    if (!isBasePhysical)
-        dvmAbort();
+
+    if (!isBasePhysical) {
+        ALOGE("JIT_ERROR: Base register not physical in lower_fp_to_mem");
+        SET_JIT_ERROR(kJitErrorInsScheduling);
+        return NULL;
+    }
     LowOpRegMem* op = singletonPtr<Scheduler>()->allocateNewEmptyLIR<LowOpRegMem>();
+
     op->opCode = m;
     op->opCode2 = m2;
     op->opndDest.size = size;
@@ -1005,9 +1054,15 @@ LowOpMemReg* lower_mem_to_fp(Mnemonic m, AtomOpCode m2, OpndSize size, int disp,
                 stream);
         return NULL;
     }
-    if (!isBasePhysical)
-        dvmAbort();
+
+    if (!isBasePhysical) {
+        ALOGE("JIT_ERROR: Base register not physical in lower_mem_to_fp");
+        SET_JIT_ERROR(kJitErrorInsScheduling);
+        return NULL;
+    }
+
     LowOpMemReg* op = singletonPtr<Scheduler>()->allocateNewEmptyLIR<LowOpMemReg>();
+
     op->opCode = m;
     op->opCode2 = m2;
     op->opndDest.size = size;
@@ -1159,7 +1214,7 @@ void compare_VR_reg_all(OpndSize size,
         if(isConst == 3) {
             if(m == Mnemonic_COMISS) {
 #ifdef DEBUG_NCG_O1
-                LOGI("VR is const and SS in compare_VR_reg");
+                ALOGI("VR is const and SS in compare_VR_reg");
 #endif
                 dumpImmToMem(vA, OpndSize_32, tmpValue[0]);
                 //dumpImmToMem(vA+1, OpndSize_32, 0); //CHECK necessary? will overwrite vA+1!!!
@@ -1168,14 +1223,14 @@ void compare_VR_reg_all(OpndSize size,
             }
             else if(size != OpndSize_64) {
 #ifdef DEBUG_NCG_O1
-                LOGI("VR is const and 32 bits in compare_VR_reg");
+                ALOGI("VR is const and 32 bits in compare_VR_reg");
 #endif
                 dump_imm_reg(m, ATOM_NORMAL, size, tmpValue[0], reg, isPhysical, pType, false);
                 return;
             }
             else if(size == OpndSize_64) {
 #ifdef DEBUG_NCG_O1
-                LOGI("VR is const and 64 bits in compare_VR_reg");
+                ALOGI("VR is const and 64 bits in compare_VR_reg");
 #endif
                 dumpImmToMem(vA, OpndSize_32, tmpValue[0]);
                 dumpImmToMem(vA+1, OpndSize_32, tmpValue[1]);
@@ -1232,13 +1287,13 @@ void load_fp_stack_VR_all(OpndSize size, int vB, Mnemonic m) {
         if(isConst > 0) {
             if(size != OpndSize_64) {
 #ifdef DEBUG_NCG_O1
-                LOGI("VR is const and 32 bits in load_fp_stack");
+                ALOGI("VR is const and 32 bits in load_fp_stack");
 #endif
                 dumpImmToMem(vB, OpndSize_32, tmpValue[0]);
             }
             else {
 #ifdef DEBUG_NCG_O1
-                LOGI("VR is const and 64 bits in load_fp_stack_VR");
+                ALOGI("VR is const and 64 bits in load_fp_stack_VR");
 #endif
                 if(isConst == 1 || isConst == 3) dumpImmToMem(vB, OpndSize_32, tmpValue[0]);
                 if(isConst == 2 || isConst == 3) dumpImmToMem(vB+1, OpndSize_32, tmpValue[1]);
@@ -1321,7 +1376,9 @@ void fpu_VR(ALU_Opcode opc, OpndSize size, int vA) {
             }
         }
         if(!isInMemory(vA, size)) {
-            ALOGE("fpu_VR");
+            ALOGE("JIT_ERROR: VR not in memory for FPU operation");
+            SET_JIT_ERROR(kJitErrorRegAllocFailed);
+            return;
         }
         dump_mem_fp(m, ATOM_NORMAL_ALU, size, 4*vA, PhysicalReg_FP, true, MemoryAccess_VR, vA, 0);
     } else {
@@ -1364,7 +1421,11 @@ void compare_imm_VR(OpndSize size, int imm,
              int vA) {
     Mnemonic m = Mnemonic_CMP;
     if(gDvm.executionMode == kExecutionModeNcgO1) {
-        if(size != OpndSize_32) ALOGE("only 32 bits supported in compare_imm_VR");
+        if(size != OpndSize_32) {
+            ALOGE("JIT_ERROR: Only 32 bits supported in compare_imm_VR");
+            SET_JIT_ERROR(kJitErrorRegAllocFailed);
+            return;
+        }
         int tmpValue[2];
         int isConst = isVirtualRegConstant(vA, getTypeFromIntSize(size), tmpValue, false/*updateRefCount*/);
         if(isConst > 0) {
@@ -1863,7 +1924,11 @@ void move_chain_to_mem(OpndSize size, int imm,
 void move_imm_to_mem(OpndSize size, int imm,
                       int disp, int base_reg, bool isBasePhysical) {
     assert(size != OpndSize_64);
-    if(size == OpndSize_64) ALOGE("move_imm_to_mem with 64 bits");
+    if(size == OpndSize_64) {
+        ALOGE("JIT_ERROR: Trying to move 64-bit imm to memory");
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
+        return;
+    }
     dump_imm_mem(Mnemonic_MOV, ATOM_NORMAL, size, imm, disp, base_reg, isBasePhysical, MemoryAccess_Unknown, -1, false);
 }
 //! set a VR to an immediate
@@ -1871,7 +1936,11 @@ void move_imm_to_mem(OpndSize size, int imm,
 //!
 void set_VR_to_imm(u2 vA, OpndSize size, int imm) {
     assert(size != OpndSize_64);
-    if(size == OpndSize_64) ALOGE("move_imm_to_mem with 64 bits");
+    if(size == OpndSize_64) {
+        ALOGE("JIT_ERROR: Trying to set VR with 64-bit imm");
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
+        return;
+    }
     Mnemonic m = (size == OpndSize_64) ? Mnemonic_MOVQ : Mnemonic_MOV;
     if(gDvm.executionMode == kExecutionModeNcgO1) {
         int regAll = checkVirtualReg(vA, getTypeFromIntSize(size), 0);
@@ -1903,7 +1972,11 @@ void set_VR_to_imm_noupdateref(LowOp* op, u2 vA, OpndSize size, int imm) {
 //! Do not allocate a physical register for the VR
 void set_VR_to_imm_noalloc(u2 vA, OpndSize size, int imm) {
     assert(size != OpndSize_64);
-    if(size == OpndSize_64) ALOGE("move_imm_to_mem with 64 bits");
+    if(size == OpndSize_64) {
+        ALOGE("JIT_ERROR: Trying to move 64-bit imm to memory (noalloc)");
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
+        return;
+    }
     Mnemonic m = (size == OpndSize_64) ? Mnemonic_MOVQ : Mnemonic_MOV;
     dump_imm_mem_noalloc(m, size, imm, 4*vA, PhysicalReg_FP, true, MemoryAccess_VR, vA);
 }
@@ -1917,7 +1990,11 @@ void move_chain_to_reg(OpndSize size, int imm, int reg, bool isPhysical) {
 //!
 void move_imm_to_reg(OpndSize size, int imm, int reg, bool isPhysical) {
     assert(size != OpndSize_64);
-    if(size == OpndSize_64) ALOGE("move_imm_to_reg with 64 bits");
+    if(size == OpndSize_64) {
+        ALOGE("JIT_ERROR: Trying to move 64-bit imm to register");
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
+        return;
+    }
     Mnemonic m = Mnemonic_MOV;
     dump_imm_reg(m, ATOM_NORMAL, size, imm, reg, isPhysical, LowOpndRegType_gp, false);
 }
@@ -1926,7 +2003,11 @@ void move_imm_to_reg(OpndSize size, int imm, int reg, bool isPhysical) {
 //! The operand is already allocated
 void move_imm_to_reg_noalloc(OpndSize size, int imm, int reg, bool isPhysical) {
     assert(size != OpndSize_64);
-    if(size == OpndSize_64) ALOGE("move_imm_to_reg with 64 bits");
+    if(size == OpndSize_64) {
+        ALOGE("JIT_ERROR: Trying to move 64-bit imm to register (noalloc)");
+        SET_JIT_ERROR(kJitErrorRegAllocFailed);
+        return;
+    }
     Mnemonic m = Mnemonic_MOV;
     dump_imm_reg_noalloc(m, size, imm, reg, isPhysical, LowOpndRegType_gp);
 }
@@ -2160,9 +2241,15 @@ int get_currentpc(int reg, bool isPhysical) {
     move_mem_to_reg(OpndSize_32, -sizeofStackSaveArea+offStackSaveArea_localRefTop, PhysicalReg_FP, true, reg, isPhysical);
     return 1;
 }
-//!generate native code to perform null check
 
-//!This function does not export PC
+//! \brief generate native code to perform null check
+//!
+//! \details This function does not export PC
+//! \param reg
+//! \param isPhysical is the reg is physical
+//! \param vr the vr corresponding to reg
+//!
+//! \return -1 if error happened, 0 otherwise
 int simpleNullCheck(int reg, bool isPhysical, int vr) {
     if(isVRNullCheck(vr, OpndSize_32)) {
         updateRefCount2(reg, LowOpndRegType_gp, isPhysical);
@@ -2171,7 +2258,9 @@ int simpleNullCheck(int reg, bool isPhysical, int vr) {
     }
     compare_imm_reg(OpndSize_32, 0, reg, isPhysical);
     conditional_jump_global_API(Condition_E, "common_errNullObject", false);
-    setVRNullCheck(vr, OpndSize_32);
+    int retCode = setVRNullCheck(vr, OpndSize_32);
+    if (retCode < 0)
+        return retCode;
     return 0;
 }
 
@@ -2212,6 +2301,7 @@ int boundCheck(int vr_array, int reg_array, bool isPhysical_array,
  */
 int nullCheck(int reg, bool isPhysical, int exceptionNum, int vr) {
     const char * errorName = "common_errNullObject";
+    int retCode = 0;
 
     //nullCheck optimization is available in O1 mode only
     if(gDvm.executionMode == kExecutionModeNcgO1 && isVRNullCheck(vr, OpndSize_32)) {
@@ -2263,7 +2353,9 @@ int nullCheck(int reg, bool isPhysical, int exceptionNum, int vr) {
 
     if(gDvm.executionMode == kExecutionModeNcgO1) {
         goToState(exceptionNum);
-        setVRNullCheck(vr, OpndSize_32);
+        retCode = setVRNullCheck(vr, OpndSize_32);
+        if (retCode < 0)
+            return retCode;
     }
 
     return 0;
@@ -2336,6 +2428,7 @@ int get_self_pointer(int reg, bool isPhysical) {
 
 //!It uses two scratch registers
 int get_res_strings(int reg, bool isPhysical) {
+    int retCode = 0;
     //if spill_loc_index > 0 || reg != NULL, use registerAlloc
     if(isGlueHandled(PhysicalReg_GLUE_DVMDEX)) {
         //if spill_loc_index > 0
@@ -2358,12 +2451,15 @@ int get_res_strings(int reg, bool isPhysical) {
             get_self_pointer(C_SCRATCH_1, isScratchPhysical);
             move_mem_to_reg(OpndSize_32, offsetof(Thread, interpSave.methodClassDex), C_SCRATCH_1, isScratchPhysical, C_SCRATCH_2, isScratchPhysical);
             //glue is not in a physical reg nor in a spilled location
-            updateGlue(C_SCRATCH_2, isScratchPhysical, PhysicalReg_GLUE_DVMDEX); //spill_loc_index is -1, set physicalReg
+            retCode = updateGlue(C_SCRATCH_2, isScratchPhysical, PhysicalReg_GLUE_DVMDEX); //spill_loc_index is -1, set physicalReg
+            if (retCode < 0)
+                return retCode;
             move_mem_to_reg(OpndSize_32, offDvmDex_pResStrings, C_SCRATCH_2, isScratchPhysical, reg, isPhysical);
         }
     return 0;
 }
 int get_res_classes(int reg, bool isPhysical) {
+    int retCode = 0;
     //if spill_loc_index > 0 || reg != NULL, use registerAlloc
     if(isGlueHandled(PhysicalReg_GLUE_DVMDEX)) {
         //if spill_loc_index > 0
@@ -2380,7 +2476,9 @@ int get_res_classes(int reg, bool isPhysical) {
             get_self_pointer(C_SCRATCH_1, isScratchPhysical);
             move_mem_to_reg(OpndSize_32, offsetof(Thread, interpSave.methodClassDex), C_SCRATCH_1, isScratchPhysical, C_SCRATCH_2, isScratchPhysical);
             //glue is not in a physical reg nor in a spilled location
-            updateGlue(C_SCRATCH_2, isScratchPhysical, PhysicalReg_GLUE_DVMDEX); //spill_loc_index is -1, set physicalReg
+            retCode = updateGlue(C_SCRATCH_2, isScratchPhysical, PhysicalReg_GLUE_DVMDEX); //spill_loc_index is -1, set physicalReg
+            if (retCode < 0)
+                return retCode;
             move_mem_to_reg(OpndSize_32, offDvmDex_pResClasses, C_SCRATCH_2, isScratchPhysical, reg, isPhysical);
         }
     return 0;
@@ -2389,6 +2487,7 @@ int get_res_classes(int reg, bool isPhysical) {
 
 //!It uses two scratch registers
 int get_res_fields(int reg, bool isPhysical) {
+    int retCode = 0;
     //if spill_loc_index > 0 || reg != NULL, use registerAlloc
     if(isGlueHandled(PhysicalReg_GLUE_DVMDEX)) {
         //if spill_loc_index > 0
@@ -2405,7 +2504,9 @@ int get_res_fields(int reg, bool isPhysical) {
             get_self_pointer(C_SCRATCH_1, isScratchPhysical);
             move_mem_to_reg(OpndSize_32, offsetof(Thread, interpSave.methodClassDex), C_SCRATCH_1, isScratchPhysical, C_SCRATCH_2, isScratchPhysical);
             //glue is not in a physical reg nor in a spilled location
-            updateGlue(C_SCRATCH_2, isScratchPhysical, PhysicalReg_GLUE_DVMDEX); //spill_loc_index is -1, set physicalReg
+            retCode = updateGlue(C_SCRATCH_2, isScratchPhysical, PhysicalReg_GLUE_DVMDEX); //spill_loc_index is -1, set physicalReg
+            if (retCode < 0)
+                return retCode;
             move_mem_to_reg(OpndSize_32, offDvmDex_pResFields, C_SCRATCH_2, isScratchPhysical, reg, isPhysical);
         }
     return 0;
@@ -2414,6 +2515,7 @@ int get_res_fields(int reg, bool isPhysical) {
 
 //!It uses two scratch registers
 int get_res_methods(int reg, bool isPhysical) {
+    int retCode = 0;
     //if spill_loc_index > 0 || reg != NULL, use registerAlloc
     if(isGlueHandled(PhysicalReg_GLUE_DVMDEX)) {
         //if spill_loc_index > 0
@@ -2430,7 +2532,9 @@ int get_res_methods(int reg, bool isPhysical) {
             get_self_pointer(C_SCRATCH_1, isScratchPhysical);
             move_mem_to_reg(OpndSize_32, offsetof(Thread, interpSave.methodClassDex), C_SCRATCH_1, isScratchPhysical, C_SCRATCH_2, isScratchPhysical);
             //glue is not in a physical reg nor in a spilled location
-            updateGlue(C_SCRATCH_2, isScratchPhysical, PhysicalReg_GLUE_DVMDEX); //spill_loc_index is -1, set physicalReg
+            retCode = updateGlue(C_SCRATCH_2, isScratchPhysical, PhysicalReg_GLUE_DVMDEX); //spill_loc_index is -1, set physicalReg
+            if (retCode < 0)
+                return retCode;
             move_mem_to_reg(OpndSize_32, offDvmDex_pResMethods, C_SCRATCH_2, isScratchPhysical, reg, isPhysical);
         }
     return 0;
@@ -2465,6 +2569,7 @@ int set_glue_method(int reg, bool isPhysical) {
 
 //!It uses one scratch register
 int get_glue_dvmdex(int reg, bool isPhysical) {
+    int retCode = 0;
     //if spill_loc_index > 0 || reg != NULL, use registerAlloc
     if(isGlueHandled(PhysicalReg_GLUE_DVMDEX)) {
         //if spill_loc_index > 0
@@ -2482,7 +2587,9 @@ int get_glue_dvmdex(int reg, bool isPhysical) {
             get_self_pointer(C_SCRATCH_1, isScratchPhysical);
             move_mem_to_reg(OpndSize_32, offsetof(Thread, interpSave.methodClassDex), C_SCRATCH_1, isScratchPhysical, reg, isPhysical);
             //glue is not in a physical reg nor in a spilled location
-            updateGlue(reg, isPhysical, PhysicalReg_GLUE_DVMDEX); //spill_loc_index is -1, set physicalReg
+            retCode = updateGlue(reg, isPhysical, PhysicalReg_GLUE_DVMDEX); //spill_loc_index is -1, set physicalReg
+            if (retCode < 0)
+                return retCode;
         }
     return 0;
 }
@@ -3123,7 +3230,8 @@ The only register that is still live after this function is ebx
 int const_string_resolve() {
     scratchRegs[0] = PhysicalReg_ESI; scratchRegs[1] = PhysicalReg_EDX;
     scratchRegs[2] = PhysicalReg_Null; scratchRegs[3] = PhysicalReg_Null;
-    insertLabel(".const_string_resolve", false);
+    if (insertLabel(".const_string_resolve", false) == -1)
+        return -1;
     //method stored in glue structure as well as on the interpreted stack
     get_glue_method_class(P_GPR_2, true);
     load_effective_addr(-8, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
@@ -3151,7 +3259,8 @@ The only register that is still live after this function is ebx
 int resolve_class2(
            int startLR/*scratch register*/, bool isPhysical, int indexReg/*const pool index*/,
            bool indexPhysical, int thirdArg) {
-    insertLabel(".class_resolve", false);
+    if (insertLabel(".class_resolve", false) == -1)
+        return -1;
     scratchRegs[0] = PhysicalReg_ESI; scratchRegs[1] = PhysicalReg_EDX;
     scratchRegs[2] = PhysicalReg_Null; scratchRegs[3] = PhysicalReg_Null;
 
@@ -3184,12 +3293,18 @@ int resolve_method2(
             int startLR/*logical register index*/, bool isPhysical, int indexReg/*const pool index*/,
             bool indexPhysical,
             int thirdArg/*VIRTUAL*/) {
-    if(thirdArg == METHOD_VIRTUAL)
-        insertLabel(".virtual_method_resolve", false);
-    else if(thirdArg == METHOD_DIRECT)
-        insertLabel(".direct_method_resolve", false);
-    else if(thirdArg == METHOD_STATIC)
-        insertLabel(".static_method_resolve", false);
+    if(thirdArg == METHOD_VIRTUAL) {
+        if (insertLabel(".virtual_method_resolve", false) == -1)
+            return -1;
+    }
+    else if(thirdArg == METHOD_DIRECT) {
+        if (insertLabel(".direct_method_resolve", false) == -1)
+            return -1;
+    }
+    else if(thirdArg == METHOD_STATIC) {
+        if (insertLabel(".static_method_resolve", false) == -1)
+            return -1;
+    }
 
     load_effective_addr(-12, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
     move_reg_to_mem(OpndSize_32, indexReg, indexPhysical, 4, PhysicalReg_ESP, true);
@@ -3222,7 +3337,8 @@ The only register that is still live after this function is ebx
 int resolve_inst_field2(
             int startLR/*logical register index*/, bool isPhysical,
             int indexReg/*const pool index*/, bool indexPhysical) {
-    insertLabel(".inst_field_resolve", false);
+    if (insertLabel(".inst_field_resolve", false) == -1)
+        return -1;
     scratchRegs[0] = PhysicalReg_ESI; scratchRegs[1] = PhysicalReg_EDX;
     scratchRegs[2] = PhysicalReg_Null; scratchRegs[3] = PhysicalReg_Null;
 
@@ -3253,7 +3369,8 @@ The only register that is still live after this function is ebx
 int resolve_static_field2(
               int startLR/*logical register index*/, bool isPhysical, int indexReg/*const pool index*/,
               bool indexPhysical) {
-    insertLabel(".static_field_resolve", false);
+    if (insertLabel(".static_field_resolve", false) == -1)
+        return -1;
     scratchRegs[0] = PhysicalReg_ESI; scratchRegs[1] = PhysicalReg_EDX;
     scratchRegs[2] = PhysicalReg_Null; scratchRegs[3] = PhysicalReg_Null;
 
diff --git a/vm/compiler/codegen/x86/LowerInvoke.cpp b/vm/compiler/codegen/x86/LowerInvoke.cpp
index cfb0fe7..79f2cd7 100644
--- a/vm/compiler/codegen/x86/LowerInvoke.cpp
+++ b/vm/compiler/codegen/x86/LowerInvoke.cpp
@@ -177,7 +177,8 @@ int common_invoke_super(bool isRange, u2 tmp,
         move_imm_to_reg(OpndSize_32, tmp, PhysicalReg_EAX, true);
         call(".virtual_method_resolve"); //in %eax
         transferToState(1);
-        insertLabel(".LinvokeSuper_resolved", true);
+        if (insertLabel(".LinvokeSuper_resolved", true) == -1)
+            return -1;
         scratchRegs[0] = PhysicalReg_SCRATCH_3; scratchRegs[1] = PhysicalReg_SCRATCH_4;
         get_glue_method_class(6, false);
         move_mem_to_reg(OpndSize_32, offClassObject_super, 6, false, 7, false);
@@ -211,11 +212,11 @@ int common_invoke_super(bool isRange, u2 tmp,
 #undef PP_GPR_3
 #undef PP_GPR_4
 
-//! helper function to handle no such method error
-
-//!
-int invoke_super_nsm() {
-    insertLabel(".invoke_super_nsm", false);
+//! \brief helper function to handle no such method error
+//! \return -1 if error, 0 otherwise
+int invoke_super_nsm(void) {
+    if (insertLabel(".invoke_super_nsm", false) == -1)
+        return -1;
     //NOTE: it seems that the name in %edx is not used in common_errNoSuchMethod
     move_mem_to_reg(OpndSize_32, offMethod_name, PhysicalReg_EAX, true, PhysicalReg_EDX, true); //method name
     unconditional_jump("common_errNoSuchMethod", false);
@@ -263,7 +264,8 @@ int common_invoke_direct(bool isRange, u2 tmp, u2 vD, const MIR *mir)
         call_helper_API(".direct_method_resolve"); //in %eax
         move_reg_to_reg(OpndSize_32, PhysicalReg_EAX, true, PhysicalReg_ECX, true);
         transferToState(1);
-        insertLabel(".LinvokeDirect_resolved", true);
+        if (insertLabel(".LinvokeDirect_resolved", true) == -1)
+            return -1;
         const Method *calleeMethod = NULL;
 #else
         /* method is already resolved in trace-based JIT */
@@ -319,7 +321,8 @@ int common_invoke_static(bool isRange, u2 tmp,
         call(".static_method_resolve"); //in %eax
         move_reg_to_reg(OpndSize_32, PhysicalReg_EAX, true, PhysicalReg_ECX, true);
         transferToState(1);
-        insertLabel(".LinvokeStatic_resolved", true);
+        if (insertLabel(".LinvokeStatic_resolved", true) == -1)
+            return -1;
         const Method *calleeMethod = NULL;
 #else
         /* method is already resolved in trace-based JIT */
@@ -823,7 +826,8 @@ int common_invokeMethodRange_noJmp(const DecodedInstruction &decodedInst) {
         load_effective_addr(4*vD, PhysicalReg_FP, true, 12, false);
         alu_binary_imm_reg(OpndSize_32, sub_opc, 4*count, 21, false);
         move_imm_to_reg(OpndSize_32, count, 13, false);
-        insertLabel(".invokeMethod_1", true); //if checkDup: will perform work from ShortWorklist
+        if (insertLabel(".invokeMethod_1", true) == -1) //if checkDup: will perform work from ShortWorklist
+            return -1;
         rememberState(1);
         move_mem_to_reg(OpndSize_32, 0, 12, false, 14, false);
         move_reg_to_mem(OpndSize_32, 14, false, 0, 21, false);
@@ -889,7 +893,7 @@ int unspill_reg(int reg, bool isPhysical) {
 }
 
 void generate_invokeNative(bool generateForNcg); //forward declaration
-void generate_stackOverflow(); //forward declaration
+int generate_stackOverflow(void); //forward declaration
 
 //! common code to invoke a method after all arguments are handled
 
@@ -908,17 +912,24 @@ int common_invokeArgsDone(ArgsDoneType form, bool isJitFull) {
 
     bool generateForNcg = false;
     if(form == ArgsDone_Full) {
-        if(isJitFull)
-            insertLabel(".invokeArgsDone_jit", false);
+        if(isJitFull){
+            if (insertLabel(".invokeArgsDone_jit", false) == -1)
+                return -1;
+        }
         else {
-            insertLabel(".invokeArgsDone", false);
+            if (insertLabel(".invokeArgsDone", false) == -1)
+                return -1;
             generateForNcg = true;
         }
     }
-    else if(form == ArgsDone_Normal)
-        insertLabel(".invokeArgsDone_normal", false);
-    else if(form == ArgsDone_Native)
-        insertLabel(".invokeArgsDone_native", false);
+    else if(form == ArgsDone_Normal){
+        if (insertLabel(".invokeArgsDone_normal", false) == -1)
+            return -1;
+    }
+    else if(form == ArgsDone_Native) {
+        if (insertLabel(".invokeArgsDone_native", false) == -1)
+            return -1;
+    }
     //%ecx: methodToCall
     movez_mem_to_reg(OpndSize_16, offMethod_registersSize, PhysicalReg_ECX, true, P_SCRATCH_1, true); //regSize
     scratchRegs[0] = PhysicalReg_EBX; scratchRegs[1] = PhysicalReg_ESI;
@@ -982,7 +993,8 @@ int common_invokeArgsDone(ArgsDoneType form, bool isJitFull) {
                             offStackSaveArea_returnAddr-sizeofStackSaveArea, PhysicalReg_FP, true);
     }
 
-    insertLabel(".invokeInterp", true);
+    if (insertLabel(".invokeInterp", true) == -1)
+        return -1;
     if(!generateForNcg) {
         bool callNoChain = false;
 #ifdef PREDICTED_CHAINING
@@ -1008,7 +1020,8 @@ int common_invokeArgsDone(ArgsDoneType form, bool isJitFull) {
     }
 
     if(form == ArgsDone_Full) generate_invokeNative(generateForNcg);
-    generate_stackOverflow();
+    if (generate_stackOverflow() == -1)
+        return -1;
 #if defined VTUNE_DALVIK
     if(gDvmJit.vtuneInfo != kVTuneInfoDisabled) {
         int endStreamPtr = (int)stream;
@@ -1023,7 +1036,8 @@ int common_invokeArgsDone(ArgsDoneType form, bool isJitFull) {
      with the interpreter or with JIT'ed code if chained
 */
 void generate_invokeNative(bool generateForNcg) {
-    insertLabel(".invokeNative", true);
+    if (insertLabel(".invokeNative", true) == -1)
+        return;
     //if(!generateForNcg)
     //    load_effective_addr(-8, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
     load_effective_addr(-28, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
@@ -1072,7 +1086,8 @@ void generate_invokeNative(bool generateForNcg) {
         conditional_jump(Condition_E, ".nativeToInterp", true);
         unconditional_jump_reg(P_SCRATCH_2, true);
         //if returnAddr is NULL, return to interpreter after executing the native method
-        insertLabel(".nativeToInterp", true);
+        if (insertLabel(".nativeToInterp", true) == -1)
+            return;
         //move rPC by 6 (3 bytecode units for INVOKE)
         alu_binary_imm_reg(OpndSize_32, add_opc, 6, PhysicalReg_EBX, true);
         scratchRegs[0] = PhysicalReg_EAX;
@@ -1085,8 +1100,9 @@ void generate_invokeNative(bool generateForNcg) {
     }
     return;
 }
-void generate_stackOverflow() {
-    insertLabel(".stackOverflow", true);
+int generate_stackOverflow() {
+    if (insertLabel(".stackOverflow", true) == -1)
+        return -1;
     //load_effective_addr(-8, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
     move_reg_to_mem(OpndSize_32, PhysicalReg_ECX, true, 4, PhysicalReg_ESP, true);
     get_self_pointer(P_GPR_1, true); //glue->self
@@ -1094,6 +1110,7 @@ void generate_stackOverflow() {
     call_dvmHandleStackOverflow();
     load_effective_addr(8, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
     unconditional_jump("common_exceptionThrown", false);
+    return 0;
 }
 #undef P_GPR_1
 #undef P_GPR_2
@@ -1149,7 +1166,8 @@ int op_execute_inline(const MIR * mir, bool isRange) {
             beforeCall("exception"); //dump GG, GL VRs
             unconditional_jump("common_errNullObject", false);
             goToState(1);
-            insertLabel(".do_inlined_string_length", true);
+            if (insertLabel(".do_inlined_string_length", true) == -1)
+                return -1;
             move_mem_to_reg(OpndSize_32, 0x14, 1, false, 2, false);
             get_self_pointer(3, false);
             move_reg_to_mem(OpndSize_32, 2, false, offsetof(Thread, interpSave.retval), 3, false);
@@ -1164,17 +1182,20 @@ int op_execute_inline(const MIR * mir, bool isRange) {
             beforeCall("exception"); //dump GG, GL VRs
             unconditional_jump("common_errNullObject", false);
             goToState(1);
-            insertLabel(".do_inlined_string_length", true);
+            if (insertLabel(".do_inlined_string_length", true) == -1)
+                return -1;
             compare_imm_mem(OpndSize_32, 0, 0x14, 1, false);
             conditional_jump(Condition_E, ".inlined_string_length_return_true",
                              true);
             get_self_pointer(2, false);
             move_imm_to_mem(OpndSize_32, 0, offsetof(Thread, interpSave.retval), 2, false);
             unconditional_jump(".inlined_string_length_done", true);
-            insertLabel(".inlined_string_length_return_true", true);
+            if (insertLabel(".inlined_string_length_return_true", true) == -1)
+                return -1;
             get_self_pointer(2, false);
             move_imm_to_mem(OpndSize_32, 1, offsetof(Thread, interpSave.retval), 2, false);
-            insertLabel(".inlined_string_length_done", true);
+            if (insertLabel(".inlined_string_length_done", true) == -1)
+                return -1;
             return 0;
         case INLINE_MATH_ABS_INT:
             get_virtual_reg(vC, OpndSize_32, 1, false);
@@ -1241,7 +1262,8 @@ int op_execute_inline(const MIR * mir, bool isRange) {
             beforeCall("exception");
             unconditional_jump("common_errNullObject", false);
             goToState(1);
-            insertLabel(".inlined_string_CharAt_arg_validate_1", true);
+            if (insertLabel(".inlined_string_CharAt_arg_validate_1", true) == -1)
+                return -1;
             get_virtual_reg(vD, OpndSize_32, 2, false);
             compare_mem_reg(OpndSize_32, 0x14, 1, false, 2, false);
             conditional_jump(Condition_L, ".inlined_string_CharAt_arg_validate_2", true);
@@ -1250,7 +1272,8 @@ int op_execute_inline(const MIR * mir, bool isRange) {
             beforeCall("exception");
             unconditional_jump("common_errStringIndexOutOfBounds", false);
             goToState(2);
-            insertLabel(".inlined_string_CharAt_arg_validate_2", true);
+            if (insertLabel(".inlined_string_CharAt_arg_validate_2", true) == -1)
+                return -1;
             compare_imm_reg(OpndSize_32, 0, 2, false);
             conditional_jump(Condition_NS, ".do_inlined_string_CharAt", true);
             rememberState(3);
@@ -1258,7 +1281,8 @@ int op_execute_inline(const MIR * mir, bool isRange) {
             beforeCall("exception");
             unconditional_jump("common_errStringIndexOutOfBounds", false);
             goToState(3);
-            insertLabel(".do_inlined_string_CharAt", true);
+            if (insertLabel(".do_inlined_string_CharAt", true) == -1)
+                return -1;
             alu_binary_mem_reg(OpndSize_32, add_opc, 0x10, 1, false, 2, false);
             move_mem_to_reg(OpndSize_32, 0x8, 1, false, 1, false);
             movez_mem_disp_scale_to_reg(OpndSize_16, 1, false, offsetof(ArrayObject, contents)/*disp*/, 2, false, 2, 2, false);
@@ -1281,7 +1305,8 @@ int op_execute_inline(const MIR * mir, bool isRange) {
             beforeCall("exception"); //dump GG, GL VRs
             unconditional_jump("common_errNullObject", false);
             goToState(1);
-            insertLabel(".do_inlined_string_fastIndexof", true);
+            if (insertLabel(".do_inlined_string_fastIndexof", true) == -1)
+                return -1;
             move_mem_to_reg(OpndSize_32, 0x14, 1, false, 4, false);
             move_mem_to_reg(OpndSize_32, 0x8, 1, false, 5, false);
             move_mem_to_reg(OpndSize_32, 0x10, 1, false, 6, false);
@@ -1302,7 +1327,8 @@ int op_execute_inline(const MIR * mir, bool isRange) {
             load_effective_addr(0x1, 1, false, 3, false);
             load_effective_addr_scale(5, false, 3, false, 2, 5, false);
             unconditional_jump(".do_inlined_string_fastIndexof_iter", true);
-            insertLabel(".do_inlined_string_fastIndexof_ch_cmp", true);
+            if (insertLabel(".do_inlined_string_fastIndexof_ch_cmp", true) == -1)
+                return -1;
             if(gDvm.executionMode == kExecutionModeNcgO1) {
                 rememberState(1);
             }
@@ -1312,7 +1338,8 @@ int op_execute_inline(const MIR * mir, bool isRange) {
             conditional_jump(Condition_E, ".do_inlined_string_fastIndexof_exit",
                              true);
             load_effective_addr(0x1, 3, false, 3, false);
-            insertLabel(".do_inlined_string_fastIndexof_iter", true);
+            if (insertLabel(".do_inlined_string_fastIndexof_iter", true) == -1)
+                return -1;
             compare_reg_reg(4, false, 3, false);
             move_reg_to_reg(OpndSize_32, 3, false, 1, false);
             if(gDvm.executionMode == kExecutionModeNcgO1) {
@@ -1320,9 +1347,11 @@ int op_execute_inline(const MIR * mir, bool isRange) {
             }
             conditional_jump(Condition_NE,
                              ".do_inlined_string_fastIndexof_ch_cmp", true);
-            insertLabel(".do_inlined_string_fastIndexof_exitfalse", true);
+            if (insertLabel(".do_inlined_string_fastIndexof_exitfalse", true) == -1)
+                return -1;
             move_imm_to_reg(OpndSize_32, 0xffffffff, 1,  false);
-            insertLabel(".do_inlined_string_fastIndexof_exit", true);
+            if (insertLabel(".do_inlined_string_fastIndexof_exit", true) == -1)
+                return -1;
             get_self_pointer(7, false);
             move_reg_to_mem(OpndSize_32, 1, false, offsetof(Thread, interpSave.retval), 7, false);
             return 0;
@@ -1385,7 +1414,8 @@ int op_execute_inline(const MIR * mir, bool isRange) {
     //jump to dvmJitToExceptionThrown
     scratchRegs[0] = PhysicalReg_SCRATCH_1;
     jumpToExceptionThrown(1/*exception number*/);
-    insertLabel(".execute_inline_done", true);
+    if (insertLabel(".execute_inline_done", true) == -1)
+        return -1;
     return 0;
 }
 #undef P_GPR_1
@@ -1589,7 +1619,8 @@ void predicted_chain_interface_O0(u2 tmp) {
     jumpToExceptionThrown(1/*exception number*/);
 
     /* the interface method is found */
-    insertLabel(".find_interface_done", true);
+    if (insertLabel(".find_interface_done", true) == -1)
+        return;
     /* reduce counter in chaining cell by 1 */
     move_mem_to_reg(OpndSize_32, offChainingCell_counter, P_GPR_1, true, P_SCRATCH_2, true); //counter
     alu_binary_imm_reg(OpndSize_32, sub_opc, 0x1, P_SCRATCH_2, true);
@@ -1612,7 +1643,8 @@ void predicted_chain_interface_O0(u2 tmp) {
     scratchRegs[0] = PhysicalReg_EAX;
     call_dvmJitToPatchPredictedChain(); //inputs: method, unused, predictedChainCell, clazz
     load_effective_addr(16, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
-    insertLabel(".skipPrediction", true);
+    if (insertLabel(".skipPrediction", true) == -1)
+        return;
     move_reg_to_reg(OpndSize_32, PhysicalReg_EAX, true, PhysicalReg_ECX, true);
 }
 
@@ -1639,7 +1671,8 @@ void predicted_chain_interface_O1(u2 tmp) {
 
     goToState(3);
     /* the interface method is found */
-    insertLabel(".find_interface_done", true);
+    if (insertLabel(".find_interface_done", true) == -1)
+        return;
 #if 1 //
     /* for gingerbread, counter is stored in glue structure
        if clazz is not initialized, set icRechainCount to 0, otherwise, reduce it by 1 */
@@ -1683,7 +1716,8 @@ void predicted_chain_interface_O1(u2 tmp) {
     load_effective_addr(16, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
     transferToState(4);
 
-    insertLabel(".skipPrediction", true);
+    if (insertLabel(".skipPrediction", true) == -1)
+        return;
     move_reg_to_reg(OpndSize_32, PhysicalReg_EAX, true, PhysicalReg_ECX, true);
 }
 
@@ -1719,7 +1753,8 @@ void predicted_chain_virtual_O0(u2 IMMC) {
 
     //callee method in %ecx for invoke virtual
     move_reg_to_reg(OpndSize_32, PhysicalReg_EAX, true, PhysicalReg_ECX, true);
-    insertLabel(".skipPrediction", true);
+    if (insertLabel(".skipPrediction", true) == -1)
+        return;
 }
 
 // 2 inputs: ChainingCell in temp 41, current class object in temp 40
@@ -1765,14 +1800,15 @@ void predicted_chain_virtual_O1(u2 IMMC) {
     move_reg_to_reg(OpndSize_32, PhysicalReg_EAX, true, PhysicalReg_ECX, true);
     transferToState(2);
 
-    insertLabel(".skipPrediction", true);
+    if (insertLabel(".skipPrediction", true) == -1)
+        return;
 }
 
 static int invokeChain_inst = 0;
 /* object "this" is in %ebx */
 void gen_predicted_chain_O0(bool isRange, u2 tmp, int IMMC, bool isInterface,
         int inputReg, const DecodedInstruction &decodedInst) {
-    LOGI("TODO predicted_chain_O0");
+    ALOGI("TODO predicted_chain_O0");
 
     /* get current class object */
     move_mem_to_reg(OpndSize_32, offObject_clazz, PhysicalReg_EBX, true,
@@ -1846,7 +1882,8 @@ void gen_predicted_chain_O0(bool isRange, u2 tmp, int IMMC, bool isInterface,
         common_invokeMethodNoRange(ArgsDone_Full, decodedInst);
     }
 
-    insertLabel(".invokeChain", true);
+    if (insertLabel(".invokeChain", true) == -1)
+        return;
 #ifdef DEBUG_CALL_STACK3
     move_imm_to_reg(OpndSize_32, 0xdddd, PhysicalReg_EBX, true);
     scratchRegs[0] = PhysicalReg_EAX;
@@ -1905,7 +1942,8 @@ void gen_predicted_chain_O1(bool isRange, u2 tmp, int IMMC, bool isInterface,
 
     common_invokeMethod_Jmp(ArgsDone_Full); //will touch %ecx
 
-    insertLabel(".invokeChain", true);
+    if (insertLabel(".invokeChain", true) == -1)
+        return;
     goToState(1);
     common_invokeMethod_Jmp(ArgsDone_Normal);
 }
diff --git a/vm/compiler/codegen/x86/LowerJump.cpp b/vm/compiler/codegen/x86/LowerJump.cpp
index e0f8282..61377c1 100644
--- a/vm/compiler/codegen/x86/LowerJump.cpp
+++ b/vm/compiler/codegen/x86/LowerJump.cpp
@@ -90,14 +90,16 @@ int updateJumpInst(char* jumpInst, OpndSize immSize, int relativeNCG) {
 #endif
     if(immSize == OpndSize_8) { //-128 to 127
         if(relativeNCG >= 128 || relativeNCG < -128) {
-            ALOGE("pre-allocated space for a forward jump is not big enough");
-            dvmAbort();
+            ALOGE("JIT_ERROR: Pre-allocated space for a forward jump is not big enough\n");
+            SET_JIT_ERROR(kJitErrorShortJumpOffset);
+            return -1;
         }
     }
     if(immSize == OpndSize_16) { //-2^16 to 2^16-1
         if(relativeNCG >= 32768 || relativeNCG < -32768) {
-            ALOGE("pre-allocated space for a forward jump is not big enough");
-            dvmAbort();
+            ALOGE("JIT_ERROR: Pre-allocated space (16-bit) for a forward jump is not big enough\n");
+            SET_JIT_ERROR(kJitErrorShortJumpOffset);
+            return -1;
         }
     }
     dump_imm_update(relativeNCG, jumpInst, false);
@@ -121,7 +123,8 @@ int insertLabel(const char* label, bool checkDup) {
     if(!checkDup) {
         item = (LabelMap*)malloc(sizeof(LabelMap));
         if(item == NULL) {
-            ALOGE("Memory allocation failed");
+            ALOGE("JIT_ERROR: Memory allocation failed at insertLabel with checkDup false");
+            SET_JIT_ERROR(kJitErrorMallocFailed);
             return -1;
         }
         snprintf(item->label, LABEL_SIZE, "%s", label);
@@ -137,7 +140,8 @@ int insertLabel(const char* label, bool checkDup) {
 
     item = (LabelMap*)malloc(sizeof(LabelMap));
     if(item == NULL) {
-        ALOGE("Memory allocation failed");
+        ALOGE("JIT_ERROR: Memory allocation failed at insertLabel with checkDup true");
+        SET_JIT_ERROR(kJitErrorMallocFailed);
         return -1;
     }
     snprintf(item->label, LABEL_SIZE, "%s", label);
@@ -145,7 +149,7 @@ int insertLabel(const char* label, bool checkDup) {
     item->nextItem = globalShortMap;
     globalShortMap = item;
 #ifdef DEBUG_NCG
-    ALOGI("insert short-term label %s %p", label, stream);
+    ALOGI("Insert short-term label %s %p", label, stream);
 #endif
     LabelMap* ptr = globalShortWorklist;
     LabelMap* ptr_prevItem = NULL;
@@ -156,9 +160,17 @@ int insertLabel(const char* label, bool checkDup) {
             unsigned instSize = encoder_get_inst_size(ptr->codePtr);
             relativeNCG -= instSize; //size of the instruction
 #ifdef DEBUG_NCG
-            ALOGI("perform work short-term %p for label %s relative %d", ptr->codePtr, label, relativeNCG);
-#endif
-            updateJumpInst(ptr->codePtr, ptr->size, relativeNCG);
+            ALOGI("Perform work short-term %p for label %s relative %d\n", ptr->codePtr, label, relativeNCG);
+#endif
+            int retval = updateJumpInst(ptr->codePtr, ptr->size, relativeNCG);
+            //If this fails, the jump offset was not big enough. Raise the corresponding error flag
+            //We may decide to re-compiler the trace with a large jump offset later
+            if (retval == -1){
+                ALOGE("JIT_ERROR: Label \"%s\" too far away from jump location", label);
+                SET_JIT_ERROR(kJitErrorShortJumpOffset);
+                return retval;
+            }
+
             //remove work
             if(ptr_prevItem == NULL) {
                 globalShortWorklist = ptr->nextItem;
@@ -209,7 +221,8 @@ char* findCodeForShortLabel(const char* label) {
 int insertLabelWorklist(const char* label, OpndSize immSize) {
     LabelMap* item = (LabelMap*)malloc(sizeof(LabelMap));
     if(item == NULL) {
-        ALOGE("Memory allocation failed");
+        ALOGE("JIT_ERROR: Memory allocation failed at insertLabelWorklist");
+        SET_JIT_ERROR(kJitErrorMallocFailed);
         return -1;
     }
     snprintf(item->label, LABEL_SIZE, "%s", label);
@@ -218,7 +231,7 @@ int insertLabelWorklist(const char* label, OpndSize immSize) {
     item->nextItem = globalWorklist;
     globalWorklist = item;
 #ifdef DEBUG_NCG
-    ALOGI("insert globalWorklist: %s %p", label, stream);
+    ALOGI("Insert globalWorklist: %s %p", label, stream);
 #endif
     return 0;
 }
@@ -226,7 +239,8 @@ int insertLabelWorklist(const char* label, OpndSize immSize) {
 int insertShortWorklist(const char* label, OpndSize immSize) {
     LabelMap* item = (LabelMap*)malloc(sizeof(LabelMap));
     if(item == NULL) {
-        ALOGE("Memory allocation failed");
+        ALOGE("JIT_ERROR: Memory allocation failed at insertShortWorklist");
+        SET_JIT_ERROR(kJitErrorMallocFailed);
         return -1;
     }
     snprintf(item->label, LABEL_SIZE, "%s", label);
@@ -235,7 +249,7 @@ int insertShortWorklist(const char* label, OpndSize immSize) {
     item->nextItem = globalShortWorklist;
     globalShortWorklist = item;
 #ifdef DEBUG_NCG
-    ALOGI("insert globalShortWorklist: %s %p", label, stream);
+    ALOGI("Insert globalShortWorklist: %s %p", label, stream);
 #endif
     return 0;
 }
@@ -269,7 +283,8 @@ int insertGlobalPCWorklist(char * offset, char * codeStart)
 {
     LabelMap* item = (LabelMap*)malloc(sizeof(LabelMap));
     if(item == NULL) {
-        ALOGE("Memory allocation failed");
+        ALOGE("JIT_ERROR: Memory allocation failed at insertGlobalPCWorklist");
+        SET_JIT_ERROR(kJitErrorMallocFailed);
         return -1;
     }
     snprintf(item->label, LABEL_SIZE, "%s", "export_pc");
@@ -281,7 +296,7 @@ int insertGlobalPCWorklist(char * offset, char * codeStart)
     globalPCWorklistNum ++;
 
 #ifdef DEBUG_NCG
-    ALOGI("insert globalPCWorklist: %p %p %p %x %p", globalDvmNcg->streamCode,  codeStart, streamCode, item->addend, item->codePtr);
+    ALOGI("Insert globalPCWorklist: %p %p %p %x %p", globalDvmNcg->streamCode,  codeStart, streamCode, item->addend, item->codePtr);
 #endif
     return 0;
 }
@@ -290,7 +305,8 @@ int insertChainingWorklist(int bbId, char * codeStart)
 {
     LabelMap* item = (LabelMap*)malloc(sizeof(LabelMap));
     if(item == NULL) {
-        ALOGE("Memory allocation failed");
+        ALOGE("JIT_ERROR: Memory allocation failed at insertChainingWorklist");
+        SET_JIT_ERROR(kJitErrorMallocFailed);
         return -1;
     }
     item->size = OpndSize_32;
@@ -300,7 +316,7 @@ int insertChainingWorklist(int bbId, char * codeStart)
     chainingWorklist = item;
 
 #ifdef DEBUG_NCG
-    ALOGI("insertChainingWorklist: %p basic block %d", codeStart, bbId);
+    ALOGI("InsertChainingWorklist: %p basic block %d", codeStart, bbId);
 #endif
     return 0;
 }
@@ -309,7 +325,8 @@ int insertGlobalDataWorklist(char * offset, const char* label)
 {
     LabelMap* item = (LabelMap*)malloc(sizeof(LabelMap));
     if(item == NULL) {
-        ALOGE("Memory allocation failed");
+        ALOGE("JIT_ERROR: Memory allocation failed at insertGlobalDataWorklist");
+        SET_JIT_ERROR(kJitErrorMallocFailed);
         return -1;
     }
     snprintf(item->label, LABEL_SIZE, "%s", label);
@@ -320,7 +337,7 @@ int insertGlobalDataWorklist(char * offset, const char* label)
     globalDataWorklistNum ++;
 
 #ifdef DEBUG_NCG
-    ALOGI("insert globalDataWorklist: %s %p", label, offset);
+    ALOGI("Insert globalDataWorklist: %s %p", label, offset);
 #endif
 
     return 0;
@@ -330,7 +347,8 @@ int insertVMAPIWorklist(char * offset, const char* label)
 {
     LabelMap* item = (LabelMap*)malloc(sizeof(LabelMap));
     if(item == NULL) {
-        ALOGE("Memory allocation failed");
+        ALOGE("JIT_ERROR: Memory allocation failed at insertVMAPIWorklist");
+        SET_JIT_ERROR(kJitErrorMallocFailed);
         return -1;
     }
     snprintf(item->label, LABEL_SIZE, "%s", label);
@@ -343,7 +361,7 @@ int insertVMAPIWorklist(char * offset, const char* label)
     VMAPIWorklistNum ++;
 
 #ifdef DEBUG_NCG
-    ALOGI("insert VMAPIWorklist: %s %p", label, offset);
+    ALOGI("Insert VMAPIWorklist: %s %p", label, offset);
 #endif
     return 0;
 }
@@ -377,7 +395,7 @@ void performLabelWorklist() {
     LabelMap* ptr = globalWorklist;
     while(ptr != NULL) {
 #ifdef DEBUG_NCG
-        ALOGI("perform work global %p for label %s", ptr->codePtr, ptr->label);
+        ALOGI("Perform work global %p for label %s", ptr->codePtr, ptr->label);
 #endif
         char* targetCode = findCodeForLabel(ptr->label);
         assert(targetCode != NULL);
@@ -406,7 +424,7 @@ void freeLabelWorklist() {
 */
 int updateImmRMInst(char* moveInst, const char* label, int relativeNCG) {
 #ifdef DEBUG_NCG
-    ALOGI("perform work ImmRM inst @ %p for label %s with %d", moveInst, label, relativeNCG);
+    ALOGI("Perform work ImmRM inst @ %p for label %s with %d", moveInst, label, relativeNCG);
 #endif
     dump_imm_update(relativeNCG, moveInst, true);
     return 0;
@@ -459,19 +477,32 @@ unsigned getJmpCallInstSize(OpndSize size, JmpCall_type type) {
     }
     return 0;
 }
-/*!
-\brief check whether a branch target is already handled, if yes, return the size of the immediate; otherwise, call insertShortWorklist or insertLabelWorklist.
-
-If the branch target is not handled, call insertShortWorklist or insertLabelWorklist depending on isShortTerm, unknown is set to true, immSize is set to 32 if isShortTerm is false, set to 32 if isShortTerm is true and target is check_cast_null, set to 8 otherwise.
-
-If the branch target is handled, call estOpndSizeFromImm to set immSize for jump instruction, returns the value of the immediate
-*/
+//! \brief Get the offset given a jump target
+//!
+//! \detail check whether a branch target is already handled if yes, return the
+//! size of the immediate; otherwise, call insertShortWorklist or insertLabelWorklist.
+//!
+//! If the branch target is not handled, call insertShortWorklist or insertLabelWorklist
+//! depending on isShortTerm, unknown is set to true, immSize is set to 32 if isShortTerm
+//! is false, set to 32 if isShortTerm is true and target is check_cast_null, set to 8 otherwise.
+//!
+//! If the branch target is handled, call estOpndSizeFromImm to set immSize for jump
+//! instruction, returns the value of the immediate
+//!
+//! \param target the target of the jump
+//! \param isShortTerm whether this is a short term jump
+//! \param type Call or Jmp
+//! \param unknown target known or not
+//! \param immSize size of the jump offset
+//!
+//! \return jump offset (can also return error value, but caller cannot distinguish)
 int getRelativeOffset(const char* target, bool isShortTerm, JmpCall_type type, bool* unknown, OpndSize* immSize) {
     char* targetPtrInStream = NULL;
     if(isShortTerm) targetPtrInStream = findCodeForShortLabel(target);
     else targetPtrInStream = findCodeForLabel(target);
 
     int relOffset;
+    int retCode = 0;
     *unknown = false;
     if(targetPtrInStream == NULL) {
         //branch target is not handled yet
@@ -482,14 +513,17 @@ int getRelativeOffset(const char* target, bool isShortTerm, JmpCall_type type, b
                since the lable is only used within a single bytecode, we assume OpndSize_8 is big enough
                but there are special cases where we should use 32 bit offset
             */
-            if(!strcmp(target, ".check_cast_null") || !strcmp(target, ".stackOverflow") ||
-               !strcmp(target, ".invokeChain") ||
-               !strcmp(target, ".new_instance_done") ||
-               !strcmp(target, ".new_array_done") ||
-               !strcmp(target, ".fill_array_data_done") ||
-               !strcmp(target, ".inlined_string_compare_done") ||
-               !strncmp(target, "after_exception", 15) ||
-               !strncmp(target, "exception_restore_state_", 24)) {
+            //Check if we have failed with 8-bit offset previously. Use 32-bit offsets if so.
+            if (gDvmJit.disableOpt & (1 << kShortJumpOffset)){
+                *immSize = OpndSize_32;
+            }
+            //Check if it is a special case:
+            //These labels are known to be far off from the jump location
+            //Safe to set them to large offset by default
+            else if(!strcmp(target, ".stackOverflow") ||
+                    !strcmp(target, ".invokeChain") ||
+                    !strcmp(target, "after_exception_1") ||
+                    !strncmp(target, "exception_restore_state_", 24)) {
 #ifdef SUPPORT_IMM_16
                 *immSize = OpndSize_16;
 #else
@@ -499,9 +533,14 @@ int getRelativeOffset(const char* target, bool isShortTerm, JmpCall_type type, b
                 *immSize = OpndSize_8;
             }
 #ifdef DEBUG_NCG_JUMP
-            ALOGI("insert to short worklist %s %d", target, *immSize);
-#endif
-            insertShortWorklist(target, *immSize);
+            ALOGI("Insert to short worklist %s %d", target, *immSize);
+#endif
+            retCode = insertShortWorklist(target, *immSize);
+            //NOTE: Returning negative value here cannot indicate an error
+            //The caller accepts any value as correct. Only the premature
+            //return matters here.
+            if (retCode < 0)
+                return retCode;
         }
         else {
 #ifdef SUPPORT_IMM_16
@@ -509,7 +548,12 @@ int getRelativeOffset(const char* target, bool isShortTerm, JmpCall_type type, b
 #else
             *immSize = OpndSize_32;
 #endif
-            insertLabelWorklist(target, *immSize);
+            retCode = insertLabelWorklist(target, *immSize);
+            //NOTE: Returning negative value here cannot indicate an error
+            //The caller accepts any value as correct. Only the premature
+            //return matters here.
+            if (retCode < 0)
+                return retCode;
         }
         if(type == JmpCall_call) { //call sz16 does not work in gdb
             *immSize = OpndSize_32;
@@ -522,11 +566,13 @@ int getRelativeOffset(const char* target, bool isShortTerm, JmpCall_type type, b
 #else
         *immSize = OpndSize_32;
 #endif
-        insertLabelWorklist(target, *immSize);
+        retCode = insertLabelWorklist(target, *immSize);
+        if (retCode < 0)
+            return retCode;
     }
 
 #ifdef DEBUG_NCG
-    ALOGI("backward branch @ %p for label %s", stream, target);
+    ALOGI("Backward branch @ %p for label %s", stream, target);
 #endif
     relOffset = targetPtrInStream - stream;
     if(type == JmpCall_call) *immSize = OpndSize_32;
@@ -688,11 +734,12 @@ void call_mem(int disp, int reg, bool isPhysical) {
 int insertNCGWorklist(s4 relativePC, OpndSize immSize) {
     int offsetNCG2 = stream - streamMethodStart;
 #ifdef DEBUG_NCG
-    ALOGI("insert NCGWorklist (goto forward) @ %p offsetPC %x relativePC %x offsetNCG %x", stream, offsetPC, relativePC, offsetNCG2);
+    ALOGI("Insert NCGWorklist (goto forward) @ %p offsetPC %x relativePC %x offsetNCG %x", stream, offsetPC, relativePC, offsetNCG2);
 #endif
     NCGWorklist* item = (NCGWorklist*)malloc(sizeof(NCGWorklist));
     if(item == NULL) {
-        ALOGE("Memory allocation failed");
+        ALOGE("JIT_ERROR: Memory allocation failed at insertNCGWorklist");
+        SET_JIT_ERROR(kJitErrorMallocFailed);
         return -1;
     }
     item->relativePC = relativePC;
@@ -718,7 +765,8 @@ int insertDataWorklist(s4 relativePC, char* codePtr1) {
     //insert according to offsetPC+relativePC, smallest at the head
     DataWorklist* item = (DataWorklist*)malloc(sizeof(DataWorklist));
     if(item == NULL) {
-        ALOGE("Memory allocation failed");
+        ALOGE("JIT_ERROR: Memory allocation failed at insertDataWorklist");
+        SET_JIT_ERROR(kJitErrorMallocFailed);
         return -1;
     }
     item->relativePC = relativePC;
@@ -752,7 +800,7 @@ int insertDataWorklist(s4 relativePC, char* codePtr1) {
 int performNCGWorklist() {
     NCGWorklist* ptr = globalNCGWorklist;
     while(ptr != NULL) {
-        ALOGV("perform NCG worklist: @ %p target block %d target NCG %x",
+        ALOGV("Perform NCG worklist: @ %p target block %d target NCG %x",
              ptr->codePtr, ptr->relativePC, traceLabelList[ptr->relativePC].lop.generic.offset);
         int tmpNCG = traceLabelList[ptr->relativePC].lop.generic.offset;
         assert(tmpNCG >= 0);
@@ -833,10 +881,10 @@ int performDataWorklist() {
             if ((stream + sz) < codeCacheEnd) {
                 memcpy(stream, (u2*)currentMethod->insns+tmpPC, sz);
 #ifdef DEBUG_NCG_CODE_SIZE
-                ALOGI("copy data section to stream %p: start at %d, %d bytes", stream, tmpPC, sz);
+                ALOGI("Copy data section to stream %p: start at %d, %d bytes", stream, tmpPC, sz);
 #endif
 #ifdef DEBUG_NCG
-                ALOGI("update data section at %p with %d", ptr->codePtr, stream-ptr->codePtr);
+                ALOGI("Update data section at %p with %d", ptr->codePtr, stream-ptr->codePtr);
 #endif
                 updateImmRMInst(ptr->codePtr, "", stream - ptr->codePtr);
                 stream += sz;
@@ -857,7 +905,7 @@ int performDataWorklist() {
                     //need stream, offsetPC,
                     int relativeNCG = getRelativeNCGForSwitch(relativePC+ptr->offsetPC, ptr->codePtr2);
 #ifdef DEBUG_NCG_CODE_SIZE
-                    ALOGI("convert target from %d to %d", relativePC+ptr->offsetPC, relativeNCG);
+                    ALOGI("Convert target from %d to %d", relativePC+ptr->offsetPC, relativeNCG);
 #endif
                     *((s4*)stream) = relativeNCG;
                     stream += 4;
@@ -932,7 +980,7 @@ int getRelativeNCG(s4 tmp, JmpCall_type type, bool* unknown, OpndSize* size) {//
     }
     int offsetNCG2 = stream - streamMethodStart;
 #ifdef DEBUG_NCG
-    ALOGI("goto backward @ %p offsetPC %d relativePC %d offsetNCG %d relativeNCG %d", stream, offsetPC, tmp, offsetNCG2, tmpNCG-offsetNCG2);
+    ALOGI("Goto backward @ %p offsetPC %d relativePC %d offsetNCG %d relativeNCG %d", stream, offsetPC, tmp, offsetNCG2, tmpNCG-offsetNCG2);
 #endif
     int relativeOff = tmpNCG - offsetNCG2;
     *size = estOpndSizeFromImm(relativeOff);
@@ -944,7 +992,8 @@ int getRelativeNCG(s4 tmp, JmpCall_type type, bool* unknown, OpndSize* size) {//
 input: jump target in %eax; at end of the function, jump to %eax
 */
 int common_backwardBranch() {
-    insertLabel("common_backwardBranch", false);
+    if (insertLabel("common_backwardBranch", false) == -1)
+        return -1;
 
 #if defined VTUNE_DALVIK
      int startStreamPtr = (int)stream;
@@ -971,6 +1020,7 @@ If it is a backward branch, call common_periodicChecks4 to handle GC request.
 Since this is the end of a basic block, constVREndOfBB and globalVREndOfBB are called right before the jump instruction.
 */
 int common_goto(s4 tmp) { //tmp: relativePC
+    int retCode = 0;
     if(tmp < 0) {
 #ifdef ENABLE_TRACING
 #if !defined(TRACING_OPTION2)
@@ -984,7 +1034,9 @@ int common_goto(s4 tmp) { //tmp: relativePC
         call_helper_API("common_periodicChecks4");
     }
     constVREndOfBB();
-    globalVREndOfBB(currentMethod);
+    retCode = globalVREndOfBB(currentMethod);
+    if (retCode < 0)
+        return retCode;
     bool unknown;
     OpndSize size;
     int relativeNCG = tmp;
@@ -998,10 +1050,11 @@ int common_if(s4 tmp, ConditionCode cc_next, ConditionCode cc_taken) {
     if(tmp < 0) { //backward
         conditional_jump(cc_next, ".if_next", true);
         common_goto(tmp);
-        insertLabel(".if_next", true);
+        if (insertLabel(".if_next", true) == -1)
+            return -1;
     }
     else {
-        //if(tmp < 0) LOGI("skip periodicCheck for if");
+        //if(tmp < 0) ALOGI("skip periodicCheck for if");
         bool unknown;
         OpndSize size;
         int relativeNCG = tmp;
@@ -1012,12 +1065,26 @@ int common_if(s4 tmp, ConditionCode cc_next, ConditionCode cc_taken) {
     return 0;
 }
 #else
-//when this is called from JIT, there is no need to check GC
+
+//! \brief common code to handle GOTO
+//!
+//! \details If it is a backward branch, call common_periodicChecks4
+//! to handle GC request.
+//! Since this is the end of a basic block, constVREndOfBB and
+//! globalVREndOfBB are called right before the jump instruction.
+//! when this is called from JIT, there is no need to check GC
+//!
+//! \param targetBlockId
+//!
+//! \return -1 if error
 int common_goto(s4 targetBlockId) {
     bool unknown;
+    int retCode = 0;
     OpndSize size;
     constVREndOfBB();
-    globalVREndOfBB(currentMethod);
+    retCode = globalVREndOfBB(currentMethod);
+    if (retCode < 0)
+        return retCode;
 
     if(gDvmJit.scheduling) {
         unconditional_jump_block((int)targetBlockId);
@@ -1046,7 +1113,8 @@ int common_if(s4 tmp, ConditionCode cc_next, ConditionCode cc) {
                 unconditional_jump_int(relativeNCG, size);
             }
 
-            insertLabel(".vr_store_at_loop_exit", true);
+            if (insertLabel(".vr_store_at_loop_exit", true) == -1)
+                return -1;
             storeVRExitOfLoop();
 
             if(gDvmJit.scheduling && traceCurrentBB->taken) {
@@ -1070,7 +1138,8 @@ int common_if(s4 tmp, ConditionCode cc_next, ConditionCode cc) {
                 unconditional_jump_int(relativeNCG, size);
             }
 
-            insertLabel(".vr_store_at_loop_exit", true);
+            if (insertLabel(".vr_store_at_loop_exit", true) == -1)
+                return -1;
             storeVRExitOfLoop();
 
             if(gDvmJit.scheduling && traceCurrentBB->fallThrough) {
@@ -1082,8 +1151,11 @@ int common_if(s4 tmp, ConditionCode cc_next, ConditionCode cc) {
                 unconditional_jump_int(relativeNCG, size);
             }
         }
-        else
-           LOGE("ERROR in common_if\n");
+        else {
+           ALOGE("JIT_ERROR: Invalid branch type in common_if\n");
+           SET_JIT_ERROR(kJitErrorTraceFormation);
+           return -1;
+        }
     }
     else {
         if(gDvmJit.scheduling) {
@@ -1112,7 +1184,8 @@ int common_if(s4 tmp, ConditionCode cc_next, ConditionCode cc) {
 
 */
 int common_errNullObject() {
-    insertLabel("common_errNullObject", false);
+    if (insertLabel("common_errNullObject", false) == -1)
+        return -1;
 
 #if defined VTUNE_DALVIK
     int startStreamPtr = (int)stream;
@@ -1136,11 +1209,13 @@ int common_errNullObject() {
 
 */
 int common_errStringIndexOutOfBounds() {
-    insertLabel("common_errStringIndexOutOfBounds", false);
+    if (insertLabel("common_errStringIndexOutOfBounds", false) == -1)
+        return -1;
 
 #if defined VTUNE_DALVIK
     int startStreamPtr = (int)stream;
 #endif
+
     move_imm_to_reg(OpndSize_32, 0, PhysicalReg_EAX, true);
     move_imm_to_reg(OpndSize_32, (int)gDvm.exStringIndexOutOfBoundsException, PhysicalReg_ECX, true);
     unconditional_jump("common_throw", false);
@@ -1159,7 +1234,8 @@ int common_errStringIndexOutOfBounds() {
 
 */
 int common_errArrayIndex() {
-    insertLabel("common_errArrayIndex", false);
+    if (insertLabel("common_errArrayIndex", false) == -1)
+        return -1;
 #if defined VTUNE_DALVIK
     int startStreamPtr = (int)stream;
 #endif
@@ -1181,7 +1257,8 @@ int common_errArrayIndex() {
 
 */
 int common_errArrayStore() {
-    insertLabel("common_errArrayStore", false);
+    if (insertLabel("common_errArrayStore", false) == -1)
+        return -1;
 #if defined VTUNE_DALVIK
     int startStreamPtr = (int)stream;
 #endif
@@ -1203,7 +1280,8 @@ int common_errArrayStore() {
 
 */
 int common_errNegArraySize() {
-    insertLabel("common_errNegArraySize", false);
+    if (insertLabel("common_errNegArraySize", false) == -1)
+        return -1;
 
 #if defined VTUNE_DALVIK
     int startStreamPtr = (int)stream;
@@ -1225,7 +1303,8 @@ int common_errNegArraySize() {
 
 */
 int common_errDivideByZero() {
-    insertLabel("common_errDivideByZero", false);
+    if (insertLabel("common_errDivideByZero", false) == -1)
+        return -1;
 
 #if defined VTUNE_DALVIK
     int startStreamPtr = (int)stream;
@@ -1247,7 +1326,8 @@ int common_errDivideByZero() {
 
 */
 int common_errNoSuchMethod() {
-    insertLabel("common_errNoSuchMethod", false);
+    if (insertLabel("common_errNoSuchMethod", false) == -1)
+        return -1;
 
 #if defined VTUNE_DALVIK
     int startStreamPtr = (int)stream;
@@ -1274,7 +1354,8 @@ int call_dvmFindCatchBlock();
 
 */
 int common_exceptionThrown() {
-    insertLabel("common_exceptionThrown", false);
+    if (insertLabel("common_exceptionThrown", false) == -1)
+        return -1;
 #if defined VTUNE_DALVIK
     int startStreamPtr = (int)stream;
 #endif
@@ -1304,7 +1385,8 @@ OUTPUT: no
 */
 int throw_exception_message(int exceptionPtrReg, int obj_reg, bool isPhysical,
                             int startLR/*logical register index*/, bool startPhysical) {
-    insertLabel("common_throw_message", false);
+    if (insertLabel("common_throw_message", false) == -1)
+        return -1;
 
 #if defined VTUNE_DALVIK
     int startStreamPtr = (int)stream;
@@ -1336,7 +1418,8 @@ scratch: C_SCRATCH_1(%edx)
 */
 int throw_exception(int exceptionPtrReg, int immReg,
                     int startLR/*logical register index*/, bool startPhysical) {
-    insertLabel("common_throw", false);
+    if (insertLabel("common_throw", false) == -1)
+        return -1;
 
 #if defined VTUNE_DALVIK
     int startStreamPtr = (int)stream;
@@ -1419,6 +1502,7 @@ int op_goto_32(const MIR * mir) {
  * @return value >= 0 when handled
  */
 int op_packed_switch(const MIR * mir, const u2 * dalvikPC) {
+    int retCode = 0;
     assert(mir->dalvikInsn.opcode == OP_PACKED_SWITCH);
     u2 vA = mir->dalvikInsn.vA;
     u4 tmp = mir->dalvikInsn.vB;
@@ -1462,7 +1546,9 @@ int op_packed_switch(const MIR * mir, const u2 * dalvikPC) {
     //TODO: eax should be absolute address, call globalVREndOfBB, constVREndOfBB
     //conditional_jump_global_API(Condition_LE, "common_backwardBranch", false);
     constVREndOfBB();
-    globalVREndOfBB(currentMethod); //update GG VRs
+    retCode = globalVREndOfBB(currentMethod); //update GG VRs
+    if (retCode < 0)
+        return retCode;
     //get rPC, %eax has the relative PC offset
     alu_binary_imm_reg(OpndSize_32, add_opc, (int)dalvikPC, PhysicalReg_EAX, true);
     scratchRegs[0] = PhysicalReg_SCRATCH_2;
@@ -1487,6 +1573,7 @@ int op_packed_switch(const MIR * mir, const u2 * dalvikPC) {
  * @return value >= 0 when handled
  */
 int op_sparse_switch(const MIR * mir, const u2 * dalvikPC) {
+    int retCode = 0;
     assert(mir->dalvikInsn.opcode == OP_SPARSE_SWITCH);
     u2 vA = mir->dalvikInsn.vA;
     u4 tmp = mir->dalvikInsn.vB;
@@ -1529,7 +1616,9 @@ int op_sparse_switch(const MIR * mir, const u2 * dalvikPC) {
     //TODO: eax should be absolute address, call globalVREndOfBB constVREndOfBB
     //conditional_jump_global_API(Condition_LE, "common_backwardBranch", false);
     constVREndOfBB();
-    globalVREndOfBB(currentMethod);
+    retCode = globalVREndOfBB(currentMethod);
+    if (retCode < 0)
+        return retCode;
     //get rPC, %eax has the relative PC offset
     alu_binary_imm_reg(OpndSize_32, add_opc, (int)dalvikPC, PhysicalReg_EAX, true);
     scratchRegs[0] = PhysicalReg_SCRATCH_2;
@@ -1554,6 +1643,7 @@ int op_sparse_switch(const MIR * mir, const u2 * dalvikPC) {
  * @return value >= 0 when handled
  */
 int op_if_eq(const MIR * mir) {
+    int retCode = 0;
     assert(mir->dalvikInsn.opcode == OP_IF_EQ);
     u2 vA = mir->dalvikInsn.vA;
     u2 vB = mir->dalvikInsn.vB;
@@ -1561,7 +1651,9 @@ int op_if_eq(const MIR * mir) {
     get_virtual_reg(vA, OpndSize_32, 1, false);
     compare_VR_reg(OpndSize_32, vB, 1, false);
     constVREndOfBB();
-    globalVREndOfBB(currentMethod);
+    retCode = globalVREndOfBB(currentMethod);
+    if (retCode < 0)
+        return retCode;
     common_if(tmp, Condition_NE, Condition_E);
     return 0;
 }
@@ -1572,6 +1664,7 @@ int op_if_eq(const MIR * mir) {
  * @return value >= 0 when handled
  */
 int op_if_ne(const MIR * mir) {
+    int retCode = 0;
     assert(mir->dalvikInsn.opcode == OP_IF_NE);
     u2 vA = mir->dalvikInsn.vA;
     u2 vB = mir->dalvikInsn.vB;
@@ -1579,7 +1672,9 @@ int op_if_ne(const MIR * mir) {
     get_virtual_reg(vA, OpndSize_32, 1, false);
     compare_VR_reg(OpndSize_32, vB, 1, false);
     constVREndOfBB();
-    globalVREndOfBB(currentMethod);
+    retCode = globalVREndOfBB(currentMethod);
+    if (retCode < 0)
+        return retCode;
     common_if(tmp, Condition_E, Condition_NE);
     return 0;
 }
@@ -1590,6 +1685,7 @@ int op_if_ne(const MIR * mir) {
  * @return value >= 0 when handled
  */
 int op_if_lt(const MIR * mir) {
+    int retCode = 0;
     assert(mir->dalvikInsn.opcode == OP_IF_LT);
     u2 vA = mir->dalvikInsn.vA;
     u2 vB = mir->dalvikInsn.vB;
@@ -1597,7 +1693,9 @@ int op_if_lt(const MIR * mir) {
     get_virtual_reg(vA, OpndSize_32, 1, false);
     compare_VR_reg(OpndSize_32, vB, 1, false);
     constVREndOfBB();
-    globalVREndOfBB(currentMethod);
+    retCode = globalVREndOfBB(currentMethod);
+    if (retCode < 0)
+        return retCode;
     common_if(tmp, Condition_GE, Condition_L);
     return 0;
 }
@@ -1608,6 +1706,7 @@ int op_if_lt(const MIR * mir) {
  * @return value >= 0 when handled
  */
 int op_if_ge(const MIR * mir) {
+    int retCode = 0;
     assert(mir->dalvikInsn.opcode == OP_IF_GE);
     u2 vA = mir->dalvikInsn.vA;
     u2 vB = mir->dalvikInsn.vB;
@@ -1615,7 +1714,9 @@ int op_if_ge(const MIR * mir) {
     get_virtual_reg(vA, OpndSize_32, 1, false);
     compare_VR_reg(OpndSize_32, vB, 1, false);
     constVREndOfBB();
-    globalVREndOfBB(currentMethod);
+    retCode = globalVREndOfBB(currentMethod);
+    if (retCode < 0)
+        return retCode;
     common_if(tmp, Condition_L, Condition_GE);
     return 0;
 }
@@ -1626,6 +1727,7 @@ int op_if_ge(const MIR * mir) {
  * @return value >= 0 when handled
  */
 int op_if_gt(const MIR * mir) {
+    int retCode = 0;
     assert(mir->dalvikInsn.opcode == OP_IF_GT);
     u2 vA = mir->dalvikInsn.vA;
     u2 vB = mir->dalvikInsn.vB;
@@ -1633,7 +1735,9 @@ int op_if_gt(const MIR * mir) {
     get_virtual_reg(vA, OpndSize_32, 1, false);
     compare_VR_reg(OpndSize_32, vB, 1, false);
     constVREndOfBB();
-    globalVREndOfBB(currentMethod);
+    retCode = globalVREndOfBB(currentMethod);
+    if (retCode < 0)
+        return retCode;
     common_if(tmp, Condition_LE, Condition_G);
     return 0;
 }
@@ -1644,6 +1748,7 @@ int op_if_gt(const MIR * mir) {
  * @return value >= 0 when handled
  */
 int op_if_le(const MIR * mir) {
+    int retCode = 0;
     assert(mir->dalvikInsn.opcode == OP_IF_LE);
     u2 vA = mir->dalvikInsn.vA;
     u2 vB = mir->dalvikInsn.vB;
@@ -1651,7 +1756,9 @@ int op_if_le(const MIR * mir) {
     get_virtual_reg(vA, OpndSize_32, 1, false);
     compare_VR_reg(OpndSize_32, vB, 1, false);
     constVREndOfBB();
-    globalVREndOfBB(currentMethod);
+    retCode = globalVREndOfBB(currentMethod);
+    if (retCode < 0)
+        return retCode;
     common_if(tmp, Condition_G, Condition_LE);
     return 0;
 }
@@ -1663,12 +1770,15 @@ int op_if_le(const MIR * mir) {
  * @return value >= 0 when handled
  */
 int op_if_eqz(const MIR * mir) {
+    int retCode = 0;
     assert(mir->dalvikInsn.opcode == OP_IF_EQZ);
     u2 vA = mir->dalvikInsn.vA;
     s2 tmp = mir->dalvikInsn.vB;
     compare_imm_VR(OpndSize_32, 0, vA);
     constVREndOfBB();
-    globalVREndOfBB(currentMethod);
+    retCode = globalVREndOfBB(currentMethod);
+    if (retCode < 0)
+        return retCode;
     common_if(tmp, Condition_NE, Condition_E);
     return 0;
 }
@@ -1679,12 +1789,15 @@ int op_if_eqz(const MIR * mir) {
  * @return value >= 0 when handled
  */
 int op_if_nez(const MIR * mir) {
+    int retCode = 0;
     assert(mir->dalvikInsn.opcode == OP_IF_NEZ);
     u2 vA = mir->dalvikInsn.vA;
     s2 tmp = mir->dalvikInsn.vB;
     compare_imm_VR(OpndSize_32, 0, vA);
     constVREndOfBB();
-    globalVREndOfBB(currentMethod);
+    retCode = globalVREndOfBB(currentMethod);
+    if (retCode < 0)
+        return retCode;
     common_if(tmp, Condition_E, Condition_NE);
     return 0;
 }
@@ -1695,12 +1808,15 @@ int op_if_nez(const MIR * mir) {
  * @return value >= 0 when handled
  */
 int op_if_ltz(const MIR * mir) {
+    int retCode = 0;
     assert(mir->dalvikInsn.opcode == OP_IF_LTZ);
     u2 vA = mir->dalvikInsn.vA;
     s2 tmp = mir->dalvikInsn.vB;
     compare_imm_VR(OpndSize_32, 0, vA);
     constVREndOfBB();
-    globalVREndOfBB(currentMethod);
+    retCode = globalVREndOfBB(currentMethod);
+    if (retCode < 0)
+        return retCode;
     common_if(tmp, Condition_GE, Condition_L);
     return 0;
 }
@@ -1711,12 +1827,15 @@ int op_if_ltz(const MIR * mir) {
  * @return value >= 0 when handled
  */
 int op_if_gez(const MIR * mir) {
+    int retCode = 0;
     assert(mir->dalvikInsn.opcode == OP_IF_GEZ);
     u2 vA = mir->dalvikInsn.vA;
     s2 tmp = mir->dalvikInsn.vB;
     compare_imm_VR(OpndSize_32, 0, vA);
     constVREndOfBB();
-    globalVREndOfBB(currentMethod);
+    retCode = globalVREndOfBB(currentMethod);
+    if (retCode < 0)
+        return retCode;
     common_if(tmp, Condition_L, Condition_GE);
     return 0;
 }
@@ -1727,12 +1846,15 @@ int op_if_gez(const MIR * mir) {
  * @return value >= 0 when handled
  */
 int op_if_gtz(const MIR * mir) {
+    int retCode = 0;
     assert(mir->dalvikInsn.opcode == OP_IF_GTZ);
     u2 vA = mir->dalvikInsn.vA;
     s2 tmp = mir->dalvikInsn.vB;
     compare_imm_VR(OpndSize_32, 0, vA);
     constVREndOfBB();
-    globalVREndOfBB(currentMethod);
+    retCode = globalVREndOfBB(currentMethod);
+    if (retCode < 0)
+        return retCode;
     common_if(tmp, Condition_LE, Condition_G);
     return 0;
 }
@@ -1743,12 +1865,15 @@ int op_if_gtz(const MIR * mir) {
  * @return value >= 0 when handled
  */
 int op_if_lez(const MIR * mir) {
+    int retCode = 0;
     assert(mir->dalvikInsn.opcode == OP_IF_LEZ);
     u2 vA = mir->dalvikInsn.vA;
     s2 tmp = mir->dalvikInsn.vB;
     compare_imm_VR(OpndSize_32, 0, vA);
     constVREndOfBB();
-    globalVREndOfBB(currentMethod);
+    retCode = globalVREndOfBB(currentMethod);
+    if (retCode < 0)
+        return retCode;
     common_if(tmp, Condition_G, Condition_LE);
     return 0;
 }
@@ -1760,7 +1885,8 @@ int op_if_lez(const MIR * mir) {
 BCOffset in %edx
 */
 int common_periodicChecks4() {
-    insertLabel("common_periodicChecks4", false);
+    if (insertLabel("common_periodicChecks4", false) == -1)
+        return -1;
 
 #if defined VTUNE_DALVIK
     int startStreamPtr = (int)stream;
@@ -1773,7 +1899,8 @@ int common_periodicChecks4() {
     conditional_jump(Condition_NE, "common_handleSuspend4", true); //called once
     x86_return();
 
-    insertLabel("common_handleSuspend4", true);
+    if (insertLabel("common_handleSuspend4", true) == -1)
+        return -1;
     push_reg_to_stack(OpndSize_32, PhysicalReg_ECX, true);
     call_dvmCheckSuspendPending();
     load_effective_addr(4, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
@@ -1795,13 +1922,15 @@ int common_periodicChecks4() {
     //recover registers and return
     x86_return();
 
-    insertLabel("common_handleSuspend4_1", true);
+    if (insertLabel("common_handleSuspend4_1", true) == -1)
+        return -1;
     push_mem_to_stack(OpndSize_32, offGlue_self, PhysicalReg_Glue, true);
     call_dvmCheckSuspendPending();
     load_effective_addr(4, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
     x86_return();
 
-    insertLabel("common_debuggerActive4", true);
+    if (insertLabel("common_debuggerActive4", true) == -1)
+        return -1;
     //%edx: offsetBC (at run time, get method->insns_bytecode, then calculate BCPointer)
     move_mem_to_reg(OpndSize_32, offGlue_method, PhysicalReg_Glue, true, P_GPR_1, true);
     move_mem_to_reg(OpndSize_32, offMethod_insns_bytecode, P_GPR_1, true, P_GPR_2, true);
@@ -1825,7 +1954,8 @@ int common_periodicChecks4() {
 
 */
 int common_periodicChecks_entry() {
-    insertLabel("common_periodicChecks_entry", false);
+    if (insertLabel("common_periodicChecks_entry", false) == -1)
+        return -1;
 #if defined VTUNE_DALVIK
     int startStreamPtr = (int)stream;
 #endif
@@ -1850,7 +1980,8 @@ int common_periodicChecks_entry() {
 
     //recover registers and return
     x86_return();
-    insertLabel("common_handleSuspend", true);
+    if (insertLabel("common_handleSuspend", true) == -1)
+        return -1;
     get_self_pointer(P_GPR_1, true);
     load_effective_addr(-4, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
     move_reg_to_mem(OpndSize_32, P_GPR_1, true, 0, PhysicalReg_ESP, true);
@@ -1858,7 +1989,8 @@ int common_periodicChecks_entry() {
     load_effective_addr(4, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
     x86_return();
 #ifdef NCG_DEBUG
-    insertLabel("common_debuggerActive", true);
+    if (insertLabel("common_debuggerActive", true) == -1)
+        return -1;
     //adjust PC!!! use 0(%esp) TODO
     set_glue_entryPoint_imm(0); //kInterpEntryInstr);
     unconditional_jump("common_gotoBail", false);
@@ -1880,12 +2012,14 @@ int common_periodicChecks_entry() {
   input: %edx: BCPointer %esi: Glue
   set %eax to 1 (switch interpreter = true), recover the callee-saved registers and return
 */
-int common_gotoBail() {
-    insertLabel("common_gotoBail", false);
+int common_gotoBail(void) {
+    if (insertLabel("common_gotoBail", false) == -1)
+        return -1;
 
 #if defined VTUNE_DALVIK
     int startStreamPtr = (int)stream;
 #endif
+
     //scratchRegs[0] = PhysicalReg_EDX; scratchRegs[1] = PhysicalReg_ESI;
     //scratchRegs[2] = PhysicalReg_Null; scratchRegs[3] = PhysicalReg_Null;
     //save_pc_fp_to_glue();
@@ -1918,8 +2052,9 @@ int common_gotoBail() {
 
   set %eax to 0, recover the callee-saved registers and return
 */
-int common_gotoBail_0() {
-    insertLabel("common_gotoBail_0", false);
+int common_gotoBail_0(void) {
+    if (insertLabel("common_gotoBail_0", false) == -1)
+        return -1;
 
 #if defined VTUNE_DALVIK
     int startStreamPtr = (int)stream;
diff --git a/vm/compiler/codegen/x86/LowerObject.cpp b/vm/compiler/codegen/x86/LowerObject.cpp
index 85453d4..2c79201 100644
--- a/vm/compiler/codegen/x86/LowerObject.cpp
+++ b/vm/compiler/codegen/x86/LowerObject.cpp
@@ -39,7 +39,7 @@ int check_cast_nohelper(u2 vA, u4 tmp, bool instance, u2 vDest) {
     bool needToResolve = true;
     ClassObject *classPtr =
                 (currentMethod->clazz->pDvmDex->pResClasses[tmp]);
-    ALOGV("in check_cast, class is resolved to %p", classPtr);
+    ALOGV("In check_cast, class is resolved to %p", classPtr);
     if(classPtr != NULL) {
         needToResolve = false;
         ALOGV("check_cast class %s", classPtr->descriptor);
@@ -83,9 +83,15 @@ int check_cast_nohelper(u2 vA, u4 tmp, bool instance, u2 vDest) {
     }
     //class is resolved, and it is in %eax
     if(!instance) {
-        insertLabel(".check_cast_resolved", true);
+        if (insertLabel(".check_cast_resolved", true) == -1){
+            return -1;
+        }
+    }
+    else {
+        if (insertLabel(".instance_of_resolved", true) == -1) {
+            return -1;
+        }
     }
-    else insertLabel(".instance_of_resolved", true);
 
     move_mem_to_reg(OpndSize_32, offObject_clazz, 1, false, 6, false); //object->clazz
 
@@ -132,9 +138,16 @@ int check_cast_nohelper(u2 vA, u4 tmp, bool instance, u2 vDest) {
         unconditional_jump_global_API("common_throw_message", false);
     }
     //handler for speical case where object reference is null
-    if(instance)
-        insertLabel(".instance_of_null", true);
-    else insertLabel(".check_cast_null", true);
+    if(instance) {
+        if (insertLabel(".instance_of_null", true) == -1) {
+            return -1;
+        }
+    }
+    else {
+        if (insertLabel(".check_cast_null", true) == -1) {
+            return -1;
+        }
+    }
     goToState(1);
     if(instance) {
         move_imm_to_reg(OpndSize_32, 0, 3, false);
@@ -146,17 +159,30 @@ int check_cast_nohelper(u2 vA, u4 tmp, bool instance, u2 vDest) {
         unconditional_jump(".check_cast_okay", true);
 
     //handler for special case where class of object is the same as the resolved class
-    if(instance)
-        insertLabel(".instance_of_equal", true);
-    else insertLabel(".check_cast_equal", true);
+    if(instance) {
+        if (insertLabel(".instance_of_equal", true) == -1){
+            return -1;
+        }
+    }
+    else {
+        if (insertLabel(".check_cast_equal", true) == -1)
+            return -1;
+    }
     goToState(3);
     if(instance) {
         move_imm_to_reg(OpndSize_32, 1, 3, false);
     }
     transferToState(4);
-    if(instance)
-        insertLabel(".instance_of_okay", true);
-    else insertLabel(".check_cast_okay", true);
+    if(instance) {
+        if (insertLabel(".instance_of_okay", true) == -1) {
+            return -1;
+        }
+    }
+    else {
+        if (insertLabel(".check_cast_okay", true) == -1) {
+            return -1;
+        }
+    }
     //all cases merge here and the value is put to virtual register
     if(instance) {
         set_virtual_reg(vDest, OpndSize_32, 3, false);
@@ -182,8 +208,7 @@ int op_check_cast(const MIR * mir) {
     assert(mir->dalvikInsn.opcode == OP_CHECK_CAST);
     u2 vA = mir->dalvikInsn.vA;
     u4 tmp = mir->dalvikInsn.vB;
-    common_check_cast_instance_of(vA, tmp, false, 0);
-    return 0;
+    return common_check_cast_instance_of(vA, tmp, false, 0);
 }
 
 /**
@@ -196,8 +221,7 @@ int op_instance_of(const MIR * mir) {
     u2 vA = mir->dalvikInsn.vA;
     u2 vB = mir->dalvikInsn.vB;
     u4 tmp = mir->dalvikInsn.vC;
-    common_check_cast_instance_of(vB, tmp, true, vA);
-    return 0;
+    return common_check_cast_instance_of(vB, tmp, true, vA);
 }
 
 #define P_GPR_1 PhysicalReg_EBX
@@ -344,7 +368,9 @@ int op_monitor_exit(const MIR * mir) {
                                            Condition_E, Condition_NE,
                                            2, errName);
 #endif
-        insertLabel(".unlock_object_done", true);
+        if (insertLabel(".unlock_object_done", true) == -1) {
+            return -1;
+        }
         ///////////////////////////
     }
     return 0;
@@ -460,7 +486,8 @@ int op_new_instance(const MIR * mir) {
         transferToState(1);
 
         //here, class is resolved
-        insertLabel(".new_instance_resolved", true);
+        if (insertLabel(".new_instance_resolved", true) == -1)
+            return -1;
         //check whether the class is initialized
         //if yes, jump to initialized
         //if no, call new_instance_needinit
@@ -471,7 +498,8 @@ int op_new_instance(const MIR * mir) {
         call_helper_API(".new_instance_needinit");
         transferToState(2);
         //here, class is already initialized
-        insertLabel(".new_instance_initialized", true);
+        if (insertLabel(".new_instance_initialized", true) == -1)
+            return -1;
         //check whether the class is an interface or abstract, if yes, throw exception
         move_mem_to_reg(OpndSize_32, offClassObject_accessFlags, PhysicalReg_EAX, true, 6, false);
         test_imm_reg(OpndSize_32, ACC_INTERFACE|ACC_ABSTRACT, 6, false); //access flags
@@ -508,7 +536,8 @@ int op_new_instance(const MIR * mir) {
                                            3, "common_exceptionThrown");
 #endif
     }
-    insertLabel(".new_instance_done", true);
+    if (insertLabel(".new_instance_done", true) == -1)
+        return -1;
     set_virtual_reg(vA, OpndSize_32, PhysicalReg_EAX, true);
     return 0;
 }
@@ -520,7 +549,8 @@ int op_new_instance(const MIR * mir) {
 //!CALL: dvmInitClass
 //!%eax, %esi, %ebx are live through function new_instance_needinit
 int new_instance_needinit() {
-    insertLabel(".new_instance_needinit", false);
+    if (insertLabel(".new_instance_needinit", false) == -1)
+        return -1;
     load_effective_addr(-8, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
     move_reg_to_mem(OpndSize_32, PhysicalReg_EAX, true, 0, PhysicalReg_ESP, true);
     move_reg_to_mem(OpndSize_32, PhysicalReg_EAX, true, 4, PhysicalReg_ESP, true);
@@ -600,7 +630,8 @@ int op_new_array(const MIR * mir) {
 #endif
         //here, class is already resolved, the class object is in %eax
         //prepare to call dvmAllocArrayByClass with inputs: resolved class, array length, flag ALLOC_DONT_TRACK
-        insertLabel(".new_array_resolved", true);
+        if (insertLabel(".new_array_resolved", true) == -1)
+                return -1;
         load_effective_addr(-12, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
 #if defined(WITH_JIT)
         /* 1st argument to dvmAllocArrayByClass at 0(%esp) */
@@ -628,7 +659,8 @@ int op_new_array(const MIR * mir) {
                                            Condition_E, Condition_NE,
                                            2, "common_exceptionThrown");
 #endif
-        insertLabel(".new_array_done", true);
+        if (insertLabel(".new_array_done", true) == -1)
+            return -1;
         set_virtual_reg(vA, OpndSize_32, PhysicalReg_EAX, true);
         //////////////////////////////////////
     }
@@ -663,7 +695,8 @@ int common_filled_new_array(u2 length, u4 tmp, bool hasRange) {
     call_helper_API(".class_resolve");
     transferToState(1);
     //here, class is already resolved
-    insertLabel(".filled_new_array_resolved", true);
+    if (insertLabel(".filled_new_array_resolved", true) == -1)
+        return -1;
     //check descriptor of the class object, if not implemented, throws exception
     move_mem_to_reg(OpndSize_32, 24, PhysicalReg_EAX, true, 5, false);
     //load a single byte of the descriptor
@@ -675,7 +708,8 @@ int common_filled_new_array(u2 length, u4 tmp, bool hasRange) {
     compare_imm_reg(OpndSize_32, '[', 6, false);
     conditional_jump(Condition_NE, ".filled_new_array_notimpl", false);
 
-    insertLabel(".filled_new_array_impl", true);
+    if (insertLabel(".filled_new_array_impl", true) == -1)
+        return -1;
     //prepare to call dvmAllocArrayByClass with inputs: classObject, length, flag ALLOC_DONT_TRACK
     load_effective_addr(-12, PhysicalReg_ESP, true, PhysicalReg_ESP, true);
     move_imm_to_mem(OpndSize_32, (int)classPtr, 0, PhysicalReg_ESP, true);
@@ -706,7 +740,8 @@ int common_filled_new_array(u2 length, u4 tmp, bool hasRange) {
 
     markCard_filled(6, false, PhysicalReg_SCRATCH_4, false);
 
-    insertLabel(".dont_mark_filled_new_array", true);
+    if (insertLabel(".dont_mark_filled_new_array", true) == -1)
+        return -1;
 
     //return value of bytecode FILLED_NEW_ARRAY is in GLUE structure
     scratchRegs[0] = PhysicalReg_SCRATCH_4; scratchRegs[1] = PhysicalReg_Null;
@@ -733,7 +768,8 @@ int op_filled_new_array(const MIR * mir) {
     v2 = mir->dalvikInsn.arg[1];
     v1 = mir->dalvikInsn.arg[0];
 
-    common_filled_new_array(length, tmp, false);
+    if (common_filled_new_array(length, tmp, false) == -1)
+        return -1;
     if(length >= 1) {
         //move from virtual register to contents of array object
         get_virtual_reg(v1, OpndSize_32, 7, false);
@@ -766,7 +802,8 @@ int op_filled_new_array(const MIR * mir) {
 //!
 int filled_new_array_notimpl() {
     //two inputs for common_throw:
-    insertLabel(".filled_new_array_notimpl", false);
+    if (insertLabel(".filled_new_array_notimpl", false) == -1)
+        return -1;
     move_imm_to_reg(OpndSize_32, LstrFilledNewArrayNotImpl, PhysicalReg_EAX, true);
     move_imm_to_reg(OpndSize_32, (int) gDvm.exInternalError, PhysicalReg_ECX, true);
     unconditional_jump("common_throw", false);
@@ -785,7 +822,8 @@ int op_filled_new_array_range(const MIR * mir) {
     u2 length = mir->dalvikInsn.vA;
     u4 tmp = mir->dalvikInsn.vB;
     u4 vC = mir->dalvikInsn.vC;
-    common_filled_new_array(length, tmp, true/*hasRange*/);
+    if (common_filled_new_array(length, tmp, true/*hasRange*/) == -1)
+        return -1;
     //here, %eax points to the array object
     if(length >= 1) {
         //dump all virtual registers used by this bytecode to stack, for NCG O1
@@ -800,7 +838,8 @@ int op_filled_new_array_range(const MIR * mir) {
         //loop counter
         move_imm_to_reg(OpndSize_32, length-1, 9, false); //counter
         //start of the loop
-        insertLabel(".filled_new_array_range_loop1", true);
+        if (insertLabel(".filled_new_array_range_loop1", true) == -1)
+            return -1;
         rememberState(1);
         move_mem_to_reg(OpndSize_32, 0, 7, false, 10, false);
         load_effective_addr(4, 7, false, 7, false);
@@ -849,7 +888,8 @@ int op_fill_array_data(const MIR * mir, const u2 * dalvikPC) {
     //jump to dvmJitToExceptionThrown
     scratchRegs[0] = PhysicalReg_SCRATCH_2;
     jumpToExceptionThrown(2/*exception number*/);
-    insertLabel(".fill_array_data_done", true);
+    if (insertLabel(".fill_array_data_done", true) == -1)
+        return -1;
     return 0;
 }
 #undef P_GPR_1
diff --git a/vm/compiler/codegen/x86/LowerReturn.cpp b/vm/compiler/codegen/x86/LowerReturn.cpp
index fa73ba8..336a5dc 100644
--- a/vm/compiler/codegen/x86/LowerReturn.cpp
+++ b/vm/compiler/codegen/x86/LowerReturn.cpp
@@ -73,7 +73,8 @@ int common_returnFromMethod() {
     //if returnAddr is not NULL, the thread is still in code cache
     move_reg_to_mem(OpndSize_32, PhysicalReg_EBX, true, offThread_inJitCodeCache, 3, false);
 
-    insertLabel(".LreturnToInterp", true); //local label
+    if (insertLabel(".LreturnToInterp", true) == -1) //local label
+        return -1;
     //move rPC by 6 (3 bytecode units for INVOKE)
     alu_binary_imm_reg(OpndSize_32, add_opc, 6, PhysicalReg_EAX, true);
 
@@ -90,7 +91,8 @@ int common_returnFromMethod() {
     move_reg_to_reg(OpndSize_32, PhysicalReg_ESI, true, PhysicalReg_EBX, true);
 #endif
     unconditional_jump_reg(PhysicalReg_EBX, true);
-    insertLabel(".LcontinueToInterp", true);
+    if (insertLabel(".LcontinueToInterp", true) == -1)
+        return -1;
     scratchRegs[0] = PhysicalReg_SCRATCH_4;
     typedef void (*vmHelper)(int);
     vmHelper funcPtr = dvmJitToInterpNoChainNoProfile; //%eax is the input
@@ -137,8 +139,8 @@ int op_return(const MIR * mir) {
     scratchRegs[0] = PhysicalReg_SCRATCH_1;
     set_return_value(OpndSize_32, 22, false);
 
-    common_returnFromMethod();
-    return 0;
+    int retVal = common_returnFromMethod();
+    return retVal;
 }
 
 /**
@@ -154,6 +156,6 @@ int op_return_wide(const MIR * mir) {
     scratchRegs[2] = PhysicalReg_Null; scratchRegs[3] = PhysicalReg_Null;
     set_return_value(OpndSize_64, 1, false);
 
-    common_returnFromMethod();
-    return 0;
+    int retVal = common_returnFromMethod();
+    return retVal;
 }
diff --git a/vm/compiler/codegen/x86/NcgAot.cpp b/vm/compiler/codegen/x86/NcgAot.cpp
index c3c28ec..d1d1a87 100644
--- a/vm/compiler/codegen/x86/NcgAot.cpp
+++ b/vm/compiler/codegen/x86/NcgAot.cpp
@@ -138,8 +138,15 @@ int unconditional_jump_global_API(
     unconditional_jump(target, isShortTerm);
     return 1;
 }
+
+/* @brief Provides address to global constants
+ * @details Essentially provides an associative
+ * array of global data values indexed by name
+ * @param dataName the string for the data
+ * @return pointer to the global data
+ */
 int getGlobalDataAddr(const char* dataName) {
-    int dataAddr = -1;
+    int dataAddr = 0;
     if(!strcmp(dataName, "doubNeg")) dataAddr = LdoubNeg;
     else if(!strcmp(dataName, "intMax")) dataAddr = LintMax;
     else if(!strcmp(dataName, "intMin")) dataAddr = LintMin;
@@ -152,7 +159,10 @@ int getGlobalDataAddr(const char* dataName) {
     else if(!strcmp(dataName, "strClassCastExceptionPtr")) dataAddr = LstrClassCastExceptionPtr;
     else if(!strcmp(dataName, "strInstantiationError")) dataAddr = LstrInstantiationErrorPtr;
     else if(!strcmp(dataName, "gDvmInlineOpsTable")) dataAddr = (int)gDvmInlineOpsTable;
-    else ALOGE("global data %s not supported", dataName);
+    else {
+        ALOGE("JIT_ERROR: global data %s not supported\n", dataName);
+        SET_JIT_ERROR(kJitErrorGlobalData);
+    }
     return dataAddr;
 }
 
@@ -163,6 +173,8 @@ int load_imm_global_data_API(const char* dataName,
 
     //find the address from name
     int dataAddr = getGlobalDataAddr(dataName);
+    if (dataAddr == 0)
+        return -1;
     move_imm_to_reg(size, dataAddr, reg, isPhysical);
     return 0;
 }
@@ -174,6 +186,8 @@ int load_global_data_API(const char* dataName,
 
     //find the address from name
     int dataAddr = getGlobalDataAddr(dataName);
+    if (dataAddr == 0)
+        return -1;
     move_mem_to_reg(size, dataAddr, PhysicalReg_Null, true, reg, isPhysical);
     return 0;
 }
@@ -182,6 +196,8 @@ int load_sd_global_data_API(const char* dataName,
 
     //find the address from name
     int dataAddr = getGlobalDataAddr(dataName);
+    if (dataAddr == 0)
+        return -1;
     move_sd_mem_to_reg(dataAddr, PhysicalReg_Null, true, reg, isPhysical);
     return 0;
 }
@@ -190,6 +206,8 @@ int load_fp_stack_global_data_API(const char* dataName,
                                   OpndSize size) {
 
     int dataAddr = getGlobalDataAddr(dataName);
+    if (dataAddr == 0)
+        return -1;
     load_int_fp_stack_imm(size, dataAddr); //fildl
     return 0;
 }
diff --git a/vm/compiler/codegen/x86/Schedule.cpp b/vm/compiler/codegen/x86/Schedule.cpp
index 0cbe732..fa86f5d 100644
--- a/vm/compiler/codegen/x86/Schedule.cpp
+++ b/vm/compiler/codegen/x86/Schedule.cpp
@@ -1676,18 +1676,20 @@ void Scheduler::schedule() {
 
     // Make sure that original and scheduled basic blocks are same size
     if (scheduledLIREntries.size() != queuedLIREntries.size()) {
-        ALOGE("ERROR: Atom Scheduler bug! Original basic block is not same "
-                "size as the scheduled basic block");
-        dvmAbort();
+        ALOGE("JIT_ERROR: (Atom Scheduler) Original basic block is not same \
+                size as the scheduled basic block");
+        SET_JIT_ERROR(kJitErrorInsScheduling);
+        return;
     }
 
     // Make sure that basic block delimiter mnemonic is always last one in
     // scheduled basic block
     if (isBasicBlockDelimiter(queuedLIREntries.back()->opCode)
             && !isBasicBlockDelimiter(scheduledLIREntries.back()->opCode)) {
-        ALOGE("ERROR: Atom Scheduler bug! Sync point should be the last "
-        "scheduled instruction.");
-        dvmAbort();
+        ALOGE("JIT_ERROR: (Atom Scheduler) Sync point should be the last \
+                scheduled instruction.");
+        SET_JIT_ERROR(kJitErrorInsScheduling);
+        return;
     }
 }
 
-- 
1.7.4.1

